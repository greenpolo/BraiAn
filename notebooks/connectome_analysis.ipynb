{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectome analysis\n",
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIRECTORY = \"rebased_on_mjd\"                     # e.g. \"rebased_on_mjd\", \"p4\", ...\n",
    "USE_LOCAL_DATA = True                                       # if False, it tries to read the data on the laboratory's server\n",
    "IS_COLLABORATION_PROJ = True\n",
    "import os\n",
    "COLLABORATION_DIRECTORY = os.path.join(\"Mathias Schmidt\", \"soumnya\")\n",
    "\n",
    "# ###################################### LOCAL DIRECTORIES ######################################\n",
    "DATA_ROOT  = f\"../data/experiments/soumnya/{EXPERIMENT_DIRECTORY}\"\n",
    "PLOTS_ROOT = f\"../plots/soumnya/{EXPERIMENT_DIRECTORY}/\"\n",
    "# DATA_ROOT  = f\"../data/experiments/{EXPERIMENT_DIRECTORY}\"\n",
    "# PLOTS_ROOT = f\"../plots/{EXPERIMENT_DIRECTORY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### GENERAL OPTIONS #######################################\n",
    "BRANCHES_TO_EXCLUDE = [\"retina\", \"VS\", \"grv\", \"fiber tracts\", \"CB\"]\n",
    "USE_LITERATURE_REUNIENS = False                             # add a 'REtot' region, merging the following regions: 'PR', 'RE', 'Xi', 'RH'\n",
    "# MIN_AREA = 0.0                                            # area in mm². If a region of one animal is smaller, that same animal won't be displayed in the plots\n",
    "MIN_AREA = 0.1 # we used this for bar plots\n",
    "NORMALIZATION = \"Density\"                                   # call get_normalization_methods() on a AnimalGroup object to know its available normalization methods\n",
    "REGIONS_TO_PLOT_SELECTION_METHOD = \"summary structures\"     # Available options are:\n",
    "                                                            #   - \"summary structures\"\n",
    "                                                            #   - \"nre to bla\"\n",
    "                                                            #   - \"major divisions\"\n",
    "                                                            #   - \"depth <n>\" where <n> is an integer of the depth desired\n",
    "                                                            #   - \"structural level <n>\" where <n> is an integer of the level desired\n",
    "                                                            #   - \"pls <experiment> <salience_threshold>\" (e.g., \"pls proof 1.2\")\n",
    "SAVED_PLOT_EXTENSION = \".html\"                              # '.html' for interactive plot\n",
    "                                                            # '.svg' for vectorized image\n",
    "                                                            # '.png'/'.jpg'/... for rasterized image\n",
    "# ###################################### CROSS CORRELATION ######################################\n",
    "MIN_ANIMALS_CROSS_CORRELATION = 4                           # 'None' means that ALL the animals must have the region, otherwise the correlation is NaN\n",
    "PLOT_ONLY_REGIONS_PRESENT_IN_ALL_GROUPS = False             # if False, the correlation matrix and the chord plots of two groups may refer to different regions\n",
    "PLOT_REGIONS_WITH_INSUFFICIENT_DATA = True                  # what to do with brain regions with less animals than min_animals_cross_correlation\n",
    "\n",
    "# ###################################### CORRELATION MATRIX #####################################\n",
    "MATRIX_SAVE_PLOT = False\n",
    "MATRIX_SHOW_PLOT = False\n",
    "MATRIX_CELL_HEIGHT = 18\n",
    "MATRIX_STAR_SIZE = 8\n",
    "MATRIX_CELL_RATIO = 1\n",
    "MATRIX_MIN_PLOT_HEIGHT = 500\n",
    "\n",
    "# ######################################## CORR. NETWORK ########################################\n",
    "# NETWORK_P_CUTOFF = 0.05                                     # 1 if you don't want to filter by p-value\n",
    "NETWORK_P_CUTOFF = 0.01\n",
    "# NETWORK_P_CUTOFF = 0.0025\n",
    "NETWORK_R_CUTOFF = 0.87\n",
    "NETWORK_USE_NEGATIVE_LINKS = False\n",
    "NETWORK_USE_ISOLATED_VERTICES = False\n",
    "\n",
    "# ######################################## CHORD DIAGRAM ########################################\n",
    "CHORD_SAVE_PLOT = False\n",
    "CHORD_SHOW_PLOT = True\n",
    "CHORD_PLOT_SIZE = 1200\n",
    "CHORD_NO_BACKGROUND = False\n",
    "CHORD_REGIONS_SIZE = 10\n",
    "CHORD_REGIONS_FONT_SIZE = 10\n",
    "CHORD_MAX_EDGE_WIDTH = 3\n",
    "CHORD_USE_WEIGHTED_EDGE_WIDTHS = False\n",
    "CHORD_USE_COLORSCALE_EDGES = True\n",
    "CHORD_COLORSCALE = \"Plasma\"                                 # see https://plotly.com/python/builtin-colorscales/\n",
    "CHORD_COLORSCALE_MIN = \"cutoff\"\n",
    "CHORD_BOTTOM_ANNOTATIONS = dict(\n",
    "    annotation1 = \"Dark grey nodes are regions with insufficient data to compute cross correlation\",\n",
    "    annotation2 = \"Light grey nodes are regions with no correlation with others above the threshold\",\n",
    "    annotation3 = \"This is the third annotation\",\n",
    "    # howmany annotations desired with the following format:\n",
    "    # annotations<k> = \"<annotation>\"\n",
    ")\n",
    "# ###############################################################################################\n",
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "from collections import namedtuple\n",
    "GroupInfo = namedtuple(\"GroupInfo\", \"name colour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHILA - 3 Groups {Control|Stress|Resilient}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[6]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[7]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Resilient\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[8]\n",
    "    )\n",
    "]\n",
    "group_folder = \"C-S-R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA FEMALES+MALES - 2 Groups {Stress|Control}\n",
    "# SHILA - 2 Groups {Control|Stress+Resilient}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[4]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[5]\n",
    "    )\n",
    "]\n",
    "group_folder = \"C-S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA ALL - 2 Groups {Stress|Control} + 2 Groups {Males|Females}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control (Females)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[0]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress (Females)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[1]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Control (Males)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[2]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress (Males)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[3]\n",
    "    )\n",
    "]\n",
    "group_folder = \"CF-SF-CM-SM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA FEMALES - 2 Groups {Stress|Control}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control (Females)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[0]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress (Females)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[1]\n",
    "    )\n",
    "]\n",
    "group_folder = \"CF-SF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P4 - 2 Groups {Sham|SNi}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"SNi\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[0]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Sham\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[1]\n",
    "    )\n",
    "]\n",
    "group_folder = \"Sham-SNi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA MALES - 2 Groups {Stress|Control}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control (Males)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[2]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress (Males)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[3]\n",
    "    )\n",
    "]\n",
    "group_folder = \"CM-SM\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script's code\n",
    "run all cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "project_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(project_path)\n",
    "import BraiAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_LOCAL_DATA:\n",
    "    match sys.platform:\n",
    "        case \"darwin\":\n",
    "            mnt_point = \"/Volumes/Ricerca/\"\n",
    "            \n",
    "        case \"linux\":\n",
    "            mnt_point = \"/run/user/1000/gvfs/smb-share:server=ich.techosp.it,share=ricerca/\"\n",
    "        case \"win32\":\n",
    "            mnt_point = \"\\\\\\\\ich.techosp.it\\\\Ricerca\\\\\"\n",
    "        case _:\n",
    "            raise Exception(f\"Can't find the 'Ricerca' folder in the server for '{sys.platform}' operative system. Please report the developer (Carlo)!\")\n",
    "    if not os.path.isdir(mnt_point):\n",
    "        raise Exception(f\"Could not read '{mnt_point}'. Please be sure you are connected to the server.\")\n",
    "    if IS_COLLABORATION_PROJ:\n",
    "        DATA_ROOT  =  os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", COLLABORATION_DIRECTORY, \"data\", EXPERIMENT_DIRECTORY)\n",
    "        PLOTS_ROOT = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", \"Mathias Schmidt\", \"soumnya\", \"results\", EXPERIMENT_DIRECTORY, \"plots\")\n",
    "    else:\n",
    "        DATA_ROOT  =  os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"projects\", \"data\", EXPERIMENT_DIRECTORY)\n",
    "        PLOTS_ROOT = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"projects\", \"results\", EXPERIMENT_DIRECTORY, \"plots\")\n",
    "\n",
    "data_input_path     = os.path.join(DATA_ROOT, \"BraiAn_output\")\n",
    "data_output_path    = os.path.join(data_input_path, group_folder)\n",
    "plots_output_path   = os.path.join(PLOTS_ROOT, group_folder)\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)\n",
    "\n",
    "if not(os.path.exists(plots_output_path)):\n",
    "    os.makedirs(plots_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "path_to_allen_json = os.path.join(project_path, \"data\", \"AllenMouseBrainOntology.json\")\n",
    "BraiAn.cache(path_to_allen_json, \"http://api.brain-map.org/api/v2/structure_graph_download/1.json\")\n",
    "AllenBrain = BraiAn.AllenBrainHierarchy(path_to_allen_json, BRANCHES_TO_EXCLUDE, use_literature_reuniens=USE_LITERATURE_REUNIENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_groups: list[BraiAn.AnimalGroup] = []\n",
    "for group in groups:\n",
    "    animal_group = BraiAn.AnimalGroup.from_csv(group.name, data_input_path, f\"cell_counts_{group.name}.csv\")\n",
    "    animal_groups.append(animal_group)\n",
    "    print(f\"Group '{animal_group.name}' - #animals: {animal_group.n}, marker: {animal_group.marker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match REGIONS_TO_PLOT_SELECTION_METHOD:\n",
    "    case \"summary structures\":\n",
    "        # selects the Summary Strucutures\n",
    "        path_to_summary_structures = os.path.join(project_path, \"data\", \"AllenSummaryStructures.csv\")\n",
    "        AllenBrain.select_from_csv(path_to_summary_structures, include_nre_tot=USE_LITERATURE_REUNIENS)\n",
    "    case \"nre to bla\":\n",
    "        # selects the NRe to BLA inputs\n",
    "        path_to_inputs = os.path.join(project_path, \"data\", \"NRe_to_BLA_inputs.csv\")\n",
    "        AllenBrain.select_from_csv(path_to_inputs, include_nre_tot=USE_LITERATURE_REUNIENS)\n",
    "        nre_bla_regions = AllenBrain.get_selected_regions()\n",
    "        nre_bla_regions += (\"REtot\", \"BLA\")\n",
    "        AllenBrain.select_regions(nre_bla_regions)\n",
    "    case \"major divisions\":\n",
    "        AllenBrain.select_regions(BraiAn.MAJOR_DIVISIONS)\n",
    "    case s if s.startswith(\"pls\"):\n",
    "        options = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")\n",
    "        assert len(options) == 3, \"The 'REGIONS_TO_PLOT_SELECTION_METHOD' option is invalid. Make sure it follows the follows the following pattern: \\\"pls <experiment> <salience_threshold>\\\" (e.g., \\\"pls proof 1.2\\\")\"\n",
    "        pls_experiment, pls_threshold = options[1:]\n",
    "        pls_threshold = pls_threshold.replace(\".\", \"_\")\n",
    "        assert len(animal_groups) == 2, f\"You can't use the PLS of '{pls_experiment}' for selecting the regions to plot because '{group_folder}' has too many groups ({len(animal_groups)})\"\n",
    "        pls_file = f\"pls_{animal_groups[0].marker}_{NORMALIZATION}_salient_regions_above_{pls_threshold}.csv\".lower()\n",
    "        regions_to_plot_pls_csv = os.path.abspath(os.path.join(DATA_ROOT, os.pardir, pls_experiment, \"BraiAn_output\", group_folder, pls_file))\n",
    "        assert os.path.isfile(regions_to_plot_pls_csv), f\"Could not find the file '{regions_to_plot_pls_csv}'\"\n",
    "        AllenBrain.select_from_csv(regions_to_plot_pls_csv, key=\"acronym\")\n",
    "    case s if s.startswith(\"depth\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            depth = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'depth' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        AllenBrain.select_at_depth(depth)\n",
    "    case s if s.startswith(\"structural level\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            level = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'structural level' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        AllenBrain.select_at_structural_level(level)\n",
    "    case _:\n",
    "        raise Exception(f\"Invalid value '{REGIONS_TO_PLOT_SELECTION_METHOD}' for REGIONS_TO_PLOT_SELECTION_METHOD\")\n",
    "regions_to_plot = AllenBrain.get_selected_regions()\n",
    "print(f\"You selected {len(regions_to_plot)} regions to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal_group in animal_groups:\n",
    "    animal_group.remove_smaller_subregions(MIN_AREA, regions_to_plot, AllenBrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATRIX_SAVE_PLOT or MATRIX_SHOW_PLOT or CHORD_SAVE_PLOT or CHORD_SHOW_PLOT:\n",
    "    groups_cross_correlations = [BraiAn.CrossCorrelation(g, regions_to_plot, AllenBrain, NORMALIZATION, MIN_ANIMALS_CROSS_CORRELATION, g.name) for g in animal_groups]\n",
    "    \n",
    "    if PLOT_ONLY_REGIONS_PRESENT_IN_ALL_GROUPS:\n",
    "        BraiAn.CrossCorrelation.make_comparable(*groups_cross_correlations)\n",
    "    if not PLOT_REGIONS_WITH_INSUFFICIENT_DATA:\n",
    "        for cc in groups_cross_correlations:\n",
    "            cc.remove_insufficient_regions()\n",
    "    regions_to_plot_selection_method_str = REGIONS_TO_PLOT_SELECTION_METHOD.replace(\".\", \"_\").replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATRIX_SAVE_PLOT or MATRIX_SHOW_PLOT:\n",
    "    for group, cc in zip(animal_groups, groups_cross_correlations):\n",
    "        title = f\"{group.name} Pearson cross correlation matrix (n = {group.n})\"\n",
    "        fig = cc.plot(\n",
    "                title=title,\n",
    "                cell_height=MATRIX_CELL_HEIGHT, min_plot_height=MATRIX_MIN_PLOT_HEIGHT,\n",
    "                star_size=MATRIX_STAR_SIZE, aspect_ratio=MATRIX_CELL_RATIO,\n",
    "                color_min=-1, color_max=1\n",
    "                )\n",
    "        if MATRIX_SAVE_PLOT:\n",
    "            plot_filename = f\"correlation_matrix_min{MIN_ANIMALS_CROSS_CORRELATION}_{group.name}_{group.marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "            plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "            match SAVED_PLOT_EXTENSION.lower():\n",
    "                case \".html\":\n",
    "                    fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "                case _:\n",
    "                    fig.write_image(plot_filepath)\n",
    "        if MATRIX_SHOW_PLOT:\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_str = str(NETWORK_P_CUTOFF).replace(\".\", \"_\")\n",
    "r_str = str(NETWORK_R_CUTOFF).replace(\".\", \"_\")\n",
    "for animal_group, cc in zip(animal_groups, groups_cross_correlations):\n",
    "    connectome = BraiAn.FunctionalConnectome(cc,\n",
    "                                         p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                         negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=True, weighted=True)\n",
    "    if REGIONS_TO_PLOT_SELECTION_METHOD == \"nre to bla\" and \"REtot\" in cc.p.index:\n",
    "        connectome = connectome.region_subgraph(\"REtot\", isolated_vertices=True)\n",
    "    title = f\"{animal_group.name} connectomics graph from Pearson correlation (n = {animal_group.n}, {'|r|' if NETWORK_USE_NEGATIVE_LINKS else 'r'} >= {NETWORK_R_CUTOFF}, p <= {NETWORK_P_CUTOFF})\"\n",
    "    fig = BraiAn.draw_chord_plot(connectome,\n",
    "                                AllenBrain=AllenBrain,\n",
    "                                ideograms_arc_index=50,\n",
    "                                title=title,\n",
    "                                size=CHORD_PLOT_SIZE,\n",
    "                                no_background=CHORD_NO_BACKGROUND,\n",
    "                                regions_size=CHORD_REGIONS_SIZE,\n",
    "                                regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "                                max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "                                use_weighted_edge_widths=CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "                                colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "                                colorscale=CHORD_COLORSCALE,\n",
    "                                colorscale_min=CHORD_COLORSCALE_MIN,\n",
    "    )\n",
    "    fig.show()\n",
    "    # filename = f\"chord_plot_min{MIN_ANIMALS_CROSS_CORRELATION}_p{p_str}_r{r_str}_{animal_group.name.lower()}_{animal_groups[0].marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}.html\"\n",
    "    # fig.write_html(filename.lower(), config=dict(toImageButtonOptions=dict(format=\"svg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "\n",
    "# https://doi.org/10.1109/TKDE.2007.190689\n",
    "# clustering_args = (ig.Graph.community_optimal_modularity,)\n",
    "                    # Graphs with up to fifty vertices should be fine, graphs with a couple of hundred vertices might be possible.\n",
    "                    # crashes on my pc with summary structure's Graph\n",
    "clustering_args = (ig.Graph.community_fastgreedy,)\n",
    "# clustering_args = (ig.Graph.community_infomap,)\n",
    "# clustering_args = (ig.Graph.community_leading_eigenvector_naive,)\n",
    "# clustering_args = (ig.Graph.community_leading_eigenvector,)\n",
    "# clustering_args = (ig.Graph.community_label_propagation,)\n",
    "# clustering_args = (ig.Graph.community_multilevel,)\n",
    "# clustering_args = (ig.Graph.community_edge_betweenness, dict(directed=False))\n",
    "# clustering_args = (ig.Graph.community_spinglass,)\n",
    "# clustering_args = (ig.Graph.community_walktrap,)\n",
    "# clustering_args = (ig.Graph.community_leiden,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout_fun = ig.Graph.layout_kamada_kawai               # 1st best - good for ~small networks\n",
    "layout_fun = ig.Graph.layout_fruchterman_reingold       # 2nd best - good for bigger networks\n",
    "# layout_fun = ig.Graph.layout_graphopt                   # 3rd best\n",
    "# layout_fun = ig.Graph.layout_davidson_harel             # 4th best\n",
    "# layout_fun = ig.Graph.layout_mds                        # 5th best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal_group, cc in zip(animal_groups, groups_cross_correlations):\n",
    "    connectome = BraiAn.FunctionalConnectome(cc,\n",
    "                                        p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                        negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=NETWORK_USE_ISOLATED_VERTICES, weighted=False)\n",
    "    if REGIONS_TO_PLOT_SELECTION_METHOD == \"nre to bla\" and \"REtot\" in cc.p.index:\n",
    "        connectome = connectome.region_subgraph(\"REtot\", isolated_vertices=NETWORK_USE_ISOLATED_VERTICES)\n",
    "    connectome.cluster_regions(*clustering_args)\n",
    "    \n",
    "    title = f\"{connectome.name} connectomics graph from Pearson correlation (n = {connectome.n}, {'|r|' if NETWORK_USE_NEGATIVE_LINKS else 'r'} >= {NETWORK_R_CUTOFF}, p <= {NETWORK_P_CUTOFF})\"\n",
    "    random.seed(0) # used by layout_fun to arrange the nodes of the connectome\n",
    "    fig = BraiAn.draw_network_plot(connectome, layout_fun, AllenBrain, title=title)\n",
    "    fig.show()\n",
    "    # filename = f\"network_min{MIN_ANIMALS_CROSS_CORRELATION}_p{p_str}_r{r_str}_{animal_group.name.lower()}_{animal_groups[0].marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}.html\"\n",
    "    # fig.write_html(filename.lower(), config=dict(toImageButtonOptions=dict(format=\"svg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from https://download.alleninstitute.org/publications/A_high_resolution_data-driven_model_of_the_mouse_connectome/\n",
    "normalized_connection_density_file = os.path.join(project_path, \"data\",\n",
    "                                                    \"A_high_resolution_data-driven_model_of_the_mouse_connectome\",\n",
    "                                                    \"normalized_connection_density.csv\")\n",
    "BraiAn.cache(normalized_connection_density_file,\n",
    "             \"https://download.alleninstitute.org/publications/A_high_resolution_data-driven_model_of_the_mouse_connectome/normalized_connection_density.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(where):\n",
    "    rows = where.index[where.any(axis=1)]\n",
    "    return [(row, col) for row in rows for col in where.columns if where.loc[row, col]]\n",
    "\n",
    "# find_indices(normalized_connection_density == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log10_cutoff = -3.8\n",
    "allen_connectome = BraiAn.StructuralConnectome(normalized_connection_density_file, regions_to_plot, AllenBrain, mode=\"max\", log10_cutoff=log10_cutoff)\n",
    "print(f\"\"\"\n",
    "Max: {allen_connectome.A.max()}\n",
    "Mean: {allen_connectome.A.mean()}+-{allen_connectome.A.std()}\n",
    "Mean (log10): {allen_connectome.A.mean(log=True)}+-{allen_connectome.A.std(log=True)}\n",
    "Density: {allen_connectome.G.density()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as Figure 2 in https://direct.mit.edu/netn/article/3/1/217/2194/High-resolution-data-driven-model-of-the-mouse\n",
    "allen_connectome.plot_adjacency(color_min=-5, color_max=-2.5, cell_height=4)\\\n",
    "                .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = allen_connectome.G.vs.select(name=\"RE\")[0]\n",
    "print(\"RE->BLA density:\", allen_connectome.A.data.loc[\"RE\", \"BLA\"], f\"(log10={np.log10(allen_connectome.A.data.loc['RE', 'BLA'])})\")\n",
    "print(\"BLA->RE density:\", allen_connectome.A.data.loc[\"BLA\", \"RE\"], f\"(log10={np.log10(allen_connectome.A.data.loc['BLA', 'RE'])})\")\n",
    "print(\"RE->ILA density:\", allen_connectome.A.data.loc[\"RE\", \"ILA\"], f\"(log10={np.log10(allen_connectome.A.data.loc['RE', 'ILA'])})\")\n",
    "print(\"ILA->RE density:\", allen_connectome.A.data.loc[\"ILA\", \"RE\"], f\"(log10={np.log10(allen_connectome.A.data.loc['ILA', 'RE'])})\")\n",
    "print(f\"\\nNetwork with log10(density) cutoff={log10_cutoff} ({10**log10_cutoff})\")\n",
    "print(\"\\tRE Degree:\", re.degree(), f\"({re.indegree()}+{re.outdegree()})\")\n",
    "for e in re.all_edges():\n",
    "    print(f\"\\t\\t{e.source_vertex['name']}->{e.target_vertex['name']}: {e['weight']:.3f} ({10**e['weight']:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allen_connectome.G.es[\"p-value\"] = 0\n",
    "# allen_connectome.G.vs[\"is_undefined\"] = False\n",
    "# allen_connectome.G.vs[\"upper_region\"] = [allen_connection_matrix.upper_regions[region] for region in allen_connectome.G.vs[\"name\"]]\n",
    "# allen_connectome = BraiAn.FunctionalConnectome(None, None, r_cutoff=0, graph=G_allen, n=None, name=\"Allen's Connectome\")\n",
    "fig = BraiAn.draw_chord_plot(allen_connectome,\n",
    "                            AllenBrain=AllenBrain,\n",
    "                            ideograms_arc_index=50,\n",
    "                            title=allen_connectome.name+f\" [log10(normalized density) >= {log10_cutoff}]\",\n",
    "                            size=CHORD_PLOT_SIZE,\n",
    "                            no_background=CHORD_NO_BACKGROUND,\n",
    "                            regions_size=CHORD_REGIONS_SIZE,\n",
    "                            regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "                            max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "                            use_weighted_edge_widths=False, #CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "                            colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "                            colorscale=CHORD_COLORSCALE,\n",
    "                            colorscale_min=10**log10_cutoff,\n",
    "                            colorscale_max=10**(-2.5) #np.log10(allen_connection_matrix.A.max(axis=None))\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_P_CUTOFF = 0.01\n",
    "for cc in groups_cross_correlations:\n",
    "    fc_pruned = BraiAn.PrunedConnectomics(allen_connectome, cc, NETWORK_R_CUTOFF, NETWORK_P_CUTOFF, isolated_vertices=False, weighted=True)\n",
    "    title = f\"{fc_pruned.name} [n = {cc.n}, {'|r|' if NETWORK_USE_NEGATIVE_LINKS else 'r'} >= {NETWORK_R_CUTOFF}, p <= {NETWORK_P_CUTOFF}, d >= {10**log10_cutoff}]\"\n",
    "    fc_pruned.G.vs[\"PageRank\"] = fc_pruned.G.pagerank()\n",
    "    fc_pruned.G.vs[\"Betweeness\"] = fc_pruned.G.betweenness()\n",
    "    fc_pruned.G.vs[\"Harmonic\"] = fc_pruned.G.harmonic_centrality()\n",
    "    fc_pruned.G.vs[\"Eigenvector\"] = fc_pruned.G.evcent()\n",
    "    random.seed(0) # used by layout_fun to arrange the nodes of the connectome\n",
    "    fig = BraiAn.draw_network_plot(fc_pruned, layout_fun, AllenBrain, title=title, use_centrality=True, centrality_metric=\"Harmonic\")\n",
    "    # fig = BraiAn.draw_chord_plot(fc_pruned,\n",
    "    #                             AllenBrain=AllenBrain,\n",
    "    #                             ideograms_arc_index=50,\n",
    "    #                             title=title,\n",
    "    #                             size=CHORD_PLOT_SIZE,\n",
    "    #                             no_background=CHORD_NO_BACKGROUND,\n",
    "    #                             regions_size=CHORD_REGIONS_SIZE,\n",
    "    #                             regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "    #                             max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "    #                             use_weighted_edge_widths=CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "    #                             colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "    #                             colorscale=CHORD_COLORSCALE,\n",
    "    #                             colorscale_min=NETWORK_R_CUTOFF, #CHORD_COLORSCALE_MIN,\n",
    "    # )\n",
    "    fig.show()\n",
    "    # fig.write_html(f\"chord_{fc_pruned.name.lower()}.html\")\n",
    "    # fig.write_html(f\"{fc_pruned.name.lower()}_r{NETWORK_R_CUTOFF}_p{NETWORK_P_CUTOFF}_d{log10_cutoff}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = fc_pruned.G.vs.select(name=\"VPL\")[0]\n",
    "for e in re.all_edges():\n",
    "    d = e[\"weight\"] # fc_pruned. .data.loc[e.source_vertex['name'], e.target_vertex['name']]\n",
    "    p = cc.p.data.loc[e.source_vertex['name'], e.target_vertex['name']]\n",
    "    print(d >= 10**log10_cutoff, 10**log10_cutoff, log10_cutoff)\n",
    "    print(f\"{e.source_vertex['name']}->{e.target_vertex['name']}: r={e['weight']:.3f} p={p:.4f} d={d:.5f} ({np.log10(d):.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "connectome = BraiAn.FunctionalConnectome(groups_cross_correlations[i],\n",
    "                                         p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                         negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=NETWORK_USE_ISOLATED_VERTICES, weighted=False)\n",
    "connectome_w = BraiAn.FunctionalConnectome(groups_cross_correlations[i],\n",
    "                                         p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                         negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=NETWORK_USE_ISOLATED_VERTICES, weighted=True)\n",
    "sorted(list(zip(connectome.G.degree(), connectome.G.vs[\"name\"])), key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def centrality_barplot(G: ig.Graph, centrality_fun, n=20, name=\"\", yaxis=\"y1\", offsetgroup=1, **kwargs):\n",
    "    sorted_by_centrality = sorted(G.vs.indices, key=lambda i: centrality_fun(G, i, **kwargs), reverse=True)\n",
    "    selected_regions = G.vs[sorted_by_centrality[:n]]\n",
    "    return go.Bar(\n",
    "        x=selected_regions[\"name\"],\n",
    "        y=centrality_fun(G, selected_regions, **kwargs),\n",
    "        name=name,\n",
    "        yaxis=yaxis,\n",
    "        offsetgroup=offsetgroup\n",
    "    )\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        centrality_barplot(connectome.G, ig.Graph.degree, n=20, name=\"Degree\", mode=\"all\", loops=False, yaxis=\"y1\", offsetgroup=1),\n",
    "        centrality_barplot(connectome.G, ig.Graph.pagerank, n=20, name=\"PageRank\", yaxis=\"y2\", offsetgroup=2),\n",
    "        centrality_barplot(connectome.G, ig.Graph.betweenness, n=20, name=\"Betweenness\", yaxis=\"y3\", offsetgroup=3),\n",
    "#        centrality_barplot(connectome.G, ig.Graph.closeness, n=20, name=\"Closeness\", yaxis=\"y4\", offsetgroup=4), # closeness makes little to no sense to be used in a graph with isolated vertices\n",
    "        centrality_barplot(connectome.G, ig.Graph.harmonic_centrality, n=20, name=\"Harmonic\", yaxis=\"y2\", offsetgroup=5)\n",
    "    ],\n",
    "    layout=dict(\n",
    "        title=\"top 20 ranked regions\",\n",
    "        yaxis=dict(\n",
    "            title=\"Degree\",\n",
    "            side=\"left\",\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title=\"PageRank\",\n",
    "            side=\"right\",\n",
    "            overlaying=\"y\"\n",
    "        ),\n",
    "        yaxis3=dict(\n",
    "            title=\"Betweenness\",\n",
    "            side=\"left\",\n",
    "            overlaying=\"y\",\n",
    "            #autoshift=False, shift=-100, anchor=\"free\"\n",
    "        ),\n",
    "        yaxis4=dict(\n",
    "            title=\"Closeness\",\n",
    "            side=\"right\",\n",
    "            overlaying=\"y\",\n",
    "            #autoshift=True, anchor=\"free\"\n",
    "        ),\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def get_ranks(G, centrality_fun, **kwargs):\n",
    "    centrality_scores = np.flip(np.sort(np.nan_to_num(centrality_fun(G, **kwargs), copy=False, nan=0.0)))\n",
    "    _, unique_ranks = np.unique(centrality_scores, return_index=True) # returns indices of the unique centrality scores (in ascending order)\n",
    "    ranks_repetitions = unique_ranks[:-1]-unique_ranks[1:]\n",
    "    ranks_repetitions = np.insert(ranks_repetitions, 0, len(centrality_scores)-unique_ranks[0])\n",
    "    ranks = np.repeat(unique_ranks, ranks_repetitions)\n",
    "    return centrality_scores, np.flip(ranks)\n",
    "\n",
    "def centrality_barplot(G: ig.Graph, centrality_fun, name=\"\", yaxis=\"y1\", offsetgroup=1, **kwargs):\n",
    "    sorted_by_centrality = sorted(G.vs, key=lambda v: centrality_fun(G, v.index, **kwargs), reverse=True)\n",
    "    scores, ranks = get_ranks(connectome.G, centrality_fun, **kwargs)\n",
    "    return go.Bar(\n",
    "        x=[v[\"upper_region\"] for v in sorted_by_centrality],\n",
    "        # y=1/(ranks+1),\n",
    "        y=1/np.sqrt(ranks+1),\n",
    "        hovertext=[f\"Region: {v['name']}<br>{name}: {centrality_fun(G, v, **kwargs):.5f}\" for v in sorted_by_centrality],\n",
    "        name=name,\n",
    "        yaxis=yaxis,\n",
    "        offsetgroup=offsetgroup\n",
    "    )\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        centrality_barplot(connectome.G, ig.Graph.degree, loops=False, offsetgroup=1, name=\"Degree\", mode=\"all\"),\n",
    "        centrality_barplot(connectome.G, ig.Graph.pagerank, name=\"PageRank\", offsetgroup=2),\n",
    "        centrality_barplot(connectome.G, ig.Graph.betweenness, name=\"Betweenness\", offsetgroup=3),\n",
    "#        centrality_barplot(connectome.G, ig.Graph.closeness, name=\"Closeness\", offsetgroup=4), # closeness makes little to no sense to be used in a graph with isolated vertices\n",
    "        centrality_barplot(connectome.G, ig.Graph.harmonic_centrality, name=\"Harmonic\", offsetgroup=5)\n",
    "    ],\n",
    "    layout=dict(\n",
    "        title=\"Regions ranks with different metrics (grouped by major divisions)\",\n",
    "        yaxis=dict(\n",
    "            title=\"Importance Score\",\n",
    "            side=\"left\",\n",
    "        ),\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    [go.Histogram(\n",
    "        x=connectome.G.degree(),\n",
    "        xbins=dict(start=0, size=2,)\n",
    "    )],\n",
    "#    layout=dict(bargap=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "\n",
    "def path_length(G: ig.Graph, unreachable_nodes=True):\n",
    "    if G.is_weighted():\n",
    "        ds = np.asarray(G.distances(weights=np.abs(G.es[\"weight\"])), dtype=float)\n",
    "    else:\n",
    "        ds = np.asarray(G.distances(), dtype=float)\n",
    "    if unreachable_nodes:\n",
    "        ds[ds == np.inf] = 0\n",
    "        N = G.vcount()\n",
    "        return ds.sum(axis=0) / (N-1)\n",
    "    else:\n",
    "        ds[ds == np.inf] = np.nan\n",
    "        Ns = (~np.isnan(ds)).sum(axis=0, dtype=float)\n",
    "        den = Ns - 1\n",
    "        den[den == 0] = np.nan\n",
    "        return np.nansum(ds, axis=0) / den\n",
    "\n",
    "def average_path_length(G: ig.Graph, unreachable_nodes=True):\n",
    "    # if unreachable_nodes=False, it's equal to igraph.Graph.average_path_length(unconn=True)\n",
    "    if G.is_weighted():\n",
    "        ds = np.asarray(G.distances(weights=np.abs(G.es[\"weight\"])), dtype=float)\n",
    "    else:\n",
    "        ds = np.asarray(G.distances(), dtype=float)\n",
    "    if unreachable_nodes:\n",
    "        ds[ds == np.inf] = 0\n",
    "        N = G.vcount()\n",
    "        return ds.sum() / (N * (N - 1))\n",
    "    else:\n",
    "        ds = ds[ds != np.inf]\n",
    "        return ds.sum() / (len(ds) - G.vcount())\n",
    "\n",
    "# import networkx as nx\n",
    "\n",
    "# Gnx = nx.Graph([])\n",
    "# Gnx.add_node(1)\n",
    "# nx.global_efficiency(Gnx) # <- returns 0\n",
    "def nodal_efficiency(G: ig.Graph):\n",
    "    # https://en.wikipedia.org/wiki/Efficiency_(network_science)\n",
    "    N = G.vcount()\n",
    "    if N == 0:\n",
    "        raise ValueError(\"Empty graph\")\n",
    "    elif N == 1:\n",
    "#        return np.full(N, 1, dtype=float)\n",
    "        return np.full(N, 0, dtype=float)\n",
    "    if G.is_weighted():\n",
    "        ws = np.abs(1.0 / np.asarray(G.es[\"weight\"], dtype=float))\n",
    "        ds = np.asarray(G.distances(weights=ws), dtype=float)\n",
    "    else:\n",
    "        ds = np.asarray(G.distances(), dtype=float)\n",
    "    np.fill_diagonal(ds, np.NaN)\n",
    "    efficiency = 1 / ds\n",
    "    np.fill_diagonal(efficiency, 0)\n",
    "    ne = np.apply_along_axis(sum, 0, efficiency) / (N-1)\n",
    "    return ne\n",
    "\n",
    "def global_efficiency(G):\n",
    "    if G.vcount() == 0:\n",
    "        return np.nan\n",
    "    return nodal_efficiency(G).mean()\n",
    "\n",
    "def local_efficiency(G, zero_degree=True):\n",
    "    local_efficiency_i = []\n",
    "    for i in range(G.vcount()):\n",
    "        G_i = G.induced_subgraph(G.neighbors(i), \"create_from_scratch\")\n",
    "        global_efficiency_i = global_efficiency(G_i)\n",
    "        local_efficiency_i.append(global_efficiency_i)\n",
    "    if zero_degree:\n",
    "        return np.nansum(np.asarray(local_efficiency_i)) / len(local_efficiency_i)\n",
    "    else:\n",
    "        return np.nanmean(np.asarray(local_efficiency_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(G: ig.Graph):\n",
    "    print(f\"\"\"\n",
    "    INFO:\n",
    "        graph type: {'Weighted' if G.is_weighted() else 'Not weighted'}\n",
    "        #regions: {G.vcount()}\n",
    "        #connected regions: {len([d for d in G.degree() if d > 0])}\n",
    "        Max degree: {G.maxdegree()}\n",
    "    SEGREGATION:\n",
    "        Cluster coefficient: {G.transitivity_undirected()}\n",
    "        Mean local cluster coefficient (d>=2): {np.nanmean(G.transitivity_local_undirected())}\n",
    "        Mean local cluster coefficient (all): {np.nansum(G.transitivity_local_undirected()) / G.vcount()}\n",
    "        Local efficiency (d>=1): {local_efficiency(G, zero_degree=False)}\n",
    "        Local efficiency (all): {local_efficiency(G, zero_degree=True)}\n",
    "    INTEGRATION_\n",
    "        Global efficiency: {global_efficiency(G)}\n",
    "        Avg path length (∞ -> 0): {path_length(G, unreachable_nodes=True).mean()}\n",
    "        Avg path length (no ∞): {G.average_path_length(unconn=True)}\n",
    "        Median [characteristic] path lengh (∞ -> 0): {np.nanmedian(path_length(G, unreachable_nodes=True))}\n",
    "        Median [characteristic] path lengh (no ∞): {np.nanmedian(path_length(G, unreachable_nodes=False))}\n",
    "    \"\"\")\n",
    "\n",
    "print_stats(connectome.G)\n",
    "print_stats(connectome_w.G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: certain measures of statistical dependence used to quantify functional connectivity can bias\n",
    "# network organization in a way that cannot be removed by topological rewiring.\n",
    "# \n",
    "G_w_rewired = connectome_w.G.copy()\n",
    "G_w_rewired.rewire(mode=\"loops\")    # functional connectomes are inherently more clustered and exaggerate features such as small-worldness.\n",
    "                                    # We should use Maslov-Sneppen rewiring method (Bullmore, et al. 2016 - Fundamentals of Brain Network Analysis, chapter 10.3)\n",
    "G_w_rewired.es[\"weight\"] = connectome_w.G.es[\"weight\"]\n",
    "print_stats(G_w_rewired)\n",
    "\n",
    "G_rewired = connectome.G.copy()\n",
    "#G_rewired.rewire(mode=\"simple\") # does not create/destroy loop edges. If you allow it, you may change the degrees\n",
    "G_rewired.rewire(mode=\"loops\")\n",
    "print_stats(G_rewired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "__imported_modules = sys.modules.copy()\n",
    "for module_name, module in __imported_modules.items():\n",
    "    if not module_name.startswith(\"BraiAn\"):\n",
    "        continue\n",
    "    try:\n",
    "        importlib.reload(module)\n",
    "    except ModuleNotFoundError:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
