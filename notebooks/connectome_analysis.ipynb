{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot groups' analysis\n",
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIRECTORY = \"rebased_on_mjd\"\n",
    "USE_LOCAL_DATA = True                                       # if False, it tries to read the data on the laboratory's server\n",
    "IS_COLLABORATION_PROJ = True\n",
    "import os\n",
    "COLLABORATION_DIRECTORY = os.path.join(\"Mathias Schmidt\", \"soumnya\")\n",
    "\n",
    "# ###################################### LOCAL DIRECTORIES ######################################\n",
    "DATA_ROOT  = f\"../data/experiments/soumnya/{EXPERIMENT_DIRECTORY}\"\n",
    "PLOTS_ROOT = f\"../plots/soumnya/{EXPERIMENT_DIRECTORY}/\"\n",
    "# DATA_ROOT  = f\"../data/experiments/{EXPERIMENT_DIRECTORY}\"\n",
    "# PLOTS_ROOT = f\"../plots/{EXPERIMENT_DIRECTORY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### GENERAL OPTIONS #######################################\n",
    "BRANCHES_TO_EXCLUDE = [\"retina\", \"VS\", \"grv\", \"fiber tracts\", \"CB\"]\n",
    "USE_LITERATURE_REUNIENS = False                                  # add a 'REtot' region, merging the following regions: 'PR', 'RE', 'Xi', 'RH'\n",
    "# MIN_AREA = 0.0                                              # area in mm². If a region of one animal is smaller, that same animal won't be displayed in the plots\n",
    "MIN_AREA = 0.1 # we used this for bar plots\n",
    "NORMALIZATION = \"Density\"                                   # call get_normalization_methods() on a AnimalGroup object to know its available normalization methods\n",
    "REGIONS_TO_PLOT_SELECTION_METHOD = \"summary structures\"             # Available options are:\n",
    "                                                            #   - \"summary structures\"\n",
    "                                                            #   - \"nre to bla\"\n",
    "                                                            #   - \"major divisions\"\n",
    "                                                            #   - \"depth <n>\" where <n> is an integer of the depth desired\n",
    "                                                            #   - \"structural level <n>\" where <n> is an integer of the level desired\n",
    "                                                            #   - \"pls <experiment> <salience_threshold>\" (e.g., \"pls proof 1.2\")\n",
    "SAVED_PLOT_EXTENSION = \".html\"                              # '.html' for interactive plot\n",
    "                                                            # '.svg' for vectorized image\n",
    "                                                            # '.png'/'.jpg'/... for rasterized image\n",
    "# ###################################### CROSS CORRELATION ######################################\n",
    "MIN_ANIMALS_CROSS_CORRELATION = 4                           # 'None' means that ALL the animals must have the region, otherwise the correlation is NaN\n",
    "PLOT_ONLY_REGIONS_PRESENT_IN_ALL_GROUPS = False             # if False, the correlation matrix and the chord plots of two groups may refer to different regions\n",
    "PLOT_REGIONS_WITH_INSUFFICIENT_DATA = True                  # what to do with brain regions with less animals than min_animals_cross_correlation\n",
    "\n",
    "# ###################################### CORRELATION MATRIX #####################################\n",
    "MATRIX_SAVE_PLOT = False\n",
    "MATRIX_SHOW_PLOT = False\n",
    "MATRIX_CELL_HEIGHT = 18\n",
    "MATRIX_STAR_SIZE = 8\n",
    "MATRIX_CELL_RATIO = 1\n",
    "MATRIX_MIN_PLOT_HEIGHT = 500\n",
    "\n",
    "# ######################################## CORR. NETWORK ########################################\n",
    "NETWORK_P_CUTOFF = 0.05                                     # 1 if you don't want to filter by p-value\n",
    "NETWORK_P_CUTOFF = 0.0025\n",
    "NETWORK_R_CUTOFF = 0.87\n",
    "NETWORK_USE_NEGATIVE_LINKS = False\n",
    "NETWORK_USE_ISOLATED_VERTICES = False\n",
    "\n",
    "# ######################################## CHORD DIAGRAM ########################################\n",
    "CHORD_SAVE_PLOT = False\n",
    "CHORD_SHOW_PLOT = True\n",
    "CHORD_PLOT_SIZE = 1200\n",
    "CHORD_NO_BACKGROUND = False\n",
    "CHORD_REGIONS_SIZE = 10\n",
    "CHORD_REGIONS_FONT_SIZE = 10\n",
    "CHORD_MAX_EDGE_WIDTH = 3\n",
    "CHORD_USE_WEIGHTED_EDGE_WIDTHS = False\n",
    "CHORD_USE_COLORSCALE_EDGES = True\n",
    "CHORD_COLORSCALE = \"Plasma\"                                 # see https://plotly.com/python/builtin-colorscales/\n",
    "CHORD_COLORSCALE_MIN = \"cutoff\"\n",
    "CHORD_BOTTOM_ANNOTATIONS = dict(\n",
    "    annotation1 = \"Dark grey nodes are regions with insufficient data to compute cross correlation\",\n",
    "    annotation2 = \"Light grey nodes are regions with no correlation with others above the threshold\",\n",
    "    annotation3 = \"This is the third annotation\",\n",
    "    # howmany annotations desired with the following format:\n",
    "    # annotations<k> = \"<annotation>\"\n",
    ")\n",
    "# ###############################################################################################\n",
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "from collections import namedtuple\n",
    "GroupInfo = namedtuple(\"GroupInfo\", \"name colour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHILA - 3 Groups {Control|Stress|Resilient}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[6]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[7]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Resilient\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[8]\n",
    "    )\n",
    "]\n",
    "group_folder = \"C-S-R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA FEMALES+MALES - 2 Groups {Stress|Control}\n",
    "# SHILA - 2 Groups {Control|Stress+Resilient}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[4]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[5]\n",
    "    )\n",
    "]\n",
    "group_folder = \"C-S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA ALL - 2 Groups {Stress|Control} + 2 Groups {Males|Females}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control (Females)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[0]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress (Females)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[1]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Control (Males)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[2]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress (Males)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[3]\n",
    "    )\n",
    "]\n",
    "group_folder = \"CF-SF-CM-SM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA FEMALES - 2 Groups {Stress|Control}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control (Females)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[0]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress (Females)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[1]\n",
    "    )\n",
    "]\n",
    "group_folder = \"CF-SF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P4 - 2 Groups {Sham|SNi}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"SNi\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[0]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Sham\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[1]\n",
    "    )\n",
    "]\n",
    "group_folder = \"Sham-SNi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA MALES - 2 Groups {Stress|Control}\n",
    "groups = [\n",
    "    GroupInfo(\n",
    "        name=\"Control (Males)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[2]\n",
    "    ),\n",
    "    GroupInfo(\n",
    "        name=\"Stress (Males)\",\n",
    "        colour=DEFAULT_PLOTLY_COLORS[3]\n",
    "    )\n",
    "]\n",
    "group_folder = \"CM-SM\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script's code\n",
    "run all cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(project_path)\n",
    "import BraiAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_LOCAL_DATA:\n",
    "    match sys.platform:\n",
    "        case \"darwin\":\n",
    "            mnt_point = \"/Volumes/Ricerca/\"\n",
    "            \n",
    "        case \"linux\":\n",
    "            mnt_point = \"/run/user/1000/gvfs/smb-share:server=ich.techosp.it,share=ricerca/\"\n",
    "        case \"win32\":\n",
    "            mnt_point = \"\\\\\\\\ich.techosp.it\\\\Ricerca\\\\\"\n",
    "        case _:\n",
    "            raise Exception(f\"Can't find the 'Ricerca' folder in the server for '{sys.platform}' operative system. Please report the developer (Carlo)!\")\n",
    "    if not os.path.isdir(mnt_point):\n",
    "        raise Exception(f\"Could not read '{mnt_point}'. Please be sure you are connected to the server.\")\n",
    "    if IS_COLLABORATION_PROJ:\n",
    "        DATA_ROOT  =  os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", COLLABORATION_DIRECTORY, \"data\", EXPERIMENT_DIRECTORY)\n",
    "        PLOTS_ROOT = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", \"Mathias Schmidt\", \"soumnya\", \"results\", EXPERIMENT_DIRECTORY, \"plots\")\n",
    "    else:\n",
    "        DATA_ROOT  =  os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"projects\", \"data\", EXPERIMENT_DIRECTORY)\n",
    "        PLOTS_ROOT = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"projects\", \"results\", EXPERIMENT_DIRECTORY, \"plots\")\n",
    "\n",
    "data_input_path     = os.path.join(DATA_ROOT, \"BraiAn_output\")\n",
    "data_output_path    = os.path.join(data_input_path, group_folder)\n",
    "plots_output_path   = os.path.join(PLOTS_ROOT, group_folder)\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)\n",
    "\n",
    "if not(os.path.exists(plots_output_path)):\n",
    "    os.makedirs(plots_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "# StructureGraph id=1\n",
    "path_to_allen_json = os.path.join(project_path, \"data\", \"AllenMouseBrainOntology.json\")\n",
    "AllenBrain = BraiAn.AllenBrainHierarchy(path_to_allen_json, BRANCHES_TO_EXCLUDE, use_literature_reuniens=USE_LITERATURE_REUNIENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_groups: list[BraiAn.AnimalGroup] = []\n",
    "for group in groups:\n",
    "    animal_group = BraiAn.AnimalGroup.from_csv(group.name, data_input_path, f\"cell_counts_{group.name}.csv\")\n",
    "    animal_groups.append(animal_group)\n",
    "    print(f\"Group '{animal_group.name}' - #animals: {animal_group.n}, marker: {animal_group.marker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match REGIONS_TO_PLOT_SELECTION_METHOD:\n",
    "    case \"summary structures\":\n",
    "        # selects the Summary Strucutures\n",
    "        path_to_summary_structures = os.path.join(project_path, \"data\", \"AllenSummaryStructures.csv\")\n",
    "        AllenBrain.select_from_csv(path_to_summary_structures, include_nre_tot=USE_LITERATURE_REUNIENS)\n",
    "    case \"nre to bla\":\n",
    "        # selects the NRe to BLA inputs\n",
    "        path_to_inputs = os.path.join(project_path, \"data\", \"NRe_to_BLA_inputs.csv\")\n",
    "        AllenBrain.select_from_csv(path_to_inputs, include_nre_tot=USE_LITERATURE_REUNIENS)\n",
    "        nre_bla_regions = AllenBrain.get_selected_regions()\n",
    "        nre_bla_regions += (\"REtot\", \"BLA\")\n",
    "        AllenBrain.select_regions(nre_bla_regions)\n",
    "    case \"major divisions\":\n",
    "        AllenBrain.select_regions(BraiAn.MAJOR_DIVISIONS)\n",
    "    case s if s.startswith(\"pls\"):\n",
    "        options = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")\n",
    "        assert len(options) == 3, \"The 'REGIONS_TO_PLOT_SELECTION_METHOD' option is invalid. Make sure it follows the follows the following pattern: \\\"pls <experiment> <salience_threshold>\\\" (e.g., \\\"pls proof 1.2\\\")\"\n",
    "        pls_experiment, pls_threshold = options[1:]\n",
    "        pls_threshold = pls_threshold.replace(\".\", \"_\")\n",
    "        assert len(animal_groups) == 2, f\"You can't use the PLS of '{pls_experiment}' for selecting the regions to plot because '{group_folder}' has too many groups ({len(animal_groups)})\"\n",
    "        pls_file = f\"pls_{animal_groups[0].marker}_{NORMALIZATION}_salient_regions_above_{pls_threshold}.csv\".lower()\n",
    "        regions_to_plot_pls_csv = os.path.abspath(os.path.join(DATA_ROOT, os.pardir, pls_experiment, \"BraiAn_output\", group_folder, pls_file))\n",
    "        assert os.path.isfile(regions_to_plot_pls_csv), f\"Could not find the file '{regions_to_plot_pls_csv}'\"\n",
    "        AllenBrain.select_from_csv(regions_to_plot_pls_csv, key=\"acronym\")\n",
    "    case s if s.startswith(\"depth\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            depth = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'depth' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        AllenBrain.select_at_depth(depth)\n",
    "    case s if s.startswith(\"structural level\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            level = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'structural level' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        AllenBrain.select_at_structural_level(level)\n",
    "    case _:\n",
    "        raise Exception(f\"Invalid value '{REGIONS_TO_PLOT_SELECTION_METHOD}' for REGIONS_TO_PLOT_SELECTION_METHOD\")\n",
    "regions_to_plot = AllenBrain.get_selected_regions()\n",
    "print(f\"You selected {len(regions_to_plot)} regions to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal_group in animal_groups:\n",
    "    animal_group.remove_smaller_subregions(MIN_AREA, regions_to_plot, AllenBrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATRIX_SAVE_PLOT or MATRIX_SHOW_PLOT or CHORD_SAVE_PLOT or CHORD_SHOW_PLOT:\n",
    "    groups_cross_correlations = [BraiAn.CrossCorrelation(g, regions_to_plot, AllenBrain, NORMALIZATION, MIN_ANIMALS_CROSS_CORRELATION) for g in animal_groups]\n",
    "    \n",
    "    if PLOT_ONLY_REGIONS_PRESENT_IN_ALL_GROUPS:\n",
    "        BraiAn.CrossCorrelation.make_comparable(*groups_cross_correlations)\n",
    "    if not PLOT_REGIONS_WITH_INSUFFICIENT_DATA:\n",
    "        for cc in groups_cross_correlations:\n",
    "            cc.remove_insufficient_regions()\n",
    "    regions_to_plot_selection_method_str = REGIONS_TO_PLOT_SELECTION_METHOD.replace(\".\", \"_\").replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATRIX_SAVE_PLOT or MATRIX_SHOW_PLOT:\n",
    "    for group, cc in zip(animal_groups, groups_cross_correlations):\n",
    "        title = f\"{group.name} Pearson cross correlation matrix (n = {group.n})\"\n",
    "        fig = cc.plot(\n",
    "                title=title,\n",
    "                cell_height=MATRIX_CELL_HEIGHT, min_plot_height=MATRIX_MIN_PLOT_HEIGHT,\n",
    "                star_size=MATRIX_STAR_SIZE, aspect_ratio=MATRIX_CELL_RATIO)\n",
    "        if MATRIX_SAVE_PLOT:\n",
    "            plot_filename = f\"correlation_matrix_min{MIN_ANIMALS_CROSS_CORRELATION}_{group.name}_{group.marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "            plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "            match SAVED_PLOT_EXTENSION.lower():\n",
    "                case \".html\":\n",
    "                    fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "                case _:\n",
    "                    fig.write_image(plot_filepath)\n",
    "        if MATRIX_SHOW_PLOT:\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_str = str(NETWORK_P_CUTOFF).replace(\".\", \"_\")\n",
    "r_str = str(NETWORK_R_CUTOFF).replace(\".\", \"_\")\n",
    "for animal_group, cc in zip(animal_groups, groups_cross_correlations):\n",
    "    connectome = BraiAn.FunctionalConnectome(cc,\n",
    "                                         p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                         negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=True, weighted=False)\n",
    "    title = f\"{animal_group.name} connectomics graph from Pearson correlation (n = {animal_group.n}, {'|r|' if NETWORK_USE_NEGATIVE_LINKS else 'r'} >= {NETWORK_R_CUTOFF}, p <= {NETWORK_P_CUTOFF})\"\n",
    "    fig = BraiAn.draw_chord_plot(connectome,\n",
    "                                AllenBrain=AllenBrain,\n",
    "                                ideograms_arc_index=50,\n",
    "                                title=title,\n",
    "                                size=CHORD_PLOT_SIZE,\n",
    "                                no_background=CHORD_NO_BACKGROUND,\n",
    "                                regions_size=CHORD_REGIONS_SIZE,\n",
    "                                regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "                                max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "                                use_weighted_edge_widths=CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "                                colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "                                colorscale=CHORD_COLORSCALE,\n",
    "                                colorscale_min=CHORD_COLORSCALE_MIN,\n",
    "    )\n",
    "    fig.show()\n",
    "    # filename = f\"chord_plot_min{MIN_ANIMALS_CROSS_CORRELATION}_p{p_str}_r{r_str}_{animal_group.name.lower()}_{animal_groups[0].marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}.html\"\n",
    "    # fig.write_html(filename.lower(), config=dict(toImageButtonOptions=dict(format=\"svg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def participation_coefficient(G, vc):\n",
    "    n = G.vcount()\n",
    "    neighborhood = G.neighborhood()\n",
    "    neighborhood_size = G.neighborhood_size()\n",
    "    clusters = [set(cluster) for cluster in vc]\n",
    "    res = np.full(n, 0, dtype=float)\n",
    "    for v in range(n):\n",
    "        k_i = neighborhood_size[v]\n",
    "        res_v = 0\n",
    "        v_neighborhood = set(neighborhood[v])\n",
    "        for cluster in clusters:\n",
    "            # in-cluster neighborhood size\n",
    "            k_is = k_i - len(v_neighborhood - cluster)\n",
    "            res_v += (k_is/k_i)**2\n",
    "        res[v] = 1 - res_v\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def draw_nodes(G, layout, node_size, AllenBrain):\n",
    "    colours = AllenBrain.get_region_colours()\n",
    "    nodes_colour = []\n",
    "    outlines_colour = []\n",
    "    for v in G.vs:\n",
    "        if v.degree() > 0:\n",
    "            # node_colour = DEFAULT_PLOTLY_COLORS[v[\"cluster\"]] if \"cluster\" in v.attribute_names() else colours[v[\"name\"]]\n",
    "            # outline_colour = node_colour # '#FFFFFF'\n",
    "            outline_colour= DEFAULT_PLOTLY_COLORS[v[\"cluster\"] % len(DEFAULT_PLOTLY_COLORS)]\n",
    "            node_colour = colours[v[\"name\"]]\n",
    "            # node_colour = participations[v.index]\n",
    "        elif v[\"is_undefined\"]:\n",
    "            outline_colour = 'rgb(140,140,140)'\n",
    "            node_colour = '#A0A0A0'\n",
    "        else:\n",
    "            outline_colour = 'rgb(150,150,150)'\n",
    "            node_colour = '#CCCCCC'\n",
    "        nodes_colour.append(node_colour)\n",
    "        outlines_colour.append(outline_colour)\n",
    "\n",
    "    nodes_trace = go.Scatter(\n",
    "        x=[coord[0] for coord in layout.coords],\n",
    "        y=[coord[1] for coord in layout.coords],\n",
    "        mode=\"markers\",\n",
    "        name=\"\",\n",
    "        marker=dict(symbol=\"circle\",\n",
    "                    size=node_size,\n",
    "                    color=nodes_colour,\n",
    "                    line=dict(color=outlines_colour, width=6)), #0.5)),\n",
    "        customdata = np.stack((\n",
    "                        G.vs[\"name\"],\n",
    "                        [AllenBrain.full_name[acronym] for acronym in G.vs[\"name\"]],\n",
    "                        G.vs[\"upper_region\"],\n",
    "                        [AllenBrain.full_name[acronym] for acronym in G.vs[\"upper_region\"]],\n",
    "                        G.vs.degree()),\n",
    "                    axis=-1),\n",
    "        hovertemplate=\n",
    "            \"Region: <b>%{customdata[0]}</b><br>\" +\n",
    "            \"<i>%{customdata[1]}</i><br>\" +\n",
    "            \"Major Division: %{customdata[2]} (%{customdata[3]})<br>\" +\n",
    "            \"Degree: %{customdata[4]}\" +\n",
    "            \"<extra></extra>\",\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    return nodes_trace\n",
    "\n",
    "def add_participation_coefficient(nodes_trace, G, vc):\n",
    "    participations = participation_coefficient(G, vc)\n",
    "    nodes_trace.marker.color = list(participations)\n",
    "    nodes_trace.marker.colorscale=\"Plasma\"\n",
    "    nodes_trace.marker.showscale = True\n",
    "    nodes_trace.customdata = np.hstack((nodes_trace.customdata, np.expand_dims(participations, 1)))\n",
    "    nodes_trace.hovertemplate = nodes_trace.hovertemplate + \"<br>Participation coefficient: %{customdata[5]}\"\n",
    "    return\n",
    "\n",
    "def draw_edges(G, layout, width):\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    for e in G.es:\n",
    "        x0, y0 = layout.coords[e.source]\n",
    "        x1, y1 = layout.coords[e.target]\n",
    "        edge_x.append(x0)\n",
    "        edge_x.append(x1)\n",
    "        edge_x.append(None)\n",
    "        edge_y.append(y0)\n",
    "        edge_y.append(y1)\n",
    "        edge_y.append(None)\n",
    "\n",
    "    edges_trace = go.Scatter(\n",
    "        x=edge_x, y=edge_y,\n",
    "        line=dict(width=width, color=\"#888\"),\n",
    "        hoverinfo=\"none\",\n",
    "        mode=\"lines\",\n",
    "        showlegend=False)\n",
    "    \n",
    "    return edges_trace\n",
    "\n",
    "def cluster_graph(G, vc):\n",
    "    for i,cluster in enumerate(vc):\n",
    "        for node in cluster:\n",
    "            G.vs[node][\"cluster\"] = i\n",
    "    return\n",
    "\n",
    "no_axis = dict(showline=False, # hide axis line, grid, ticklabels and  title\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=\"\"\n",
    "          )\n",
    "\n",
    "for animal_group, cc in zip(animal_groups, groups_cross_correlations):\n",
    "    connectome = BraiAn.FunctionalConnectome(cc,\n",
    "                                        p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                        negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=NETWORK_USE_ISOLATED_VERTICES, weighted=False)\n",
    "    # https://doi.org/10.1109/TKDE.2007.190689\n",
    "    # Graphs with up to fifty vertices should be fine, graphs with a couple of hundred vertices might be possible. \n",
    "    # vc = connectome.G.community_optimal_modularity() # crashes on my pc with summary structure's Graph\n",
    "    vc = connectome.G.community_fastgreedy().as_clustering() # more here: https://python.igraph.org/en/latest/api/igraph.Graph.html#community_fastgreedy\n",
    "    cluster_graph(connectome.G, vc)\n",
    "    # graph_layout = connectome.G.layout_kamada_kawai()             # 1st best\n",
    "    graph_layout = connectome.G.layout_fruchterman_reingold()     # 2nd best\n",
    "    # graph_layout = connectome.G.layout_graphopt()                 # 3rd best\n",
    "    # graph_layout = connectome.G.layout_davidson_harel()           # 4th best\n",
    "    # graph_layout = connectome.G.layout_mds()                      # 5th best\n",
    "    nodes_trace = draw_nodes(connectome.G, graph_layout, 15, AllenBrain)\n",
    "    add_participation_coefficient(nodes_trace, connectome.G, vc)\n",
    "    edges_trace = draw_edges(connectome.G, graph_layout, 2)\n",
    "    title = f\"{animal_group.name} connectomics graph from Pearson correlation (n = {animal_group.n}, {'|r|' if NETWORK_USE_NEGATIVE_LINKS else 'r'} >= {NETWORK_R_CUTOFF}, p <= {NETWORK_P_CUTOFF})\"\n",
    "    fig = go.Figure([edges_trace, nodes_trace],\n",
    "                    layout=dict(\n",
    "                        width=1000, height=1000,\n",
    "                        title=title,\n",
    "                        xaxis=no_axis,\n",
    "                        yaxis=no_axis,\n",
    "                        paper_bgcolor='rgba(255,255,255,255)',\n",
    "                        plot_bgcolor='rgba(0,0,0,0)'\n",
    "              ))\n",
    "    fig.show()\n",
    "    filename = f\"network_min{MIN_ANIMALS_CROSS_CORRELATION}_p{p_str}_r{r_str}_{animal_group.name.lower()}_{animal_groups[0].marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}.html\"\n",
    "    fig.write_html(filename.lower(), config=dict(toImageButtonOptions=dict(format=\"svg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cc in groups_cross_correlations:\n",
    "    fig = cc.plot(\n",
    "        title=title,\n",
    "        cell_height=MATRIX_CELL_HEIGHT, min_plot_height=MATRIX_MIN_PLOT_HEIGHT,\n",
    "        star_size=MATRIX_STAR_SIZE, aspect_ratio=MATRIX_CELL_RATIO)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = connectome.G.community_optimal_modularity()\n",
    "vc.modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectome = BraiAn.FunctionalConnectome(groups_cross_correlations[1],\n",
    "                                         p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                         negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=NETWORK_USE_ISOLATED_VERTICES, weighted=False)\n",
    "sorted(list(zip(connectome.G.degree(), connectome.G.vs[\"name\"])), key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "connectome_w = BraiAn.FunctionalConnectome(groups_cross_correlations[i],\n",
    "                                         p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                         negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=NETWORK_USE_ISOLATED_VERTICES, weighted=False)\n",
    "connectome = BraiAn.FunctionalConnectome(groups_cross_correlations[i],\n",
    "                                         p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                         negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=NETWORK_USE_ISOLATED_VERTICES, weighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.asarray(connectome_w.G.strength(weights=connectome_w.G.es[\"weight\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectome.G.vs[0].betweenness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def centrality_barplot(G: ig.Graph, centrality_fun, n=20, name=\"\", yaxis=\"y1\", offsetgroup=1, **kwargs):\n",
    "    sorted_by_centrality = sorted(G.vs.indices, key=lambda i: centrality_fun(G, i, **kwargs), reverse=True)\n",
    "    selected_regions = G.vs[sorted_by_centrality[:n]]\n",
    "    return go.Bar(\n",
    "        x=selected_regions[\"name\"],\n",
    "        y=centrality_fun(G, selected_regions, **kwargs),\n",
    "        name=name,\n",
    "        yaxis=yaxis,\n",
    "        offsetgroup=offsetgroup\n",
    "    )\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        centrality_barplot(connectome.G, ig.Graph.degree, n=20, name=\"Degree\", mode=\"all\", loops=False, yaxis=\"y1\", offsetgroup=1),\n",
    "        centrality_barplot(connectome.G, ig.Graph.pagerank, n=20, name=\"PageRank\", yaxis=\"y2\", offsetgroup=2),\n",
    "        centrality_barplot(connectome.G, ig.Graph.betweenness, n=20, name=\"Betweenness\", yaxis=\"y3\", offsetgroup=3),\n",
    "#        centrality_barplot(connectome.G, ig.Graph.closeness, n=20, name=\"Closeness\", yaxis=\"y4\", offsetgroup=4), # closeness makes little to no sense to be used in a graph with isolated vertices\n",
    "        centrality_barplot(connectome.G, ig.Graph.harmonic_centrality, n=20, name=\"Harmonic\", yaxis=\"y2\", offsetgroup=5)\n",
    "    ],\n",
    "    layout=dict(\n",
    "        title=\"top 20 ranked regions\",\n",
    "        yaxis=dict(\n",
    "            title=\"Degree\",\n",
    "            side=\"left\",\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title=\"PageRank\",\n",
    "            side=\"right\",\n",
    "            overlaying=\"y\"\n",
    "        ),\n",
    "        yaxis3=dict(\n",
    "            title=\"Betweenness\",\n",
    "            side=\"left\",\n",
    "            overlaying=\"y\",\n",
    "            #autoshift=False, shift=-100, anchor=\"free\"\n",
    "        ),\n",
    "        yaxis4=dict(\n",
    "            title=\"Closeness\",\n",
    "            side=\"right\",\n",
    "            overlaying=\"y\",\n",
    "            #autoshift=True, anchor=\"free\"\n",
    "        ),\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def get_ranks(G, centrality_fun, **kwargs):\n",
    "    centrality_scores = np.flip(np.sort(np.nan_to_num(centrality_fun(G, **kwargs), copy=False, nan=0.0)))\n",
    "    _, unique_ranks = np.unique(centrality_scores, return_index=True) # returns indices of the unique centrality scores (in ascending order)\n",
    "    ranks_repetitions = unique_ranks[:-1]-unique_ranks[1:]\n",
    "    ranks_repetitions = np.insert(ranks_repetitions, 0, len(centrality_scores)-unique_ranks[0])\n",
    "    ranks = np.repeat(unique_ranks, ranks_repetitions)\n",
    "    return centrality_scores, np.flip(ranks)\n",
    "\n",
    "def centrality_barplot(G: ig.Graph, centrality_fun, name=\"\", yaxis=\"y1\", offsetgroup=1, **kwargs):\n",
    "    sorted_by_centrality = sorted(G.vs, key=lambda v: centrality_fun(G, v.index, **kwargs), reverse=True)\n",
    "    scores, ranks = get_ranks(connectome.G, centrality_fun, **kwargs)\n",
    "    return go.Bar(\n",
    "        x=[v[\"upper_region\"] for v in sorted_by_centrality],\n",
    "        # y=1/(ranks+1),\n",
    "        y=1/np.sqrt(ranks+1),\n",
    "        hovertext=[f\"Region: {v['name']}<br>{name}: {centrality_fun(G, v, **kwargs):.5f}\" for v in sorted_by_centrality],\n",
    "        name=name,\n",
    "        yaxis=yaxis,\n",
    "        offsetgroup=offsetgroup\n",
    "    )\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        centrality_barplot(connectome.G, ig.Graph.degree, loops=False, offsetgroup=1, name=\"Degree\", mode=\"all\"),\n",
    "        centrality_barplot(connectome.G, ig.Graph.pagerank, name=\"PageRank\", offsetgroup=2),\n",
    "        centrality_barplot(connectome.G, ig.Graph.betweenness, name=\"Betweenness\", offsetgroup=3),\n",
    "#        centrality_barplot(connectome.G, ig.Graph.closeness, name=\"Closeness\", offsetgroup=4), # closeness makes little to no sense to be used in a graph with isolated vertices\n",
    "        centrality_barplot(connectome.G, ig.Graph.harmonic_centrality, name=\"Harmonic\", offsetgroup=5)\n",
    "    ],\n",
    "    layout=dict(\n",
    "        title=\"Regions ranks with different metrics (grouped by major divisions)\",\n",
    "        yaxis=dict(\n",
    "            title=\"Importance Score\",\n",
    "            side=\"left\",\n",
    "        ),\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go.Figure(\n",
    "    [go.Histogram(\n",
    "        x=connectome.G.degree(),\n",
    "        xbins=dict(start=0, size=2,)\n",
    "    )],\n",
    "#    layout=dict(bargap=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "\n",
    "def path_length(G: ig.Graph, unreachable_nodes=True):\n",
    "    if G.is_weighted():\n",
    "        ds = np.asarray(G.distances(weights=np.abs(G.es[\"weight\"])), dtype=float)\n",
    "    else:\n",
    "        ds = np.asarray(G.distances(), dtype=float)\n",
    "    if unreachable_nodes:\n",
    "        ds[ds == np.inf] = 0\n",
    "        N = G.vcount()\n",
    "        return ds.sum(axis=0) / (N-1)\n",
    "    else:\n",
    "        ds[ds == np.inf] = np.nan\n",
    "        Ns = (~np.isnan(ds)).sum(axis=0, dtype=float)\n",
    "        den = Ns - 1\n",
    "        den[den == 0] = np.nan\n",
    "        return np.nansum(ds, axis=0) / den\n",
    "\n",
    "def average_path_length(G: ig.Graph, unreachable_nodes=True):\n",
    "    # if unreachable_nodes=False, it's equal to igraph.Graph.average_path_length(unconn=True)\n",
    "    if G.is_weighted():\n",
    "        ds = np.asarray(G.distances(weights=np.abs(G.es[\"weight\"])), dtype=float)\n",
    "    else:\n",
    "        ds = np.asarray(G.distances(), dtype=float)\n",
    "    if unreachable_nodes:\n",
    "        ds[ds == np.inf] = 0\n",
    "        N = G.vcount()\n",
    "        return ds.sum() / (N * (N - 1))\n",
    "    else:\n",
    "        ds = ds[ds != np.inf]\n",
    "        return ds.sum() / (len(ds) - G.vcount())\n",
    "\n",
    "# import networkx as nx\n",
    "\n",
    "# Gnx = nx.Graph([])\n",
    "# Gnx.add_node(1)\n",
    "# nx.global_efficiency(Gnx) # <- returns 0\n",
    "def nodal_efficiency(G: ig.Graph):\n",
    "    # https://en.wikipedia.org/wiki/Efficiency_(network_science)\n",
    "    N = G.vcount()\n",
    "    if N == 0:\n",
    "        raise ValueError(\"Empty graph\")\n",
    "    elif N == 1:\n",
    "#        return np.full(N, 1, dtype=float)\n",
    "        return np.full(N, 0, dtype=float)\n",
    "    if G.is_weighted():\n",
    "        ws = np.abs(1.0 / np.asarray(G.es[\"weight\"], dtype=float))\n",
    "        ds = np.asarray(G.distances(weights=ws), dtype=float)\n",
    "    else:\n",
    "        ds = np.asarray(G.distances(), dtype=float)\n",
    "    np.fill_diagonal(ds, np.NaN)\n",
    "    efficiency = 1 / ds\n",
    "    np.fill_diagonal(efficiency, 0)\n",
    "    ne = np.apply_along_axis(sum, 0, efficiency) / (N-1)\n",
    "    return ne\n",
    "\n",
    "def global_efficiency(G):\n",
    "    if G.vcount() == 0:\n",
    "        return np.nan\n",
    "    return nodal_efficiency(G).mean()\n",
    "\n",
    "def local_efficiency(G, zero_degree=True):\n",
    "    local_efficiency_i = []\n",
    "    for i in range(G.vcount()):\n",
    "        G_i = G.induced_subgraph(G.neighbors(i), \"create_from_scratch\")\n",
    "        global_efficiency_i = global_efficiency(G_i)\n",
    "        local_efficiency_i.append(global_efficiency_i)\n",
    "    if zero_degree:\n",
    "        return np.nansum(np.asarray(local_efficiency_i)) / len(local_efficiency_i)\n",
    "    else:\n",
    "        return np.nanmean(np.asarray(local_efficiency_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(G: ig.Graph):\n",
    "    print(f\"\"\"\n",
    "    INFO:\n",
    "        graph type: {'Weighted' if G.is_weighted() else 'Not weighted'}\n",
    "        #regions: {G.vcount()}\n",
    "        #connected regions: {len([d for d in G.degree() if d > 0])}\n",
    "        Max degree: {G.maxdegree()}\n",
    "    SEGREGATION:\n",
    "        Cluster coefficient: {G.transitivity_undirected()}\n",
    "        Mean local cluster coefficient (d>=2): {np.nanmean(G.transitivity_local_undirected())}\n",
    "        Mean local cluster coefficient (all): {np.nansum(G.transitivity_local_undirected()) / G.vcount()}\n",
    "        Local efficiency (d>=1): {local_efficiency(G, zero_degree=False)}\n",
    "        Local efficiency (all): {local_efficiency(G, zero_degree=True)}\n",
    "    INTEGRATION_\n",
    "        Global efficiency: {global_efficiency(G)}\n",
    "        Avg path length (∞ -> 0): {path_length(G, unreachable_nodes=True).mean()}\n",
    "        Avg path length (no ∞): {G.average_path_length(unconn=True)}\n",
    "        Median [characteristic] path lengh (∞ -> 0): {np.nanmedian(path_length(G, unreachable_nodes=True))}\n",
    "        Median [characteristic] path lengh (no ∞): {np.nanmedian(path_length(G, unreachable_nodes=False))}\n",
    "    \"\"\")\n",
    "\n",
    "print_stats(connectome.G)\n",
    "print_stats(connectome_w.G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_w_rewired = connectome_w.G.copy()\n",
    "G_w_rewired.rewire(mode=\"loops\") \n",
    "G_w_rewired.es[\"weight\"] = connectome_w.G.es[\"weight\"]\n",
    "print_stats(G_w_rewired)\n",
    "\n",
    "G_rewired = connectome.G.copy()\n",
    "#G_rewired.rewire(mode=\"simple\") # does not create/destroy loop edges. If you allow it, you may change the degrees\n",
    "G_rewired.rewire(mode=\"loops\")\n",
    "print_stats(G_rewired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"{animal_groups[i].name} connectomics graph from Pearson correlation (n = {animal_groups[i].n}, {'|r|' if NETWORK_USE_NEGATIVE_LINKS else 'r'} >= {NETWORK_R_CUTOFF}, p <= {NETWORK_P_CUTOFF})\"\n",
    "fig = BraiAn.draw_chord_plot(connectome,\n",
    "                            AllenBrain=AllenBrain,\n",
    "                            ideograms_arc_index=50,\n",
    "                            title=title,\n",
    "                            size=CHORD_PLOT_SIZE,\n",
    "                            no_background=CHORD_NO_BACKGROUND,\n",
    "                            regions_size=CHORD_REGIONS_SIZE,\n",
    "                            regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "                            max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "                            use_weighted_edge_widths=CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "                            colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "                            colorscale=CHORD_COLORSCALE,\n",
    "                            colorscale_min=CHORD_COLORSCALE_MIN,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"{animal_groups[i].name} connectomics graph from Pearson correlation (n = {animal_groups[i].n}, {'|r|' if NETWORK_USE_NEGATIVE_LINKS else 'r'} >= {NETWORK_R_CUTOFF}, p <= {NETWORK_P_CUTOFF})\"\n",
    "fig = BraiAn.draw_chord_plot(connectome_w,\n",
    "                            AllenBrain=AllenBrain,\n",
    "                            ideograms_arc_index=50,\n",
    "                            title=title,\n",
    "                            size=CHORD_PLOT_SIZE,\n",
    "                            no_background=CHORD_NO_BACKGROUND,\n",
    "                            regions_size=CHORD_REGIONS_SIZE,\n",
    "                            regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "                            max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "                            use_weighted_edge_widths=CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "                            colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "                            colorscale=CHORD_COLORSCALE,\n",
    "                            colorscale_min=CHORD_COLORSCALE_MIN,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(BraiAn.connectome.functional)\n",
    "importlib.reload(BraiAn.plot)\n",
    "importlib.reload(BraiAn.plot_chord)\n",
    "importlib.reload(BraiAn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
