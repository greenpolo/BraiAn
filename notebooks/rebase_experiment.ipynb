{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot groups' analysis\n",
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIRECTORY = \"experiment\"\n",
    "PROOF_DIRECTORY = \"proof\"\n",
    "REBASED_DIRECTORY = \"rebased_on_mjd\"\n",
    "USE_LOCAL_DATA = False                                        # if False, it tries to read the data on the laboratory's server\n",
    "IS_COLLABORATION_PROJ = True\n",
    "import os\n",
    "COLLABORATION_DIRECTORY = os.path.join(\"Mathias Schmidt\", \"soumnya\")\n",
    "\n",
    "# ###################################### LOCAL DIRECTORIES ######################################\n",
    "EXPERIMENT_ROOT = f\"../data/experiments/soumnya/{EXPERIMENT_DIRECTORY}/\"\n",
    "PROOF_ROOT      = f\"../data/experiments/soumnya/{PROOF_DIRECTORY}/\"\n",
    "REBASED_ROOT    = f\"../data/experiments/soumnya/{REBASED_DIRECTORY}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### GENERAL OPTIONS #######################################\n",
    "BRANCHES_TO_EXCLUDE = [\"retina\", \"VS\", \"grv\", \"fiber tracts\", \"CB\"]\n",
    "USE_LITERATURE_REUNIENS = True                                  # add a 'REtot' region, merging the following regions: 'PR', 'RE', 'Xi', 'RH'\n",
    "\n",
    "# ###################################### DATA LOAD OPTIONS ######################################\n",
    "AREA_KEY = \"Area um^2\"\n",
    "TRACER_KEY = \"Num AF647\"\n",
    "MARKER = \"CFos\"\n",
    "REBASE_REGIONS_ON = \"major divisions\"                           # \"major divisions\" or \"summary structures\"\n",
    "\n",
    "# ###################################### DATA SAVE OPTIONS ######################################\n",
    "ANIMAL_BRAIN_MODE = \"sum\"                                       # available options are: 'sum', 'mean'/'avg', 'std', 'variation'/'cvar'\n",
    "SAVE_ANIMALS = True\n",
    "SAVE_GROUPS = True\n",
    "\n",
    "# ###############################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script's code\n",
    "run all cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "project_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(project_path)\n",
    "import BraiAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_LOCAL_DATA:\n",
    "    match sys.platform:\n",
    "        case \"darwin\":\n",
    "            mnt_point = \"/Volumes/Ricerca/\"\n",
    "            \n",
    "        case \"linux\":\n",
    "            mnt_point = \"/run/user/1000/gvfs/smb-share:server=ich.techosp.it,share=ricerca/\"\n",
    "        case \"win32\":\n",
    "            mnt_point = \"\\\\\\\\ich.techosp.it\\\\Ricerca\\\\\"\n",
    "        case _:\n",
    "            raise Exception(f\"Can't find the 'Ricerca' folder in the server for '{sys.platform}' operative system. Please report the developer (Carlo)!\")\n",
    "    if not os.path.isdir(mnt_point):\n",
    "        raise Exception(f\"Could not read '{mnt_point}'. Please be sure you are connected to the server.\")\n",
    "    if IS_COLLABORATION_PROJ:\n",
    "        EXPERIMENT_ROOT = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", COLLABORATION_DIRECTORY, \"data\", EXPERIMENT_DIRECTORY)\n",
    "        PROOF_ROOT      = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", COLLABORATION_DIRECTORY, \"data\", PROOF_DIRECTORY)\n",
    "        REBASED_ROOT    = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", COLLABORATION_DIRECTORY, \"data\", REBASED_DIRECTORY)\n",
    "    else:\n",
    "        EXPERIMENT_ROOT = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"projects\", \"data\", EXPERIMENT_DIRECTORY)\n",
    "        PROOF_ROOT      = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"projects\", \"data\", PROOF_DIRECTORY)\n",
    "        REBASED_ROOT    = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"projects\", \"data\", REBASED_DIRECTORY)\n",
    "\n",
    "proof_input_path        = os.path.join(PROOF_ROOT, \"QuPath_output\")\n",
    "experiment_input_path   = os.path.join(EXPERIMENT_ROOT, \"QuPath_output\")\n",
    "rebased_output_path     = os.path.join(REBASED_ROOT, \"QuPath_output\")\n",
    "\n",
    "assert not os.path.isdir(rebased_output_path), \"rebased directory already exists!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "# StructureGraph id=1\n",
    "path_to_allen_json = os.path.join(project_path, \"data\", \"AllenMouseBrainOntology.json\")\n",
    "AllenBrain = BraiAn.AllenBrainHierarchy(path_to_allen_json, BRANCHES_TO_EXCLUDE, use_literature_reuniens=USE_LITERATURE_REUNIENS)\n",
    "match REBASE_REGIONS_ON:\n",
    "    case \"major divisions\":\n",
    "        AllenBrain.select_regions(BraiAn.MAJOR_DIVISIONS)\n",
    "    case \"summary structures\":\n",
    "        path_to_summary_structures = os.path.join(project_path, \"data\", \"AllenSummaryStructures.csv\")\n",
    "        AllenBrain.select_from_csv(path_to_summary_structures, include_nre_tot=USE_LITERATURE_REUNIENS)\n",
    "    case _:\n",
    "        raise Exception(f\"Invalid value '{REBASE_REGIONS_ON}' for rebase_regions_on\")\n",
    "        \n",
    "selected_regions = AllenBrain.get_selected_regions()\n",
    "print(f\"You selected {len(selected_regions)} regions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_animal_dirs = [d for d in os.listdir(proof_input_path) if os.path.isdir(os.path.join(proof_input_path, d)) and not d.startswith(\".\")]\n",
    "proof_slices = [BraiAn.SlicedBrain(animal_dir,\n",
    "                                    os.path.join(proof_input_path, animal_dir),\n",
    "                                    AllenBrain,\n",
    "                                    AREA_KEY,\n",
    "                                    TRACER_KEY,\n",
    "                                    MARKER,\n",
    "                                    area_units=\"µm2\")\n",
    "                    for animal_dir in proof_animal_dirs]\n",
    "print(f\"Imported all brain slices from {str(len(proof_animal_dirs))} animals of 'proof'.\")\n",
    "\n",
    "experiment_animal_dirs = [d for d in os.listdir(experiment_input_path) if os.path.isdir(os.path.join(experiment_input_path, d)) and not d.startswith(\".\")]\n",
    "experiment_slices = [BraiAn.SlicedBrain(animal_dir,\n",
    "                                    os.path.join(experiment_input_path, animal_dir),\n",
    "                                    AllenBrain,\n",
    "                                    AREA_KEY,\n",
    "                                    TRACER_KEY,\n",
    "                                    MARKER,\n",
    "                                    area_units=\"µm2\")\n",
    "                    for animal_dir in experiment_animal_dirs]\n",
    "print(f\"Imported all brain slices from {str(len(experiment_animal_dirs))} animals of 'experiment'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_experiment = [animal for animal in proof_animal_dirs if animal not in experiment_animal_dirs]\n",
    "missing_in_proof = [animal for animal in experiment_animal_dirs if animal not in proof_animal_dirs]\n",
    "print(f\"Animals missing in 'experiment': {', '.join(missing_in_experiment)}\")\n",
    "print(f\"Animals missing in 'proof': {', '.join(missing_in_proof)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: brains are being written WITH Left/Right discrimination\n",
    "# If you desire to save them without, call AnimalBrain with hemisphere_distinction=False\n",
    "\n",
    "min_slices = 3\n",
    "proof_sum_brains: List[BraiAn.AnimalBrain] = [BraiAn.AnimalBrain(sliced_brain, mode=ANIMAL_BRAIN_MODE, min_slices=min_slices, hemisphere_distinction=False, use_literature_reuniens=USE_LITERATURE_REUNIENS) for sliced_brain in proof_slices]\n",
    "experiment_sum_brains: List[BraiAn.AnimalBrain] = [BraiAn.AnimalBrain(sliced_brain, mode=ANIMAL_BRAIN_MODE, min_slices=min_slices, hemisphere_distinction=False, use_literature_reuniens=USE_LITERATURE_REUNIENS) for sliced_brain in experiment_slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebase_coefficient(proof_brain: BraiAn.AnimalBrain, experiment_brain: BraiAn.AnimalBrain):\n",
    "    assert proof_brain.name == experiment_brain.name, f\"The rebase coefficient can't be computed between two different animals '{proof_brain.name}' and '{experiment_brain.name}'\"\n",
    "    regions_in_both = list(set(proof_brain.data.index).intersection(set(experiment_brain.data.index)))\n",
    "    proof_density       = (     proof_brain.data[MARKER] /       proof_brain.data.area)[regions_in_both].mean()\n",
    "    experiment_density  = (experiment_brain.data[MARKER] /  experiment_brain.data.area)[regions_in_both].mean()\n",
    "    return proof_density / experiment_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_selected_regions = [BraiAn.AnimalBrain.filter_selected_regions(brain, AllenBrain) for brain in proof_sum_brains if brain.name not in missing_in_experiment]\n",
    "proof_selected_regions = [brain for brain in sorted(proof_selected_regions, key=lambda x: x.name)]\n",
    "experiment_selected_regions = [BraiAn.AnimalBrain.filter_selected_regions(brain, AllenBrain) for brain in experiment_sum_brains if brain.name not in missing_in_proof]\n",
    "experiment_selected_regions = [brain for brain in sorted(experiment_selected_regions, key=lambda x: x.name)]\n",
    "\n",
    "coefficients = {}\n",
    "for proof_brain, experiment_brain in zip(proof_selected_regions, experiment_selected_regions):\n",
    "    rebase_coefficient = get_rebase_coefficient(proof_brain, experiment_brain)\n",
    "    coefficients[proof_brain.name] = rebase_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_brain, experiment_brain = proof_selected_regions[0].data, experiment_selected_regions[0].data\n",
    "regions_in_both = list(set(proof_brain.index).intersection(set(experiment_brain.index)))\n",
    "proof_density       = (     proof_brain[MARKER] /       proof_brain.area)[regions_in_both].mean()\n",
    "experiment_density  = (experiment_brain[MARKER] /  experiment_brain.area)[regions_in_both].mean()\n",
    "\n",
    "rebase_coefficient = proof_density / experiment_density\n",
    "rebase_coefficient, rebase_coefficient * experiment_density, proof_density, ((experiment_brain[MARKER] * rebase_coefficient) / experiment_brain.area)[regions_in_both].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "for animal_dir, coefficient in coefficients.items():\n",
    "    experiment_results_dir = os.path.join(experiment_input_path, animal_dir, \"results\")\n",
    "    experiment_regions_to_exclude_dir = os.path.join(experiment_input_path, animal_dir, \"regions_to_exclude\")\n",
    "    output_results_dir = os.path.join(rebased_output_path, animal_dir, \"results\")\n",
    "    os.makedirs(output_results_dir, exist_ok=True)\n",
    "    output_regions_to_exclude_dir = os.path.join(rebased_output_path, animal_dir, \"regions_to_exclude\")\n",
    "    os.makedirs(output_regions_to_exclude_dir, exist_ok=True)\n",
    "    for slice_file in os.listdir(experiment_results_dir):\n",
    "        if not slice_file.endswith(\"_regions.txt\"):\n",
    "            continue\n",
    "        slice_name = slice_file.replace(\"_regions.txt\", \"\")\n",
    "        experiment_slice_results_file = os.path.join(experiment_results_dir, slice_file)\n",
    "        experiment_slice_results = pd.read_csv(experiment_slice_results_file, sep=\"\\t\").drop_duplicates()\n",
    "        experiment_slice_results[TRACER_KEY] *= coefficient # WE REBASE THE SLICE\n",
    "        experiment_slice_results[\"Num Detections\"] *= coefficient\n",
    "  \n",
    "        experiment_slice_regions_to_exclude_file = os.path.join(experiment_regions_to_exclude_dir, f\"{slice_name}_regions_to_exclude.txt\")\n",
    "        output_slice_regions_to_exclude_file = os.path.join(output_regions_to_exclude_dir, f\"{slice_name}_regions_to_exclude.txt\")\n",
    "        shutil.copy2(experiment_slice_regions_to_exclude_file, output_slice_regions_to_exclude_file)\n",
    "        output_slice_results_file = os.path.join(output_results_dir, f\"{slice_name}_regions.txt\")\n",
    "        experiment_slice_results.to_csv(output_slice_results_file, sep=\"\\t\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to think very well what to do with rebase_coefficient. Can we use the rebase coefficient, computed on density, on marker numbers (surely not on area)?\n",
    "# I would say yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(BraiAn.sliced_brain)\n",
    "importlib.reload(BraiAn.animal_brain)\n",
    "importlib.reload(BraiAn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
