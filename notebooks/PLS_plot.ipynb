{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIRECTORY = \"rebased_on_mjd\"             # \"experiment\" or \"proof\" or \"rebased_on_ss\" or \"rebased_on_mjd\"\n",
    "USE_LOCAL_DATA = False                              # if False, it tries to read the data on the laboratory's server\n",
    "# ###################################### LOCAL DIRECTORIES ######################################\n",
    "DATA_ROOT  = f\"../data/experiments/soumnya/{EXPERIMENT_DIRECTORY}\"\n",
    "PLOTS_ROOT = f\"../plots/soumnya/{EXPERIMENT_DIRECTORY}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### GENERAL OPTIONS #######################################\n",
    "BRANCHES_TO_EXCLUDE = [\"retina\", \"VS\", \"grv\", \"fiber tracts\", \"CB\"]\n",
    "NORMALIZATION = \"Density\"                           # call get_normalization_methods() on a AnimalGroup object to know its available normalization methods\n",
    "MIN_AREA = 0.0                                      # area in mmÂ². If a region of one animal is smaller, that same region won't be considered in the PLS\n",
    "                                                    # That is because the PLS only considers the brain regions that appears in every animal of the groups\n",
    "REGIONS_TO_PLOT_SELECTION_METHOD = \"summary structures\"         # Available options are: \"summary structures\", \"major divisions\" \"depth <n>\", \"structural level <n>\"\n",
    "                                                    # where <n> is an integer of the depth/level desired\n",
    "SAVED_PLOT_EXTENSION = \".html\"                      # '.html' for interactive plot\n",
    "                                                    # '.svg' for vectorized image\n",
    "                                                    # '.png'/'.jpg'/... for rasterized image\n",
    "\n",
    "# ######################################### PLS OPTIONS #########################################\n",
    "PLS_SALIENCE_THRESHOLD = 1.5                        # Only brain regions with a salience higher than plot_threshold are shown. 2 is the significance threshold.\n",
    "PLS_RANK = 1\n",
    "PLS_NUM_BOOTSTRAP = 5000\n",
    "PLS_NUM_PERMUTATIONS = 5000\n",
    "PLOT_DISTRIBUTION_OF_SINGULAR_VALUES = True\n",
    "\n",
    "# ##################################### SALIENCE SCORE PLOT #####################################\n",
    "SHOW_SALIENCE_SCORES_PLOT = True\n",
    "SAVE_SALIENCE_SCORES_PLOT = True\n",
    "SALIENCE_TITLE_TEXT_SIZE = 40\n",
    "SALIENCE_AXIS_TEXT_SIZE = 22\n",
    "SALIENCE_USE_ACRONYMS = True\n",
    "SALIENCE_USE_ACRONYMS_IN_MJD = False\n",
    "SALIENCE_MJD_BG_OPACITY = 0.3\n",
    "SALIENCE_WIDTH = 1000\n",
    "SALIENCE_BARHEIGHT = 30\n",
    "\n",
    "# ########################################## PIE CHART ##########################################\n",
    "PIE_SAVE_PLOT = True\n",
    "PIE_SHOW_PLOT = False\n",
    "PIE_USE_ACRONYMS = False\n",
    "PIE_HOLE = 0.4                                          # a value between 0 (no hole) and 1 (just a hole, no plot)\n",
    "PIE_TEXT_SIZE = 25\n",
    "\n",
    "# ########################################## BAR PLOT ###########################################\n",
    "BAR_SAVE_PLOT = True\n",
    "BAR_SHOW_PLOT = False\n",
    "BAR_ANIMAL_SIZE = 8\n",
    "BAR_TITLE_TEXT_SIZE = 40\n",
    "BAR_AXIS_TEXT_SIZE = 22\n",
    "BAR_HEIGHT = 30\n",
    "BAR_WIDTH = 1_500\n",
    "BAR_TITLE = \"\"\n",
    "BAR_USE_ACRONYMS = True\n",
    "\n",
    "# ###################################### CORRELATION MATRIX #####################################\n",
    "MATRIX_SAVE_PLOT = False\n",
    "MATRIX_SHOW_PLOT = False\n",
    "MATRIX_CELL_HEIGHT = 5\n",
    "MATRIX_CELL_RATIO = 1 # 3/2\n",
    "MATRIX_MIN_PLOT_HEIGHT = 500\n",
    "\n",
    "# ######################################## CORR. NETWORK ########################################\n",
    "NETWORK_P_CUTOFF = 0.05                                 # 1 if you don't want to filter by p-value\n",
    "NETWORK_R_CUTOFF = 0.8\n",
    "NETWORK_USE_NEGATIVE_LINKS = True\n",
    "NETWORK_USE_ISOLATED_VERTICES = True\n",
    "\n",
    "# ######################################## CHORD DIAGRAM ########################################\n",
    "CHORD_SAVE_PLOT = False\n",
    "CHORD_SHOW_PLOT = True\n",
    "CHORD_PLOT_SIZE = 1200\n",
    "CHORD_NO_BACKGROUND = False\n",
    "CHORD_REGIONS_SIZE = 15\n",
    "CHORD_REGIONS_FONT_SIZE = 10\n",
    "CHORD_MAX_EDGE_WIDTH = 5\n",
    "CHORD_USE_WEIGHTED_EDGE_WIDTHS = True\n",
    "CHORD_USE_COLORSCALE_EDGES = True\n",
    "CHORD_COLORSCALE = \"RdBu_r\"                             # see https://plotly.com/python/builtin-colorscales/\n",
    "CHORD_COLORSCALE_MIN = -1\n",
    "CHORD_BOTTOM_ANNOTATIONS = dict(\n",
    "    annotation1 = \"Dark grey nodes are regions with insufficient data to compute cross correlation\",\n",
    "    annotation2 = \"Light grey nodes are regions with no correlation with others above the threshold\",\n",
    "    annotation3 = \"This is the third annotation\",\n",
    "    # howmany annotations desired with the following format:\n",
    "    # annotations<k> = \"<annotation>\"\n",
    ")\n",
    "# ###############################################################################################\n",
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "from collections import namedtuple\n",
    "GroupInfo = namedtuple(\"GroupInfo\", \"name colour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA FEMALES+MALES - 2 Groups {Stress|Control}\n",
    "# SHILA - 2 Groups {Control|Stress+Resilient}\n",
    "group_1_info = GroupInfo(\n",
    "                name=\"Control\",\n",
    "                colour=DEFAULT_PLOTLY_COLORS[4]\n",
    "            )\n",
    "group_2_info = GroupInfo(\n",
    "                name=\"Stress\",\n",
    "                colour=DEFAULT_PLOTLY_COLORS[5]\n",
    "            )\n",
    "group_folder = \"C-S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1_info = GroupInfo(\n",
    "                name=\"Control (Females)\",\n",
    "                colour=DEFAULT_PLOTLY_COLORS[0]\n",
    "            )\n",
    "group_2_info = GroupInfo(\n",
    "                name=\"Stress (Females)\",\n",
    "                colour=DEFAULT_PLOTLY_COLORS[1]\n",
    "            )\n",
    "group_folder = \"CF-SF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1_info = GroupInfo(\n",
    "                name=\"Control (Males)\",\n",
    "                colour=DEFAULT_PLOTLY_COLORS[2]\n",
    "            )\n",
    "group_2_info = GroupInfo(\n",
    "                name=\"Stress (Males)\",\n",
    "                colour=DEFAULT_PLOTLY_COLORS[3]\n",
    "            )\n",
    "group_folder = \"CM-SM\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "project_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(project_path)\n",
    "import BraiAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_LOCAL_DATA:\n",
    "    match sys.platform:\n",
    "        case \"darwin\":\n",
    "            mnt_point = \"/Volumes/Ricerca/\"\n",
    "            \n",
    "        case \"linux\":\n",
    "            mnt_point = \"/run/user/1000/gvfs/smb-share:server=ich.techosp.it,share=ricerca/\"\n",
    "        case \"win32\":\n",
    "            mnt_point = \"\\\\\\\\ich.techosp.it\\\\Ricerca\\\\\"\n",
    "        case _:\n",
    "            raise Exception(f\"Can't find the 'Ricerca' folder in the server for '{sys.platform}' operative system. Please report the developer (Carlo)!\")\n",
    "    if not os.path.isdir(mnt_point):\n",
    "        raise Exception(f\"Could not read '{mnt_point}'. Please be sure you are connected to the server.\")\n",
    "    DATA_ROOT  = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", \"Mathias Schmidt\", \"soumnya\", \"data\", EXPERIMENT_DIRECTORY)\n",
    "    PLOTS_ROOT = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", \"Mathias Schmidt\", \"soumnya\", \"results\", EXPERIMENT_DIRECTORY, \"plots\")\n",
    "\n",
    "data_input_path = os.path.join(DATA_ROOT, \"BraiAn_output\")\n",
    "data_output_path = os.path.join(data_input_path, group_folder)\n",
    "plots_output_path = os.path.join(PLOTS_ROOT, group_folder)\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)\n",
    "\n",
    "if not(os.path.exists(plots_output_path)):\n",
    "    os.makedirs(plots_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "# StructureGraph id=1\n",
    "path_to_allen_json = os.path.join(project_path, \"data\", \"AllenMouseBrainOntology.json\")\n",
    "AllenBrain = BraiAn.AllenBrainHierarchy(path_to_allen_json, BRANCHES_TO_EXCLUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match REGIONS_TO_PLOT_SELECTION_METHOD:\n",
    "    case \"summary structures\":\n",
    "        # selects the Summary Strucutures\n",
    "        path_to_summary_structures = os.path.join(project_path, \"data\", \"AllenSummaryStructures.csv\")\n",
    "        AllenBrain.select_from_csv(path_to_summary_structures)\n",
    "    case \"major divisions\":\n",
    "        AllenBrain.select_regions(BraiAn.MAJOR_DIVISIONS)\n",
    "    case s if s.startswith(\"depth\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            depth = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'depth' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        AllenBrain.select_at_depth(depth)\n",
    "    case s if s.startswith(\"structural level\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            level = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'structural level' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        AllenBrain.select_at_structural_level(level)\n",
    "    case _:\n",
    "        raise Exception(f\"Invalid value '{REGIONS_TO_PLOT_SELECTION_METHOD}' for REGIONS_TO_PLOT_SELECTION_METHOD\")\n",
    "selected_regions = AllenBrain.get_selected_regions()\n",
    "print(f\"You selected {len(selected_regions)} regions to do PLS analysis over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = BraiAn.AnimalGroup.from_csv(group_1_info.name, data_input_path, f\"cell_counts_{group_1_info.name}.csv\")\n",
    "group_1.remove_smaller_subregions(MIN_AREA, selected_regions, AllenBrain)\n",
    "group_2 = BraiAn.AnimalGroup.from_csv(group_2_info.name, data_input_path, f\"cell_counts_{group_2_info.name}.csv\")\n",
    "group_2.remove_smaller_subregions(MIN_AREA, selected_regions, AllenBrain)\n",
    "if not group_1.is_comparable(group_2):\n",
    "    raise ImportError(\"Group 1 and Group 2 are not comparable!\\n\\\n",
    "Please check that you're reading two groups that normalized on the same brain regions and on the same marker\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are stored in ```group_1.data``` and ```group_2.data```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Least Squares  \n",
    "\n",
    "The analysis done below is taken from the tutorial written by [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074).  \n",
    "Run the 2 cells below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PLS object\n",
    "pls = BraiAn.PLS(group_1, group_2, selected_regions, NORMALIZATION)\n",
    "\n",
    "# Show the matrix X\n",
    "pls.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the matrix Y\n",
    "pd.get_dummies(pls.y).rename(columns={0: group_2.name, 1: group_1.name})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two matrices printed above (X and Y) illustrate the data on which the PLS is done.  \n",
    "- ```X:``` The rows in this matrix are the mice. The columns in the matrix are the regions selected for analysis. The values in the matrix are the **normalized value of marked cells: in that region relative to the whole brain.** \n",
    "The normalization methods are either:\n",
    "  + Density\n",
    "  + Percentage (on the total number of detected marked cells outside of excluded regions)\n",
    "  + RelativeDensity\n",
    "- ```Y:``` The rows in this matrix are the mice. The columns in the matrix are the 2 groups. **A value in this matrix is 1 if the mice belongs to the specified group**.\n",
    "\n",
    "In brief, PLS analyzes the relationship (correlation) between the columns of ```X``` and ```Y```. In our specific case, there will be 2 important outputs:\n",
    "- **Salience scores**: Each brain region has a salience score. A high salience scores means that the brain region explains much of the correlation between ```X``` and ```Y```.  \n",
    "- **Singular values**: These are the eigenvalues of the correlation matrix $R = Y^TX$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random permutations to see whether we can differentiate signal from noise. \n",
    "Here, we randomly shuffle the group to which a mouse belongs, and calculate the singular values of the permuted dataset.  \n",
    "From [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074):  \n",
    "> The set of all the (permuted) singular values provides a sampling distribution of the singular values under the null hypothesis and, therefore can be used as a null hypothesis test.\n",
    "\n",
    "*Note: running the cell below will take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Randomly permuting singular values {PLS_NUM_PERMUTATIONS} times...\")\n",
    "s,singular_values = pls.randomly_permute_singular_values(PLS_NUM_PERMUTATIONS)\n",
    "# Plot distribution of singular values\n",
    "if PLOT_DISTRIBUTION_OF_SINGULAR_VALUES:\n",
    "    fig = BraiAn.plot_permutation(pls.s[0], singular_values, PLS_NUM_PERMUTATIONS)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate p-value = Probability(experiment | H0)\n",
    "p = (singular_values[:,0] > s[0]).sum() / PLS_NUM_PERMUTATIONS\n",
    "print(\"p-value = \"+str(p))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap to identify stable salience scores\n",
    "\n",
    "Here, we use [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) (= sampling of the mice in the dataset, with replacement) to get an estimate of which salience scores are stable.\n",
    "\n",
    "From [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074):  \n",
    "> When a vector of saliences is considered generalizable and is kept for further analysis, we need to identify its elements that are stable through resampling. In practice, the stability of an element is evaluated by dividing it by its standard error. [...] To estimate the standard errors, we create bootstrap samples which are obtained by sampling with replacement the observations in and (Efron and Tibshirani, 1986). A salience standard error is then estimated as the standard error of the saliences from a large number of these bootstrap samples (say 1000 or 10000). **The ratios are akin to a Z-score, therefore when they are larger than 2 the corresponding saliences are considered significantly stable.**\n",
    "\n",
    "*Note: Running the cell below will take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Bootstrapping salience scores {PLS_NUM_BOOTSTRAP} times...\")\n",
    "u_salience_scores,v_salience_scores = pls.bootstrap_salience_scores(PLS_RANK, PLS_NUM_BOOTSTRAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salient_regions = pls.above_threshold(PLS_SALIENCE_THRESHOLD).reset_index().rename(columns={\"index\":\"acronym\", 0: \"salience_score\"})\n",
    "\n",
    "# save the salient regions in a CSV\n",
    "pls_salience_threshold_str = str(PLS_SALIENCE_THRESHOLD).replace(\".\", \"_\")\n",
    "salient_regions_file = f\"PLS_{group_1.marker}_{NORMALIZATION}_salient_regions_above_{pls_salience_threshold_str}.csv\"\n",
    "BraiAn.save_csv(salient_regions, data_output_path, salient_regions_file.lower(), overwrite=True)\n",
    "\n",
    "# save ALL the regions with salient score\n",
    "pls_filename = f\"PLS_{group_1.marker}_{NORMALIZATION}_salience_scores.csv\"\n",
    "BraiAn.save_csv(v_salience_scores.rename(columns={0:\"salience_score\"}), data_output_path, pls_filename.lower(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PLS salience scores\n",
    "fig = BraiAn.plot_salient_regions(salient_regions, AllenBrain,\n",
    "                                    title=f\"Salient regions (|score| >= {PLS_SALIENCE_THRESHOLD})\",\n",
    "                                    title_size=SALIENCE_TITLE_TEXT_SIZE, axis_size=SALIENCE_AXIS_TEXT_SIZE,\n",
    "                                    use_acronyms=SALIENCE_USE_ACRONYMS, use_acronyms_in_mjd=SALIENCE_USE_ACRONYMS_IN_MJD,\n",
    "                                    mjd_opacity=SALIENCE_MJD_BG_OPACITY,\n",
    "                                    width=SALIENCE_WIDTH, barheight=SALIENCE_BARHEIGHT)\n",
    "\n",
    "if SAVE_SALIENCE_SCORES_PLOT:\n",
    "    if not(os.path.exists(plots_output_path)):\n",
    "        os.mkdir(plots_output_path)\n",
    "    plot_filename = f\"PLS_{group_1.marker}_{NORMALIZATION}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "    plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "    match SAVED_PLOT_EXTENSION.lower():\n",
    "        case \".html\":\n",
    "            fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "        case _:\n",
    "            fig.write_image(plot_filepath)\n",
    "\n",
    "if SHOW_SALIENCE_SCORES_PLOT:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_data = BraiAn.as_prism_data(NORMALIZATION, group_1, group_2, AllenBrain)\n",
    "prism_data = prism_data.loc[salient_regions.acronym.array]\n",
    "prism_file = f\"prism_{group_folder}_{group_1.marker}_{NORMALIZATION}_above_{pls_salience_threshold_str}.csv\"\n",
    "BraiAn.save_csv(prism_data.swaplevel(), data_output_path, prism_file.lower(), sep=\",\", overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = BraiAn.plot_pie(v_salience_scores.index.values, AllenBrain, use_acronyms=PIE_USE_ACRONYMS, hole=PIE_HOLE, line_width=1, text_size=PIE_TEXT_SIZE)\n",
    "regions_to_plot_selection_method_str = REGIONS_TO_PLOT_SELECTION_METHOD.replace(\" \", \"_\")\n",
    "\n",
    "if PIE_SAVE_PLOT:\n",
    "    plot_filename = f\"pls_all_regions_piechart_{group_folder}_{group_1.marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "    plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "    match SAVED_PLOT_EXTENSION.lower():\n",
    "        case \".html\":\n",
    "            fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "        case _:\n",
    "            fig.write_image(plot_filepath)\n",
    "if PIE_SHOW_PLOT:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = BraiAn.plot_pie(salient_regions.acronym.array, AllenBrain, use_acronyms=PIE_USE_ACRONYMS, hole=PIE_HOLE, line_width=1, text_size=PIE_TEXT_SIZE)\n",
    "regions_to_plot_selection_method_str = REGIONS_TO_PLOT_SELECTION_METHOD.replace(\" \", \"_\")\n",
    "\n",
    "if PIE_SAVE_PLOT:\n",
    "    plot_filename = f\"pls_{pls_salience_threshold_str}_piechart_{group_folder}_{group_1.marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "    plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "    match SAVED_PLOT_EXTENSION.lower():\n",
    "        case \".html\":\n",
    "            fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "        case _:\n",
    "            fig.write_image(plot_filepath)\n",
    "if PIE_SHOW_PLOT:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = BraiAn.plot_groups(NORMALIZATION, AllenBrain, group_1, group_2, selected_regions=salient_regions.acronym.array,\n",
    "                            plot_title=BAR_TITLE, title_size=BAR_TITLE_TEXT_SIZE, axis_size=BAR_AXIS_TEXT_SIZE, animal_size=BAR_ANIMAL_SIZE,\n",
    "                            use_acronyms=BAR_USE_ACRONYMS, colors=(group.colour for group in (group_1_info, group_2_info)),\n",
    "                            width=BAR_WIDTH, barheight=BAR_HEIGHT, bargap=0.3, bargroupgap=0.0)\n",
    "\n",
    "if BAR_SAVE_PLOT:\n",
    "    plot_filename = f\"pls_{pls_salience_threshold_str}_barplot_{group_folder}_{group_1.marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "    plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "    match SAVED_PLOT_EXTENSION.lower():\n",
    "        case \".html\":\n",
    "            fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "        case _:\n",
    "            fig.write_image(plot_filepath)\n",
    "if BAR_SHOW_PLOT:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATRIX_SAVE_PLOT or MATRIX_SHOW_PLOT or CHORD_SAVE_PLOT or CHORD_SHOW_PLOT:\n",
    "    groups_cross_correlations = []\n",
    "    for group in (group_1, group_2):\n",
    "        # min_animals=None because it doesn't matter. PLS already removes every region with NaNs.\n",
    "        cc = BraiAn.CrossCorrelation(group, salient_regions.acronym.array, AllenBrain, NORMALIZATION, min_animals=None) \n",
    "        groups_cross_correlations.append(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATRIX_SAVE_PLOT or MATRIX_SHOW_PLOT:\n",
    "    for group, cc in zip((group_1, group_2), groups_cross_correlations):\n",
    "        title = f\"{group.name} Pearson cross correlation matrix (n = {group.n})\"\n",
    "        fig = cc.plot(\n",
    "                title=title,\n",
    "                cell_height=MATRIX_CELL_HEIGHT, min_plot_height=MATRIX_MIN_PLOT_HEIGHT,\n",
    "                aspect_ratio=MATRIX_CELL_RATIO)\n",
    "        if MATRIX_SAVE_PLOT:\n",
    "            plot_filename = f\"pls_{pls_salience_threshold_str}_correlation_matrix_filtered_{group.name}_{group.marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "            plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "            match SAVED_PLOT_EXTENSION.lower():\n",
    "                case \".html\":\n",
    "                    fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "                case _:\n",
    "                    fig.write_image(plot_filepath)\n",
    "        if MATRIX_SHOW_PLOT:\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHORD_SAVE_PLOT or CHORD_SHOW_PLOT:\n",
    "    for group, cc in zip((group_1, group_2), groups_cross_correlations):\n",
    "        connectome = BraiAn.FunctionalConnectome(cc, p_cutoff=NETWORK_P_CUTOFF, r_cutoff=NETWORK_R_CUTOFF,\n",
    "                                         negatives=NETWORK_USE_NEGATIVE_LINKS, isolated_vertices=NETWORK_USE_ISOLATED_VERTICES, weighted=True)\n",
    "\n",
    "        title = f\"{group.name} connectomics graph from Pearson correlation (n = {group.n}, {'|r|' if NETWORK_USE_NEGATIVE_LINKS else 'r'} >= {NETWORK_R_CUTOFF}, p <= {NETWORK_P_CUTOFF})\"\n",
    "        group_annotations = dict(\n",
    "                                subtitle=\"\",\n",
    "                                **CHORD_BOTTOM_ANNOTATIONS\n",
    "                            )\n",
    "        fig = BraiAn.draw_chord_plot(connectome,\n",
    "                                    AllenBrain=AllenBrain,\n",
    "                                    ideograms_arc_index=50,\n",
    "                                    title=title,\n",
    "                                    size=CHORD_PLOT_SIZE,\n",
    "                                    no_background=CHORD_NO_BACKGROUND,\n",
    "                                    regions_size=CHORD_REGIONS_SIZE,\n",
    "                                    regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "                                    max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "                                    use_weighted_edge_widths=CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "                                    colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "                                    colorscale=CHORD_COLORSCALE,\n",
    "                                    colorscale_min=CHORD_COLORSCALE_MIN,\n",
    "                                    **group_annotations\n",
    "        )\n",
    "        if CHORD_SAVE_PLOT:\n",
    "            p_str = str(NETWORK_P_CUTOFF).replace(\".\", \"_\")\n",
    "            r_str = str(NETWORK_R_CUTOFF).replace(\".\", \"_\")\n",
    "            plot_filename = f\"pls_{pls_salience_threshold_str}_chord_plot_filtered_p{p_str}_r{r_str}_{group.name}_{group.marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "            plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "            match SAVED_PLOT_EXTENSION.lower():\n",
    "                case \".html\":\n",
    "                    fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "                case _:\n",
    "                    fig.write_image(plot_filepath)\n",
    "        if CHORD_SHOW_PLOT:\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(BraiAn.statistics)\n",
    "importlib.reload(BraiAn.plot)\n",
    "importlib.reload(BraiAn.plot_chord)\n",
    "importlib.reload(BraiAn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
