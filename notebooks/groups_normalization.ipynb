{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABBA cell count analysis\n",
    "\n",
    "This notebook is the last step in the ABBA whole-brain cell counting analysis.  \n",
    "It assumes you have done the following steps:\n",
    "- Alignment of brain slices in ABBA, exported to a QuPath project.\n",
    "- Detected cells of interest in QuPath. The detections should be exported to ```.csv``` files (one per slice) in a folder called ```results```. \n",
    "- If there are regions to exclude, you should have drawn them and exported to ```.txt``` files (one per slice) in a folder called ```regions_to_exclude```.\n",
    "\n",
    "Run this notebook to load the cell counts and do analysis on them. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start ...\n",
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CONFIG_FILE_NAME = \"braian_config.toml\"                     # assumes the file is in DATA_ROOT directory\n",
    "# USE_REMOTE_DATA -> if True, it tries to read the data on the laboratory's server\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"p6\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"experiment\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"proof\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"rebased_on_mjd\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"ieg\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"cohort4iba1\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"p17iba1\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"cohort4gaba\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"p17gaba\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"APP_PNS/Cohort 4/GABA_cFos\", True\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"APP_PNS/P17/cFos_Iba1\", True\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"Cariplo_NRe/IEGs Experiment\", True\n",
    "EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"Cariplo_NRe/IEGs Experiment/second_immuno\", True\n",
    "\n",
    "# ###################################### REMOTE DIRECTORIES #####################################\n",
    "IS_COLLABORATION_PROJ = True\n",
    "# COLLABORATION_DIRECTORY = os.path.join(\"Mathias Schmidt\", \"soumnya\")\n",
    "COLLABORATION_DIRECTORY = os.path.join(\"Mathias Schmidt\", \"shila\")\n",
    "EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"proof\", True\n",
    "\n",
    "# ###################################### LOCAL DIRECTORIES ######################################\n",
    "EXPERIMENT_DIRECTORY = EXPERIMENT_DIRECTORY.replace(\"/\", os.sep)\n",
    "# DATA_ROOT  = f\"../data/experiments/sowmya/{EXPERIMENT_DIRECTORY}\"\n",
    "DATA_ROOT  = f\"../data/experiments/{EXPERIMENT_DIRECTORY}\"\n",
    "PLOTS_ROOT = f\"../plots/{EXPERIMENT_DIRECTORY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_SMALL_REGIONS_FROM_SLICES = False\n",
    "REMOVE_HIGH_CV_REGIONS = False\n",
    "CVAR_THRESHOLD = 1\n",
    "\n",
    "# ###################################### PLOT OPTIONS ######################################\n",
    "PLOT_ALLENBRAIN_HIERARCHY = False\n",
    "PLOT_ANIMALS_ROOTS = True\n",
    "PLOT_COEFFICIENT_OF_VARIATION = True\n",
    "PLOT_COEFFICIENT_OF_VARIATION_THRESHOLD = 1\n",
    "\n",
    "SAVE_ANIMALS = True\n",
    "SAVE_GROUPS = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "project_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(project_path)\n",
    "import BraiAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REMOTE_DATA:\n",
    "    DATA_ROOT, PLOTS_ROOT = BraiAn.remote_dirs(EXPERIMENT_DIRECTORY, IS_COLLABORATION_PROJ, COLLABORATION_DIRECTORY)\n",
    "\n",
    "data_input_path = os.path.join(DATA_ROOT, \"QuPath_output\")\n",
    "data_output_path= os.path.join(DATA_ROOT, \"BraiAn_output\")\n",
    "config_file = os.path.join(DATA_ROOT, CONFIG_FILE_NAME)\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)\n",
    "os.makedirs(PLOTS_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "with open(config_file, \"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "config\n",
    "# ######################################### LOAD CONFIG #########################################\n",
    "EXPERIMENT_NAME = config[\"experiment\"][\"name\"]\n",
    "\n",
    "ATLAS_VERSION = config[\"atlas\"][\"version\"]\n",
    "BRANCHES_TO_EXCLUDE = config[\"atlas\"][\"excluded-branches\"]\n",
    "\n",
    "BRAINS_AREA_KEY = config[\"brains\"][\"area-column\"]\n",
    "BRAINS_TRACER_KEYS = config[\"brains\"][\"tracer-columns\"]\n",
    "BRAINS_OVERLAPPING_TRACERS = [[i_marker-1 for i_marker in comp[\"markers\"]]\n",
    "                              for comp in config[\"comparison\"].values()\n",
    "                              if isinstance(comp, dict) and comp[\"metric\"] == \"Overlapping\" and \"markers\" in comp]\n",
    "BRAINS_MARKERS = config[\"brains\"][\"markers\"]\n",
    "BRAINS_AGGREGATION_MODE = config[\"brains\"][\"slices-aggregation-mode\"]   # available options are: 'sum', 'mean'/'avg', 'std', 'variation'/'cvar'\n",
    "\n",
    "REGIONS_TO_PLOT_SELECTION_METHOD = config[\"comparison\"][\"regions-to-plot\"]  # Available options are:\n",
    "                                                                            #   - \"summary structures\"\n",
    "                                                                            #   - \"major divisions\"\n",
    "                                                                            #   - \"depth <n>\" where <n> is an integer of the depth desired\n",
    "                                                                            #   - \"structural level <n>\" where <n> is an integer of the level desired\n",
    "                                                                            #   - \"smallest\"\n",
    "                                                                            # where <n> is an integer of the depth/level desired\n",
    "\n",
    "from collections import namedtuple\n",
    "GroupDirectory = namedtuple(\"GroupDirectory\", \"id name dirs\")\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        id=int(group[len(\"group\"):])-1,\n",
    "        name=config[\"experiment\"][group][\"name\"],\n",
    "        dirs=config[\"experiment\"][group][\"dirs\"]\n",
    "    ) for group in config[\"experiment\"] if group.startswith(\"group\") and group[len(\"group\"):].isdigit()\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Allen Brain Atlas\n",
    "\n",
    "We start by importing the mouse Allen Brain Atlas, in which we find information about all brain regions (their parent region and children regions in the brain hierarchy, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "# StructureGraph id=1\n",
    "path_to_allen_json = os.path.join(project_path, \"data\", \"AllenMouseBrainOntology.json\")\n",
    "BraiAn.cache(path_to_allen_json, \"http://api.brain-map.org/api/v2/structure_graph_download/1.json\")\n",
    "brain_onthology = BraiAn.AllenBrainHierarchy(path_to_allen_json, BRANCHES_TO_EXCLUDE, version=ATLAS_VERSION)\n",
    "\n",
    "#parent_region = brain_onthology.parent_region\n",
    "#direct_subregions = brain_onthology.direct_subregions\n",
    "#full_name = brain_onthology.full_name\n",
    "#regions = brain_onthology.list_all_subregions(\"root\", mode=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match REGIONS_TO_PLOT_SELECTION_METHOD:\n",
    "    case \"summary structures\":\n",
    "        # selects the Summary Strucutures\n",
    "        path_to_summary_structures = os.path.join(project_path, \"data\", \"AllenSummaryStructures.csv\")\n",
    "        brain_onthology.select_from_csv(path_to_summary_structures)\n",
    "    case \"major divisions\":\n",
    "        brain_onthology.select_regions(BraiAn.MAJOR_DIVISIONS)\n",
    "    case \"smallest\":\n",
    "        brain_onthology.select_leaves()\n",
    "    case s if s.startswith(\"depth\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            depth = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'depth' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        brain_onthology.select_at_depth(depth)\n",
    "    case s if s.startswith(\"structural level\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            level = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'structural level' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        brain_onthology.select_at_structural_level(level)\n",
    "    case _:\n",
    "        raise Exception(f\"Invalid value '{REGIONS_TO_PLOT_SELECTION_METHOD}' for REGIONS_TO_PLOT_SELECTION_METHOD\")\n",
    "selected_regions = brain_onthology.get_selected_regions()\n",
    "print(f\"You selected {len(selected_regions)} regions to plot.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the hierarchy of brain regions as a network (a tree). **Note that running the above cell may take a few minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Plot brain region hierarchy\n",
    "## If you want to plot it, install PyDot (pydot)\n",
    "if PLOT_ALLENBRAIN_HIERARCHY:\n",
    "    fig = brain_onthology.plot_plotly_graph()\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph above, you might want to specify the regions on which you want to do further PLS analysis:  \n",
    "*Note: to see more information about the regions, hover over them with your mouse.*\n",
    "\n",
    "- Specify a level. Analysis can only be done on one level (slice) in the brain region.\n",
    "\n",
    "- To exclude brain regions that belong to a certain branch, add the *abbreviated* nodes at the beginning of the branches to the list above.  \n",
    "Example:  \n",
    "```branches_to_exclude = [\"retina\", \"VS\"]```  \n",
    "means that **all the subregions that belong to the retina and the ventricular systems** are excluded from the PLS analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Now, we're ready to read the ```.csv``` files with the cell counts, and also the exclusion files (if there were regions to exclude).  \n",
    "Below, you have to specify:\n",
    "- ```animals_root```: Absolute path to the folder that contains the animal folders.\n",
    "- ```group_1_dirs```: A list of names of the folders corresponding to animals in **Group 1** (e.g., Control group). Indeed, it is necessary to store the results in individual folders for each animal.\n",
    "- ```group_2_dirs```: A list of names of the folders corresponding to animals in **Group 2** (e.g., Stress group).\n",
    "- ```group_1_name```: A meaningful string for Group 1.\n",
    "- ```group_2_name```: A meaningful string for Group 2.\n",
    "- ```area_key```: A string of the column in the ```.csv``` files that refers to the size of a brain areatra\n",
    "- ```tracer_key```: A string of the column in the ```.csv``` files that refers to the tracer number used to highlight the marker\n",
    "- ```marker```: A string of the marker we would like to highlight (e.g. CFos)\n",
    "\n",
    "Provare a modificar per ottenere densita in mm^2 (da micron)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the Control and Stress results seperately in two pandas dataframes, and save the results.\n",
    "\n",
    "**Note**: regions to exclude are automatically excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def fix_overlap_detection_if_old_qpscript(sliced_brain: BraiAn.SlicedBrain):\n",
    "    # if sliced_brain has was computed on data collected from an old QuPath script,\n",
    "    # then the number of detection of the first marker is ~wrong. It must be summed to the overlaps between marker1 and marker2\n",
    "    for i in range(len(sliced_brain.markers)): # e.g. header=\"GABA-(cFos+GABA)\"\n",
    "        marker1_diff = sliced_brain.markers[i]\n",
    "        # see https://regex101.com/r/LLwGIl/1\n",
    "        markers = re.compile(\"(?P<m1>\\w+)-\\((?:(\\w+)\\+(?P=m1)|(?P=m1)\\+(\\w+))\\)\").findall(marker1_diff)\n",
    "        # e.g markers=[('GABA', 'cFos', '')]\n",
    "        if len(markers) == 0:\n",
    "            continue\n",
    "        markers = [m for m in markers[0] if len(m) != 0]\n",
    "        marker1, marker2 = markers  # e.g. marker1=\"GABA\" and marker2=\"cFos\"\n",
    "        for brain_slice in sliced_brain.slices:\n",
    "            brain_slice.data[marker1_diff] += brain_slice.data[f\"{marker1_diff}+{marker2}\"]\n",
    "            brain_slice.data.rename(columns={marker1_diff: marker1, f\"{marker1_diff}+{marker2}\": f\"{marker1}+{marker2}\"}, inplace=True)\n",
    "        sliced_brain.markers[i] = marker1\n",
    "        overlap_i = next(i for i in range(len(sliced_brain.markers)) if sliced_brain.markers[i] == f\"{marker1_diff}+{marker2}\")\n",
    "        sliced_brain.markers[overlap_i] = f\"{marker1}+{marker2}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_slices: List[List[BraiAn.SlicedBrain]] = []\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    group_slices = []\n",
    "    for animal_dir in groups[i].dirs:\n",
    "        if not os.path.isdir(os.path.join(data_input_path, animal_dir)):\n",
    "            print(f\"WARNING: could not find the directory '{animal_dir}' in '{EXPERIMENT_DIRECTORY}'. Skipping this animal.\")\n",
    "            continue\n",
    "        sliced_brain = BraiAn.SlicedBrain(animal_dir,\n",
    "                                            os.path.join(data_input_path, animal_dir),\n",
    "                                            brain_onthology,\n",
    "                                            BRAINS_AREA_KEY,\n",
    "                                            BRAINS_TRACER_KEYS,\n",
    "                                            BRAINS_MARKERS,\n",
    "                                            *BRAINS_OVERLAPPING_TRACERS,\n",
    "                                            area_units=\"µm2\")\n",
    "        fix_overlap_detection_if_old_qpscript(sliced_brain)\n",
    "        group_slices.append(sliced_brain)\n",
    "    groups_slices.append(group_slices)\n",
    "    print(f\"Imported all brain slices from {str(len(groups[i].dirs))} animals of {groups[i].name} group.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMOVE_SMALL_REGIONS_FROM_SLICES:\n",
    "    for group_ in groups_slices:\n",
    "        for animal_ in group_:\n",
    "            for s in animal_.slices:\n",
    "                s._data = s.data\n",
    "                # TODO: currently there is no differentiation between real markers and overlapping markers.\n",
    "                # This bad workaround excludes all those markers having a '+' in the name.\n",
    "                real_markers = [m for m in animal_.markers if \"+\" not in m]\n",
    "                s.data = s.data[(s.data[real_markers] != 1).any(axis=1) & (s.data.area > 0.001)].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_ANIMALS_ROOTS:\n",
    "    region_name = \"root\"\n",
    "    root_plot = BraiAn.plot_region_density(region_name, *groups_slices, width=1000, height=500)\n",
    "    root_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"N regions above threshold:\", sum([(brain.data > cv_threshold).sum() for brain in cvar_brains]))\n",
    "# print(\"N regions below threshold:\", sum([(brain.data <= cv_threshold).sum() for brain in cvar_brains]))\n",
    "if PLOT_COEFFICIENT_OF_VARIATION:\n",
    "    cvar_plot = BraiAn.plot_cv_above_threshold(brain_onthology, *groups_slices, cv_threshold=PLOT_COEFFICIENT_OF_VARIATION_THRESHOLD, width=1000, height=500)\n",
    "    cvar_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"ENTl6a\"\n",
    "a = \"224.3CM\"\n",
    "# m = \"CFos\"\n",
    "def check_animal_region(animal_name: str, region_acronym: str, marker=None):\n",
    "    try:\n",
    "        sliced_brain = next(animal for group in groups_slices for animal in group if animal_name == animal.name)\n",
    "    except StopIteration:\n",
    "        print(f\"Can't find region animal '{animal_name}'\")\n",
    "        return\n",
    "    sliced_brain = BraiAn.merge_sliced_hemispheres(sliced_brain)\n",
    "    all_slices_df = sliced_brain.concat_slices()\n",
    "    slices_per_area = all_slices_df.groupby(all_slices_df.index).count().iloc[:,0]\n",
    "    if region_acronym not in slices_per_area.index:\n",
    "        print(f\"Can't find region '{region_acronym}' for animal '{animal_name}'\")\n",
    "        return\n",
    "    markers = sliced_brain.markers if marker is None else [marker]\n",
    "    brain_avg = BraiAn.AnimalBrain.from_slices(sliced_brain, mode=\"avg\", hemisphere_distinction=False)\n",
    "    brain_std = BraiAn.AnimalBrain.from_slices(sliced_brain, mode=\"std\", hemisphere_distinction=False)\n",
    "    for m in markers:\n",
    "        marker_avg = brain_avg[m]\n",
    "        marker_std = brain_std[m]\n",
    "        print(f\"\"\"Summary for brain region '{region_acronym}' of marker '{m}':\n",
    "            - N slices: {slices_per_area[region_acronym]}\n",
    "            - Mean: {marker_avg[region_acronym]:.2f} {m}/mm²),\n",
    "            - S.D.: {marker_std[region_acronym]:.2f} {m}/mm²,\n",
    "            - Coefficient of Variation: {marker_avg[region_acronym]}\n",
    "        \"\"\")\n",
    "# for a in groups[-1].dirs:\n",
    "check_animal_region(a, r) #, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see the slices in specific, run this\n",
    "import pandas as pd\n",
    "slices = []\n",
    "try:\n",
    "    sliced_brain = next(animal for group in groups_slices for animal in group if a == animal.name)\n",
    "    sliced_brain = BraiAn.merge_sliced_hemispheres(sliced_brain)\n",
    "    for slice in sliced_brain.slices:\n",
    "        if r not in slice.markers_density.index:\n",
    "            continue\n",
    "        region_densities = slice.markers_density.loc[r].copy()\n",
    "        region_densities.index += \" density\"\n",
    "        region_densities.name = slice.name\n",
    "        slices.append(region_densities)\n",
    "except StopIteration:\n",
    "    print(f\"Can't find region '{r}' for animal '{a}'\")\n",
    "pd.concat(slices, axis=1) if len(slices) != 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: brains are being written WITH Left/Right discrimination\n",
    "# If you desire to save them without, call AnimalBrain with hemisphere_distinction=False\n",
    "\n",
    "groups_sum_brains: List[List[BraiAn.AnimalBrain]] = [[BraiAn.AnimalBrain.from_slices(sliced_brain, mode=BRAINS_AGGREGATION_MODE, hemisphere_distinction=False) for sliced_brain in sliced_brain_list] for sliced_brain_list in groups_slices]\n",
    "if SAVE_ANIMALS:\n",
    "    for i in range(len(groups)):\n",
    "        for animal in groups_sum_brains[i]:\n",
    "            animal.to_csv(data_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMOVE_HIGH_CV_REGIONS:\n",
    "    for i, group_slices in enumerate(groups_slices):\n",
    "        for animal_brain, slices in zip(groups_sum_brains[i], group_slices):\n",
    "            cvars = BraiAn.AnimalBrain.from_slices(slices, mode=\"cvar\", hemisphere_distinction=animal_brain.is_split, min_slices=0)\n",
    "            # TODO: currently there is no differentiation between real markers and overlapping markers.\n",
    "            # This bad workaround excludes all those markers having a '+' in the name.\n",
    "            real_markers = [m for m in cvars.markers if \"+\" not in m]\n",
    "            cvars_data = cvars.to_pandas()\n",
    "            disperse_regions = cvars_data.index[(cvars_data > CVAR_THRESHOLD)[real_markers].any(axis=1)]\n",
    "            print(f\"removing {len(disperse_regions)}/{len(cvars_data)} dispersive regions from '{slices.name}'\")\n",
    "            animal_brain.remove_region(*disperse_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_sum = [BraiAn.AnimalGroup(groups[i].name, groups_sum_brains[i], metric=\"sum\", brain_onthology=brain_onthology, merge_hemispheres=True) for i in range(len(groups))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_density: List[BraiAn.AnimalGroup] = [BraiAn.AnimalGroup(group_sum.name, group_sum.animals, metric=\"density\", brain_onthology=brain_onthology, merge_hemispheres=True) for group_sum in groups_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_GROUPS:\n",
    "    for dgroup in groups_density:\n",
    "        dgroup.to_csv(data_output_path, f\"cell_counts_{dgroup.name}_density.csv\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "groups_perc = BraiAn.AnimalGroup(\"+\".join((g.name for g in groups_sum)),\n",
    "                                 [a for g in groups_sum for a in g.animals], \n",
    "                                 metric=\"percentage\", brain_onthology=brain_onthology, merge_hemispheres=True)\n",
    "fig = make_subplots(rows=1, cols=3, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],\n",
    "                    subplot_titles=groups_perc.markers)\n",
    "for i,marker in enumerate(groups_perc.markers):\n",
    "    data = groups_perc.mean[marker].data[BraiAn.MAJOR_DIVISIONS].copy()\n",
    "    data[\"other\"] = 1-data.sum()\n",
    "    # groups_perc[0].mean[\"Arc1\"].data[BraiAn.MAJOR_DIVISIONS].sum()\n",
    "    allen_colours = brain_onthology.get_region_colors()\n",
    "    allen_colours[\"other\"] = \"lightgrey\"\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=[brain_onthology.full_name[r] if r in BraiAn.MAJOR_DIVISIONS else r for r,p in data.items() if p != 0],\n",
    "            values=[p for p in data if p != 0],\n",
    "            name=marker,\n",
    "            marker=dict(\n",
    "                colors=[allen_colours[r] for r,p in data.items() if p != 0],\n",
    "                line=dict(color=\"#000000\", width=2)\n",
    "            ),\n",
    "            sort=False,\n",
    "            textfont=dict(size=12),\n",
    "            hole=0.3,\n",
    "            textposition=\"outside\", textinfo=\"percent+label\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        1, i+1\n",
    "    )\n",
    "    \n",
    "fig.update_layout(\n",
    "    title_text=f\"Positive percentage by areas - {groups_perc.name}\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"comparison\" in config:\n",
    "    comparisons = dict()\n",
    "    for comp_name, comp in config[\"comparison\"].items():\n",
    "        if not isinstance(comp, dict):\n",
    "            continue\n",
    "        comparisons[comp_name] = []\n",
    "        metric = BraiAn.BrainMetrics(comp[\"metric\"]) if comp[\"metric\"].lower() != \"correlation\" else \"correlation\"\n",
    "        kwargs = dict(brain_onthology=brain_onthology, merge_hemispheres=True)\n",
    "        for i, group_sum in enumerate(groups_sum): \n",
    "            if \"markers\" in comp: #len(comp[\"markers\"]) == 2\n",
    "                markers = (group_sum.markers[i-1] for i in comp[\"markers\"])\n",
    "            else:\n",
    "                markers = group_sum.markers\n",
    "            match metric:\n",
    "                case \"correlation\":\n",
    "                    data = BraiAn.AnimalGroup(group_sum.name, group_sum.animals, \"density\", **kwargs).markers_corr(*markers)\n",
    "                case BraiAn.BrainMetrics.OVERLAPPING | BraiAn.BrainMetrics.SIMILARITY_INDEX | BraiAn.BrainMetrics.DIFFERENCE:\n",
    "                    m1, m2 = markers\n",
    "                    data = BraiAn.AnimalGroup(group_sum.name, group_sum.animals, metric, marker1=m1, marker2=m2, **kwargs)\n",
    "                case _:\n",
    "                    data = BraiAn.AnimalGroup(group_sum.name, group_sum.animals, metric, **kwargs)\n",
    "            comparisons[comp_name].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filename(*ss: str):\n",
    "    return \"_\".join((s.replace(' ', '_') for s in ss if s != \"\"))\n",
    "\n",
    "if \"comparison\" in config:\n",
    "    for comp_name, comp in config[\"comparison\"].items():\n",
    "        if not isinstance(comp, dict):\n",
    "            continue\n",
    "        plots_output_dir = os.path.join(PLOTS_ROOT, comp[\"dir\"])\n",
    "        os.makedirs(plots_output_dir, exist_ok=True)\n",
    "        metric_data = []\n",
    "        if \"groups\" in comp:\n",
    "            if len(comp[\"groups\"]) != 2:\n",
    "                print(f\"WARNING: you can compare only two groups at the time!\")\n",
    "                continue\n",
    "            group1, group2 = (comparisons[comp_name][i-1] for i in comp[\"groups\"])\n",
    "            if isinstance(group1, BraiAn.AnimalGroup) and isinstance(group2, BraiAn.AnimalGroup):\n",
    "                if not group1.is_comparable(group2):\n",
    "                    print(f\"WARNING: '{group1}' is not comparable with '{group2}'!\")\n",
    "                    continue\n",
    "                for marker in group1.markers:\n",
    "                    right_data = group1.mean[marker]\n",
    "                    left_data = group2.mean[marker]\n",
    "                    metric_data.append((right_data, left_data, marker, f\"{group1.name}+{group2.name}\"))\n",
    "            elif isinstance(group1, BraiAn.BrainData) and isinstance(group2, BraiAn.BrainData):\n",
    "                metric_data.append((group1, group2, \"\", f\"{right_data.data_name}+{left_data.data_name}\"))\n",
    "            else:\n",
    "                print(f\"WARNING: '{group1}' and '{group2}' are of an unexpected type!\")\n",
    "                continue\n",
    "        elif \"markers\" in comp:\n",
    "            groups = comparisons[comp_name]\n",
    "            for group in groups:\n",
    "                if isinstance(group, BraiAn.BrainData):\n",
    "                    right_data = group\n",
    "                    left_data = None\n",
    "                    metric_data.append((right_data, left_data, right_data.data_name, \"\"))\n",
    "                    continue\n",
    "                try:\n",
    "                    marker1, marker2 = (group.markers[i-1] for i in comp[\"markers\"])\n",
    "                except IndexError:\n",
    "                    print(f\"WARNING: be sure that metric='{str(group.metric)}' is asymmetric.\", end=\" \")\n",
    "                    print(\", \".join((str(BraiAn.BrainMetrics.SIMILARITY_INDEX), str(BraiAn.BrainMetrics.DIFFERENCE), \"correlation\"))+\" are not!\")\n",
    "                    right_data = group.mean[group.markers[0]]\n",
    "                    left_data = None\n",
    "                    metric_data.append((right_data, left_data, group.name, \"\"))\n",
    "                    continue\n",
    "                right_data = group.mean[marker1]\n",
    "                right_data.data_name = marker1\n",
    "                left_data = group.mean[marker2]\n",
    "                left_data.data_name = marker2\n",
    "                metric_data.append((right_data, left_data, group.name, f\"{marker1}+{marker2}\"))\n",
    "        print(\"comparison\", comp_name, \"---\", comp[\"metric\"])\n",
    "        for right_data, left_data, common_str, comparison_str in metric_data:\n",
    "            # print(\"\\tRIGHT:\" if left_data is not None else \"\\tBOTH\", right_data.data_name, right_data.metric, right_data.units)\n",
    "            # if left_data is not None:\n",
    "            #     print(\"\\tLEFT:\", left_data.data_name, left_data.metric, left_data.units)\n",
    "            metric = right_data.metric.lower().split(\" \")[0]\n",
    "            filename = make_filename(metric, common_str, comparison_str)\n",
    "            if metric.endswith(\"-corr\") or metric.startswith(str(BraiAn.BrainMetrics.DIFFERENCE)):\n",
    "                centered_cmap = True\n",
    "            else:\n",
    "                centered_cmap = False\n",
    "            if metric.endswith(\"-corr\"):\n",
    "                cmin, cmax = -1, 1\n",
    "            elif metric.startswith(str(BraiAn.BrainMetrics.SIMILARITY_INDEX)) or \\\n",
    "                 metric.startswith(str(BraiAn.BrainMetrics.OVERLAPPING)):\n",
    "                cmin, cmax = 0, 1\n",
    "            else:\n",
    "                cmin, cmax = None, None\n",
    "            print(f\"\\t{filename}: \", end=\"\")\n",
    "            right_data.plot(selected_regions,\n",
    "                        plots_output_dir, filename, other=left_data, n=20,\n",
    "                        cmin=cmin, cmax=cmax, cmap=\"magma_r\", centered_cmap=centered_cmap,\n",
    "                        orientation=\"frontal\", show_text=False) #, title=f\"{right_m} & {left_m} {str(metric)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sum = groups_sum[0]\n",
    "group_diff = BraiAn.AnimalGroup(name=group_sum.name, animals=group_sum.animals, metric=\"diff\", marker1=\"Arc1\", marker2=\"cFos\", merge_hemispheres=True, brain_onthology=brain_onthology)\n",
    "data = group_diff.mean[\"Arc1+cFos\"]\n",
    "\n",
    "for i in range(5,7):\n",
    "    brain_onthology.select_at_structural_level(i)\n",
    "    depth_i = brain_onthology.get_selected_regions()\n",
    "    try:\n",
    "        f = data.plot(depth_i, None, None, depth=6682, centered_cmap=True, orientation=\"frontal\", show_text=True, title=f\"structural_level={i}\")\n",
    "    except ValueError:\n",
    "        print(f\"ERROR: structural_level={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4,8):\n",
    "    brain_onthology.select_at_depth(i)\n",
    "    depth_i = brain_onthology.get_selected_regions()\n",
    "    try:\n",
    "        f = data.plot(depth_i, None, None, depth=6682, centered_cmap=True, orientation=\"frontal\", show_text=True, title=f\"depth={i}\")\n",
    "    except ValueError:\n",
    "        print(f\"ERROR: depth={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = groups_density[0]\\\n",
    "        .pls_regions(groups_density[1], selected_regions, n_permutations=5000, n_bootstrap=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker = groups_density[0].markers[0]\n",
    "pls = BraiAn.PLS(selected_regions, groups_density[0], groups_density[1], marker=marker)\n",
    "pls.randomly_permute_singular_values(5000)\n",
    "pls.bootstrap_salience_scores(rank=1, num_bootstrap=5000)\n",
    "pls.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filename(*ss: str):\n",
    "    return \"_\".join((s.replace(' ', '_') for s in ss if s != \"\"))\n",
    "\n",
    "filename = make_filename(\"pls_salient_scores\", \"CTX-FC\", \"cFos+Arc1\")\n",
    "pls[\"cFos\"].data_name = \"cFos\"\n",
    "pls[\"Arc1\"].data_name = \"Arc1\"\n",
    "pls[\"cFos\"].plot(selected_regions, os.path.join(PLOTS_ROOT, \"CTX-FC\"), filename, other=pls[\"Arc1\"], n=20, centered_cmap=True, orientation=\"frontal\", show_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "\n",
    "threshold = BraiAn.PLS.norm_threshold(nsigma=2) # use the μ ± 3σ of the normal as threshold\n",
    "print(f\"THRESHOLD: ~{threshold:.2f}\")\n",
    "marker1 = \"cFos\"\n",
    "marker2 = \"Arc1\"\n",
    "\n",
    "marker1_salients = pls[marker1].data.abs() >= threshold\n",
    "marker2_salients = pls[marker2].data.abs() >= threshold\n",
    "assert (marker1_salients.index == marker2_salients.index).all(), \"PLS results must be on the same brain regions!\"\n",
    "print(f\"#salient regions ({marker1}):\", sum(marker1_salients))\n",
    "print(f\"#salient regions ({marker2}):\", sum(marker2_salients))\n",
    "marker1_only_salients = marker1_salients & (~marker2_salients)\n",
    "marker2_only_salients = marker2_salients & (~marker1_salients)\n",
    "both_markers_salients = marker1_salients & marker2_salients\n",
    "\n",
    "salient_regions = pd.Series(0, index=marker1_salients.index)    # 0 -> not salient for neither of the markers\n",
    "salient_regions[marker1_only_salients] = 1                      # 1 -> salient only for marker1\n",
    "salient_regions[marker2_only_salients] = 2                      # 2 -> salient only for marker2\n",
    "salient_regions[both_markers_salients] = 3                      # 3 -> salient for both marker1 and marker2\n",
    "salient_regions[np.isnan(pls[marker1].data)] = np.nan\n",
    "salient_regions = BraiAn.BrainData(salient_regions, pls[marker1].data_name, f\"salient regions (|z-score|≥{threshold:.2f})\", \"class\", fill=False)\n",
    "\n",
    "def make_filename(*ss: str):\n",
    "    return \"_\".join((s.replace(' ', '_') for s in ss if s != \"\"))\n",
    "\n",
    "bounds = np.array([-.5,.5,1.5,2.5,3.5])\n",
    "#norm = matplotlib.colors.BoundaryNorm(boundaries=(bounds-bounds.min())/(bounds.max()-bounds.min()), ncolors=256) #, extend='both')\n",
    "#cmap = BraiAn.brain_data.NormalizedColormap(cmap=matplotlib.colormaps['viridis'], norm=norm)\n",
    "cmap = matplotlib.colors.ListedColormap([\"#ffffcc\", \"#a1dab4\", \"#ff8686\", \"#2c7fb8\"], name=\"my_cmap\")\n",
    "# salient_regions.plot(selected_regions, None, None, depth=6500, cmap=cmap, centered_cmap=False, orientation=\"frontal\", show_text=True)\n",
    "filename = make_filename(\"pls_salient_regions\", \"CTX-FC\", \"cFos+Arc1\")\n",
    "salient_regions.plot(selected_regions, os.path.join(PLOTS_ROOT, \"CTX-FC\"), filename, n=20, cmap=cmap, centered_cmap=False, orientation=\"frontal\", show_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "np.random.seed(42)  # Set the random seed for reproducibility\n",
    "data = np.random.normal(0, 1, 100_000)\n",
    "mean = np.mean(data)\n",
    "std = np.std(data)\n",
    "print(\"(μ+2σ) percentile:\", 1-scipy.stats.norm.pdf((mean + 2*std)))\n",
    "\n",
    "# Plot normal\n",
    "x = np.linspace(scipy.stats.norm.ppf(0.01), scipy.stats.norm.ppf(0.99), 100)\n",
    "plt.plot(x, scipy.stats.norm.pdf(x), 'r-', lw=5, alpha=0.6, label='norm pdf')\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(data, bins=30, density=True, alpha=0.7)\n",
    "\n",
    "# Plot the mean and standard deviations\n",
    "plt.axvline(mean, color='r', linestyle='dashed', linewidth=1, label='Mean')\n",
    "plt.axvline(mean - std, color='g', linestyle='dashed', linewidth=1, label='1 STD')\n",
    "plt.axvline(mean + std, color='g', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(mean - 2*std, color='b', linestyle='dashed', linewidth=1, label='2 STD')\n",
    "plt.axvline(mean + 2*std, color='b', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(mean - 3*std, color='m', linestyle='dashed', linewidth=1, label='3 STD')\n",
    "plt.axvline(mean + 3*std, color='m', linestyle='dashed', linewidth=1)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram of the Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = groups_density[0]\\\n",
    "    .pls_regions(groups_density[1], selected_regions, n_permutations=5000, n_bootstrap=5000, marker=\"cFos\")\\\n",
    "    .plot(selected_regions, None, None, depth=6500, centered_cmap=True, orientation=\"frontal\", show_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bgheatmaps as bgh\n",
    "import vedo as vd\n",
    "# import vtk\n",
    "vd.embedWindow(None)\n",
    "# vd.embedWindow(\"k3d\")\n",
    "from BraiAn.brain_data import CenteredColormap\n",
    "\n",
    "group_sum = groups_sum[0]\n",
    "group_diff = BraiAn.AnimalGroup(name=group_sum.name, animals=group_sum.animals, metric=\"diff\", marker1=\"Arc1\", marker2=\"cFos\", merge_hemispheres=True, brain_onthology=brain_onthology)\n",
    "data = group_diff.mean[\"Arc1+cFos\"]\n",
    "# data = data.data[~data.data.isna()]\n",
    "data = data[BraiAn.MAJOR_DIVISIONS+selected_regions]\n",
    "\n",
    "bgh.heatmap(\n",
    "    data.to_dict(),\n",
    "    position=6658,\n",
    "    thickness=1000,\n",
    "    orientation=\"frontal\",\n",
    "    title=\"difference\",\n",
    "    cmap=CenteredColormap(\"RdBu\", data.min(), data.max()),\n",
    "    vmin=data.min(),\n",
    "    vmax=data.max(),\n",
    "    format=\"3D\",\n",
    "    hemisphere=\"right\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "__imported_modules = sys.modules.copy()\n",
    "for module_name, module in __imported_modules.items():\n",
    "    if not module_name.startswith(\"BraiAn\"): # and not module_name.startswith(\"bgheatmaps\"):\n",
    "        continue\n",
    "    try:\n",
    "        # print(\"reaload:\", module_name)\n",
    "        importlib.reload(module)\n",
    "    except ModuleNotFoundError:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silvalab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbdbc2a93f3d53e4e8b76fd52fa6db7ab146f3f80c2161705ce1711cc2868e5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
