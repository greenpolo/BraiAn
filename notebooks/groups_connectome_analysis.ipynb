{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectome analysis\n",
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CONFIG_FILE_NAME = \"braian_config.toml\"                     # assumes the file is in DATA_ROOT directory\n",
    "# EXPERIMENT_DIRECTORY = \"p4\"\n",
    "# EXPERIMENT_DIRECTORY = \"experiment\"\n",
    "# EXPERIMENT_DIRECTORY = \"proof\"\n",
    "EXPERIMENT_DIRECTORY = \"rebased_on_mjd\"\n",
    "\n",
    "USE_REMOTE_DATA = False                                     # if True, it tries to read the data on the laboratory's server\n",
    "# ###################################### REMOTE DIRECTORIES #####################################\n",
    "IS_COLLABORATION_PROJ = False\n",
    "COLLABORATION_DIRECTORY = os.path.join(\"Mathias Schmidt\", \"soumnya\")\n",
    "\n",
    "# ###################################### LOCAL DIRECTORIES ######################################\n",
    "# DATA_ROOT  = f\"../data/experiments/sowmya/{EXPERIMENT_DIRECTORY}\"\n",
    "# PLOTS_ROOT = f\"../plots/sowmya/{EXPERIMENT_DIRECTORY}\"\n",
    "DATA_ROOT  = f\"../data/experiments/{EXPERIMENT_DIRECTORY}\"\n",
    "PLOTS_ROOT = f\"../plots/{EXPERIMENT_DIRECTORY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on which comparison of CONFIG_FILE_NAME to run the connectome analysis\n",
    "COMPARISON_ID = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### GENERAL OPTIONS #######################################\n",
    "SAVED_PLOT_EXTENSION = \".html\"                              # '.html' for interactive plot\n",
    "                                                            # '.svg' for vectorized image\n",
    "                                                            # '.png'/'.jpg'/... for rasterized image\n",
    "\n",
    "# ###################################### CORRELATION MATRIX #####################################\n",
    "MATRIX_SAVE_PLOT = False\n",
    "MATRIX_SHOW_PLOT = False\n",
    "MATRIX_CELL_HEIGHT = 18\n",
    "MATRIX_STAR_SIZE = 8\n",
    "MATRIX_CELL_RATIO = 1\n",
    "MATRIX_MIN_PLOT_HEIGHT = 500\n",
    "\n",
    "# ######################################## CHORD DIAGRAM ########################################\n",
    "CHORD_SAVE_PLOT = False\n",
    "CHORD_SHOW_PLOT = True\n",
    "CHORD_PLOT_SIZE = 1200\n",
    "CHORD_NO_BACKGROUND = False\n",
    "CHORD_PLOT_ISOLATED_REGIONS = True\n",
    "CHORD_REGIONS_SIZE = 10\n",
    "CHORD_REGIONS_FONT_SIZE = 10\n",
    "CHORD_MAX_EDGE_WIDTH = 3\n",
    "CHORD_USE_WEIGHTED_EDGE_WIDTHS = False\n",
    "CHORD_USE_COLORSCALE_EDGES = True\n",
    "CHORD_BOTTOM_ANNOTATIONS = dict(\n",
    "    annotation1 = \"Dark grey nodes are regions with insufficient data to compute cross correlation\",\n",
    "    annotation2 = \"Light grey nodes are regions with no correlation with others above the threshold\",\n",
    "    annotation3 = \"This is the third annotation\",\n",
    "    # howmany annotations desired with the following format:\n",
    "    # annotations<k> = \"<annotation>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "\n",
    "# https://doi.org/10.1109/TKDE.2007.190689\n",
    "# clustering_args = (ig.Graph.community_optimal_modularity,)\n",
    "                    # Graphs with up to fifty vertices should be fine, graphs with a couple of hundred vertices might be possible.\n",
    "                    # crashes on my pc with summary structure's Graph\n",
    "clustering_args = (ig.Graph.community_fastgreedy,)\n",
    "# clustering_args = (ig.Graph.community_infomap,)\n",
    "# clustering_args = (ig.Graph.community_leading_eigenvector_naive,)\n",
    "# clustering_args = (ig.Graph.community_leading_eigenvector,)\n",
    "# clustering_args = (ig.Graph.community_label_propagation,)\n",
    "# clustering_args = (ig.Graph.community_multilevel,)\n",
    "# clustering_args = (ig.Graph.community_edge_betweenness, dict(directed=False))\n",
    "# clustering_args = (ig.Graph.community_spinglass,)\n",
    "# clustering_args = (ig.Graph.community_walktrap,)\n",
    "# clustering_args = (ig.Graph.community_leiden,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout_fun = ig.Graph.layout_kamada_kawai               # 1st best - good for ~small networks# \n",
    "layout_fun = ig.Graph.layout_fruchterman_reingold       # 2nd best - good for bigger networks\n",
    "# layout_fun = ig.Graph.layout_graphopt                   # 3rd best\n",
    "# layout_fun = ig.Graph.layout_davidson_harel             # 4th best\n",
    "# layout_fun = ig.Graph.layout_mds                        # 5th best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script's code\n",
    "run all cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "\n",
    "project_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(project_path)\n",
    "import BraiAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REMOTE_DATA:\n",
    "    DATA_ROOT, PLOTS_ROOT = BraiAn.remote_dirs(EXPERIMENT_DIRECTORY, IS_COLLABORATION_PROJ, COLLABORATION_DIRECTORY)\n",
    "\n",
    "config_file = os.path.join(DATA_ROOT, CONFIG_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "with open(config_file, \"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "config\n",
    "# ######################################### LOAD CONFIG #########################################\n",
    "EXPERIMENT_NAME = config[\"experiment\"][\"name\"]\n",
    "\n",
    "ATLAS_VERSION = config[\"atlas\"][\"version\"]\n",
    "BRANCHES_TO_EXCLUDE = config[\"atlas\"][\"excluded-branches\"]\n",
    "USE_LITERATURE_REUNIENS =  config[\"atlas\"][\"use-literature-reuniens\"]       # add a 'REtot' region, merging the following regions: 'RE', 'Xi', 'RH'\n",
    "\n",
    "NORMALIZATION = config[\"brains\"][\"normalization\"]                           # call get_normalization_methods() on a AnimalGroup object to know its available normalization methods\n",
    "MIN_AREA = config[\"connectome\"][\"min-area\"]                                 # area in mm². If a region of one animal is smaller, that same animal won't be displayed in the plots\n",
    "REGIONS_TO_PLOT_SELECTION_METHOD = config[\"connectome\"][\"regions-to-plot\"]  # Available options are:\n",
    "                                                                            #   - \"summary structures\"\n",
    "                                                                            #   - \"nre to bla\"\n",
    "                                                                            #   - \"major divisions\"\n",
    "                                                                            #   - \"depth <n>\" where <n> is an integer of the depth desired\n",
    "                                                                            #   - \"structural level <n>\" where <n> is an integer of the level desired\n",
    "                                                                            #   - \"pls <experiment> <salience_threshold>\" (e.g., \"pls proof 1.2\")\n",
    "                                                                            # where <n> is an integer of the depth/level desired\n",
    "GROUPED_REGIONS = config[\"connectome\"][\"grouped-regions\"]\n",
    "\n",
    "# ###################################### CROSS CORRELATION ######################################\n",
    "MIN_ANIMALS_CROSS_CORRELATION = config[\"connectome\"][\"min-animals\"]         # 'max'/None means that ALL the animals must have the region, otherwise the correlation is NaN\n",
    "if MIN_ANIMALS_CROSS_CORRELATION == \"max\":\n",
    "    MIN_ANIMALS_CROSS_CORRELATION = None\n",
    "ONLY_REGIONS_PRESENT_IN_ALL_GROUPS = config[\"connectome\"][\"only-regions-in-all-compared-groups\"]# if False, the correlation matrix and the chord plots of two groups may refer to different regions\n",
    "ONLY_REGIONS_WITH_SUFFICIENT_DATA = config[\"connectome\"][\"only-regions-with-sufficient-data\"]   # what to do with brain regions with less animals than MIN_ANIMALS_CROSS_CORRELATION\n",
    "\n",
    "# ######################################### CONNECTOME ##########################################\n",
    "FC_WEIGHTED = config[\"connectome\"][\"functional\"][\"weighted\"]\n",
    "PC_WEIGHTED = config[\"connectome\"][\"pruned\"][\"weighted\"]\n",
    "SC_WEIGHTED = config[\"connectome\"][\"structural\"][\"weighted\"]\n",
    "FC_USE_NEGATIVE_LINKS = config[\"connectome\"][\"functional\"][\"use-negative-links\"]\n",
    "PC_USE_NEGATIVE_LINKS = config[\"connectome\"][\"pruned\"][\"use-negative-links\"]\n",
    "FC_P_CUTOFF = config[\"connectome\"][\"functional\"][\"p-cutoff\"]\n",
    "FC_R_CUTOFF = config[\"connectome\"][\"functional\"][\"r-cutoff\"]\n",
    "SC_LOG10_CUTOFF = config[\"connectome\"][\"structural\"][\"log10-cutoff\"]\n",
    "\n",
    "if FC_USE_NEGATIVE_LINKS:\n",
    "    # see https://plotly.com/python/builtin-colorscales/\n",
    "    COLORSCALE = \"RdBu_r\"\n",
    "    CHORD_COLORSCALE_MIN = -1\n",
    "else:\n",
    "    COLORSCALE = \"Magma\"\n",
    "    CHORD_COLORSCALE_MIN = \"cutoff\"\n",
    "\n",
    "from collections import namedtuple\n",
    "GroupDirectory = namedtuple(\"GroupDirectory\", \"id name dirs\")\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        id=int(group[len(\"group\"):])-1,\n",
    "        name=config[\"experiment\"][group][\"name\"],\n",
    "        dirs=config[\"experiment\"][group][\"dirs\"]\n",
    "    ) for group in config[\"experiment\"] if group.startswith(\"group\") and group[len(\"group\"):].isdigit()\n",
    "]\n",
    "\n",
    "comparison_groups = config[\"comparison\"][str(COMPARISON_ID)][\"groups\"]\n",
    "Comparison = namedtuple(\"Comparison\", \"groups dir\")\n",
    "comparison = Comparison(\n",
    "    groups=[groups[id-1] for id in comparison_groups],\n",
    "    dir=config[\"comparison\"][str(COMPARISON_ID)][\"dir\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_path     = os.path.join(DATA_ROOT, \"BraiAn_output\")\n",
    "data_output_path    = os.path.join(data_input_path, comparison.dir)\n",
    "plots_output_path   = os.path.join(PLOTS_ROOT, comparison.dir)\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)\n",
    "\n",
    "if not(os.path.exists(plots_output_path)):\n",
    "    os.makedirs(plots_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "path_to_allen_json = os.path.join(project_path, \"data\", \"AllenMouseBrainOntology.json\")\n",
    "BraiAn.cache(path_to_allen_json, \"http://api.brain-map.org/api/v2/structure_graph_download/1.json\")\n",
    "AllenBrain = BraiAn.AllenBrainHierarchy(path_to_allen_json, BRANCHES_TO_EXCLUDE, use_literature_reuniens=USE_LITERATURE_REUNIENS, version=ATLAS_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_groups: list[BraiAn.AnimalGroup] = []\n",
    "for group in comparison.groups:\n",
    "    animal_group = BraiAn.AnimalGroup.from_csv(group.name, data_input_path, f\"cell_counts_{group.name}.csv\")\n",
    "    animal_groups.append(animal_group)\n",
    "    print(f\"Group '{animal_group.name}' - #animals: {animal_group.n}, marker: {animal_group.marker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match REGIONS_TO_PLOT_SELECTION_METHOD:\n",
    "    case \"summary structures\":\n",
    "        # selects the Summary Strucutures\n",
    "        path_to_summary_structures = os.path.join(project_path, \"data\", \"AllenSummaryStructures.csv\")\n",
    "        AllenBrain.select_from_csv(path_to_summary_structures, include_nre_tot=USE_LITERATURE_REUNIENS)\n",
    "    case \"nre to bla\":\n",
    "        # selects the NRe to BLA inputs\n",
    "        path_to_inputs = os.path.join(project_path, \"data\", \"NRe_to_BLA_inputs.csv\")\n",
    "        AllenBrain.select_from_csv(path_to_inputs, include_nre_tot=USE_LITERATURE_REUNIENS)\n",
    "        nre_bla_regions = AllenBrain.get_selected_regions()\n",
    "        nre_bla_regions += (\"REtot\", \"BLA\")\n",
    "        AllenBrain.select_regions(nre_bla_regions)\n",
    "    case \"major divisions\":\n",
    "        AllenBrain.select_regions(BraiAn.MAJOR_DIVISIONS)\n",
    "    case s if s.startswith(\"pls\"):\n",
    "        options = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")\n",
    "        assert len(options) == 3, \"The 'REGIONS_TO_PLOT_SELECTION_METHOD' option is invalid. Make sure it follows the follows the following pattern: \\\"pls <experiment> <salience_threshold>\\\" (e.g., \\\"pls proof 1.2\\\")\"\n",
    "        pls_experiment, pls_threshold = options[1:]\n",
    "        pls_threshold = pls_threshold.replace(\".\", \"_\")\n",
    "        assert len(animal_groups) == 2, f\"You can't use the PLS of '{pls_experiment}' for selecting the regions to plot because '{comparison.dir}' has too many groups ({len(animal_groups)})\"\n",
    "        pls_file = f\"pls_{animal_groups[0].marker}_{NORMALIZATION}_salient_regions_above_{pls_threshold}.csv\".lower()\n",
    "        regions_to_plot_pls_csv = os.path.abspath(os.path.join(DATA_ROOT, os.pardir, pls_experiment, \"BraiAn_output\", comparison.dir, pls_file))\n",
    "        assert os.path.isfile(regions_to_plot_pls_csv), f\"Could not find the file '{regions_to_plot_pls_csv}'\"\n",
    "        AllenBrain.select_from_csv(regions_to_plot_pls_csv, key=\"acronym\")\n",
    "    case s if s.startswith(\"depth\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            depth = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'depth' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        AllenBrain.select_at_depth(depth)\n",
    "    case s if s.startswith(\"structural level\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            level = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'structural level' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        AllenBrain.select_at_structural_level(level)\n",
    "    case _:\n",
    "        raise Exception(f\"Invalid value '{REGIONS_TO_PLOT_SELECTION_METHOD}' for REGIONS_TO_PLOT_SELECTION_METHOD\")\n",
    "\n",
    "if len(GROUPED_REGIONS) > 0:\n",
    "    AllenBrain.add_to_selection(GROUPED_REGIONS)\n",
    "regions_to_plot = AllenBrain.get_selected_regions()\n",
    "print(f\"You selected {len(regions_to_plot)} regions to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal_group in animal_groups:\n",
    "    animal_group.remove_smaller_subregions(MIN_AREA, regions_to_plot, AllenBrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATRIX_SAVE_PLOT or MATRIX_SHOW_PLOT or CHORD_SAVE_PLOT or CHORD_SHOW_PLOT:\n",
    "    groups_cross_correlations = [BraiAn.CrossCorrelation(g, regions_to_plot, AllenBrain, NORMALIZATION, MIN_ANIMALS_CROSS_CORRELATION, g.name) for g in animal_groups]\n",
    "    \n",
    "    if ONLY_REGIONS_PRESENT_IN_ALL_GROUPS:\n",
    "        BraiAn.CrossCorrelation.make_comparable(*groups_cross_correlations)\n",
    "    if ONLY_REGIONS_WITH_SUFFICIENT_DATA:\n",
    "        for cc in groups_cross_correlations:\n",
    "            cc.remove_insufficient_regions()\n",
    "    regions_to_plot_selection_method_str = REGIONS_TO_PLOT_SELECTION_METHOD.replace(\".\", \"_\").replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATRIX_SAVE_PLOT or MATRIX_SHOW_PLOT:\n",
    "    for group, cc in zip(animal_groups, groups_cross_correlations):\n",
    "        title = f\"{group.name} Pearson cross correlation matrix (n = {group.n})\"\n",
    "        fig = cc.plot(\n",
    "                title=title,\n",
    "                cell_height=MATRIX_CELL_HEIGHT, min_plot_height=MATRIX_MIN_PLOT_HEIGHT,\n",
    "                star_size=MATRIX_STAR_SIZE, aspect_ratio=MATRIX_CELL_RATIO,\n",
    "                # color_min=-1, color_max=1,\n",
    "                color_min=0, color_max=1, colorscale=COLORSCALE\n",
    "                )\n",
    "        if MATRIX_SAVE_PLOT:\n",
    "            plot_filename = f\"correlation_matrix_min{MIN_ANIMALS_CROSS_CORRELATION}_{group.name}_{group.marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "            plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "            match SAVED_PLOT_EXTENSION.lower():\n",
    "                case \".html\":\n",
    "                    fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "                case _:\n",
    "                    fig.write_image(plot_filepath)\n",
    "        if MATRIX_SHOW_PLOT:\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCs = []\n",
    "for animal_group, cc in zip(animal_groups, groups_cross_correlations):\n",
    "    connectome = BraiAn.FunctionalConnectome(cc,\n",
    "                                         p_cutoff=FC_P_CUTOFF, r_cutoff=FC_R_CUTOFF,\n",
    "                                         negatives=FC_USE_NEGATIVE_LINKS, weighted=FC_WEIGHTED)\n",
    "    FCs.append(connectome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_str = str(FC_P_CUTOFF).replace(\".\", \"_\")\n",
    "r_str = str(FC_R_CUTOFF).replace(\".\", \"_\")\n",
    "for fc in FCs:\n",
    "    # if REGIONS_TO_PLOT_SELECTION_METHOD == \"nre to bla\" and \"REtot\" in cc.p.index:\n",
    "    #     connectome = connectome.region_subgraph(\"REtot\", isolated_vertices=True)\n",
    "    title = f\"{fc.name} connectomics graph from Pearson correlation (n = {fc.n}, {'|r|' if FC_USE_NEGATIVE_LINKS else 'r'} >= {fc.r_cutoff}, p <= {fc.p_cutoff})\"\n",
    "    fig = BraiAn.draw_chord_plot(fc,\n",
    "                                AllenBrain=AllenBrain,\n",
    "                                ideograms_arc_index=50,\n",
    "                                title=title,\n",
    "                                size=CHORD_PLOT_SIZE,\n",
    "                                no_background=CHORD_NO_BACKGROUND,\n",
    "                                isolated_regions=CHORD_PLOT_ISOLATED_REGIONS,\n",
    "                                regions_size=CHORD_REGIONS_SIZE,\n",
    "                                regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "                                max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "                                use_weighted_edge_widths=CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "                                colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "                                colorscale=COLORSCALE,\n",
    "                                colorscale_min=CHORD_COLORSCALE_MIN,\n",
    "    )\n",
    "    fig.show()\n",
    "    # filename = f\"chord_plot_min{MIN_ANIMALS_CROSS_CORRELATION}_p{p_str}_r{r_str}_{animal_group.name.lower()}_{animal_groups[0].marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}.html\"\n",
    "    # fig.write_html(filename.lower(), config=dict(toImageButtonOptions=dict(format=\"svg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for animal_group, cc in zip(animal_groups, groups_cross_correlations):\n",
    "for fc in FCs:\n",
    "    #if REGIONS_TO_PLOT_SELECTION_METHOD == \"nre to bla\" and \"REtot\" in cc.p.index:\n",
    "    #    connectome = connectome.region_subgraph(\"REtot\", isolated_vertices=False)\n",
    "    fc.cluster_regions(*clustering_args)\n",
    "    fc.participation_coefficient(weights=False) # doesn't work on weighted connectomics\n",
    "    \n",
    "    title = f\"{fc.name} connectomics graph from Pearson correlation (n = {fc.n}, {'|r|' if FC_USE_NEGATIVE_LINKS else 'r'} >= {fc.r_cutoff}, p <= {fc.p_cutoff})\"\n",
    "    random.seed(0) # used by layout_fun to arrange the nodes of the connectome\n",
    "    fig = BraiAn.draw_network_plot(fc, layout_fun, AllenBrain, title=title,\n",
    "                                   isolated_regions=False,\n",
    "                                   use_centrality=True, centrality_metric=\"Participation coefficient\", width=1250)\n",
    "    fig.show()\n",
    "    # filename = f\"network_min{MIN_ANIMALS_CROSS_CORRELATION}_p{p_str}_r{r_str}_{animal_group.name.lower()}_{animal_groups[0].marker}_{NORMALIZATION}_{regions_to_plot_selection_method_str}.html\"\n",
    "    # fig.write_html(filename.lower(), config=dict(toImageButtonOptions=dict(format=\"svg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from https://download.alleninstitute.org/publications/A_high_resolution_data-driven_model_of_the_mouse_connectome/\n",
    "normalized_connection_density_file = os.path.join(project_path, \"data\",\n",
    "                                                    \"A_high_resolution_data-driven_model_of_the_mouse_connectome\",\n",
    "                                                    \"normalized_connection_density.csv\")\n",
    "BraiAn.cache(normalized_connection_density_file,\n",
    "             \"https://download.alleninstitute.org/publications/A_high_resolution_data-driven_model_of_the_mouse_connectome/normalized_connection_density.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allen_connectome = BraiAn.StructuralConnectome(normalized_connection_density_file, regions_to_plot, AllenBrain, mode=\"max\", log10_cutoff=SC_LOG10_CUTOFF, weighted=SC_WEIGHTED, isolated_vertices=False)\n",
    "print(f\"\"\"\n",
    "Max: {allen_connectome.A.max()}\n",
    "Mean: {allen_connectome.A.mean()}+-{allen_connectome.A.std()}\n",
    "Mean (log10): {allen_connectome.A.mean(log=True)}+-{allen_connectome.A.std(log=True)}\n",
    "Density: {allen_connectome.G.density()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as Figure 2 in https://direct.mit.edu/netn/article/3/1/217/2194/High-resolution-data-driven-model-of-the-mouse\n",
    "fig = allen_connectome.plot_adjacency(color_min=-5, color_max=-2.5, cell_height=4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = allen_connectome.G.vs.select(name=\"RE\")[0]\n",
    "print(\"RE->BLA density:\", allen_connectome.A.data.loc[\"RE\", \"BLA\"], f\"(log10={np.log10(allen_connectome.A.data.loc['RE', 'BLA'])})\")\n",
    "print(\"BLA->RE density:\", allen_connectome.A.data.loc[\"BLA\", \"RE\"], f\"(log10={np.log10(allen_connectome.A.data.loc['BLA', 'RE'])})\")\n",
    "print(\"RE->ILA density:\", allen_connectome.A.data.loc[\"RE\", \"ILA\"], f\"(log10={np.log10(allen_connectome.A.data.loc['RE', 'ILA'])})\")\n",
    "print(\"ILA->RE density:\", allen_connectome.A.data.loc[\"ILA\", \"RE\"], f\"(log10={np.log10(allen_connectome.A.data.loc['ILA', 'RE'])})\")\n",
    "print(\"BLA->Xi density:\", allen_connectome.A.data.loc[\"BLA\", \"Xi\"], f\"(log10={np.log10(allen_connectome.A.data.loc['BLA', 'Xi'])})\")\n",
    "print(\"Xi->BLA density:\", allen_connectome.A.data.loc[\"Xi\", \"BLA\"], f\"(log10={np.log10(allen_connectome.A.data.loc['Xi', 'BLA'])})\")\n",
    "\n",
    "print(f\"\\nNetwork with log10(density) cutoff={SC_LOG10_CUTOFF} ({10**SC_LOG10_CUTOFF})\")\n",
    "print(\"\\tRE Degree:\", re.degree(), f\"({re.indegree()}+{re.outdegree()})\")\n",
    "# for e in re.all_edges():\n",
    "#     print(f\"\\t\\t{e.source_vertex['name']}->{e.target_vertex['name']}: {e['weight']:.3f} ({10**e['weight']:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    fig = BraiAn.draw_chord_plot(allen_connectome,\n",
    "                                AllenBrain=AllenBrain,\n",
    "                                ideograms_arc_index=50,\n",
    "                                title=allen_connectome.name+f\" [log10(normalized density) >= {SC_LOG10_CUTOFF}]\",\n",
    "                                size=CHORD_PLOT_SIZE,\n",
    "                                no_background=CHORD_NO_BACKGROUND,\n",
    "                                regions_size=CHORD_REGIONS_SIZE,\n",
    "                                regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "                                max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "                                use_weighted_edge_widths=False, #CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "                                colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "                                colorscale=COLORSCALE,\n",
    "                                colorscale_min=10**SC_LOG10_CUTOFF,\n",
    "                                colorscale_max=10**(-2.5) #np.log10(allen_connection_matrix.A.max(axis=None))\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCs_pruned = []\n",
    "for cc in groups_cross_correlations:\n",
    "    fc_pruned = BraiAn.PrunedConnectomics(allen_connectome, cc, FC_P_CUTOFF, FC_R_CUTOFF, negatives=PC_USE_NEGATIVE_LINKS, weighted=PC_WEIGHTED, isolated_vertices=True)\n",
    "    fc_pruned.G.vs[\"Degree\"] = fc_pruned.G.degree(mode=\"all\")\n",
    "    fc_pruned.G.vs[\"In-degree\"] = fc_pruned.G.degree(mode=\"in\")\n",
    "    fc_pruned.G.vs[\"Out-degree\"] = fc_pruned.G.degree(mode=\"out\")\n",
    "    fc_pruned.G.vs[\"Strength\"] = fc_pruned.G.strength(mode=\"all\")\n",
    "    fc_pruned.G.vs[\"Betweeness\"] = fc_pruned.G.betweenness(directed=True)#, weights=\"weight\")\n",
    "    fc_pruned.G.vs[\"Closeness (out)\"] = fc_pruned.G.closeness(mode=\"out\", normalized=True)#, weights=\"weight\")\n",
    "    fc_pruned.G.vs[\"Harmonic (out)\"] = fc_pruned.G.harmonic_centrality(mode=\"out\", normalized=True)#, weights=\"weight\")\n",
    "    fc_pruned.G.vs[\"PageRank\"] = fc_pruned.G.pagerank(directed=True)#, weights=\"weight\")\n",
    "    fc_pruned.G.vs[\"Eigenvector\"] = fc_pruned.G.eigenvector_centrality(scale=True, directed=True, weights=None)\n",
    "    fc_pruned.cluster_regions(ig.Graph.community_infomap)\n",
    "    FCs_pruned.append(fc_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control group\n",
    "for fc, fc_pruned in zip(FCs, FCs_pruned):\n",
    "    print(fc.name, end=\":\\n\")\n",
    "    print(\"\\t#nodes (functional):\", fc.G.vcount())\n",
    "    print(\"\\t#nodes (pruned):\", fc_pruned.G.vcount())\n",
    "    print(\"\\t#edges (functional):\", fc.G.ecount()) # undirected --> multiply by 2\n",
    "    print(\"\\t#edges (pruned):\", fc_pruned.G.ecount())\n",
    "    print(\"\\tavg pruning-survivor edges:\", fc_pruned.G.ecount() / 2, f\"({fc_pruned.G.ecount()/(fc.G.ecount()*2)*100:0.3f}%)\")\n",
    "    print(\"\\tdensity (structural):\", allen_connectome.G.density())\n",
    "    print(\"\\tdensity (functional):\", fc.G.density())\n",
    "    print(\"\\tdensity (pruned):\", fc_pruned.G.density())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are edges that where cut still reachable?\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "for fc, fc_pruned in zip(FCs, FCs_pruned):\n",
    "    ds_pruned = fc_pruned.get_functional_neighbors_distances()\n",
    "    ds_unique, ds_counts = np.unique(ds_pruned, return_counts=True)\n",
    "    fig = go.Figure(\n",
    "            go.Pie(\n",
    "                labels=[int(d) if not np.isinf(d) else \"infinite\" for d in ds_unique],\n",
    "                values=ds_counts,\n",
    "                marker=dict(\n",
    "                    line=dict(color=\"#000000\", width=2)\n",
    "                ),\n",
    "                hovertemplate = \"<b>Pruned distance</b>: %{label}<br>\"+\n",
    "                                \"<b>#functional connection</b>: %{value} (%{percent})<extra></extra>\",\n",
    "                sort=False,\n",
    "                textfont=dict(size=12),\n",
    "                hole=0.3,\n",
    "                textinfo=\"label\", textposition=\"outside\",\n",
    "                showlegend=True\n",
    "            ))\n",
    "    title = f\"{fc_pruned.name}: minimum distance between regions that previously to pruning were functionally connected\"\n",
    "    fig.update_layout(title=title)\n",
    "    fig.show()\n",
    "    # reached_ds_pruned = ds_pruned[~np.isinf(ds_pruned)]\n",
    "    # n_unreachable_es = len(ds_pruned) - len(reached_ds_pruned)\n",
    "    # print(n_unreachable_es, len(reached_ds_pruned), np.mean(reached_ds_pruned), np.std(reached_ds_pruned))\n",
    "    # # percentage of unreachable brain regions that were previously functionally connected\n",
    "    # print(n_unreachable_es / fc.G.ecount() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_pruned_A = BraiAn.ConnectomeAdjacency(fc_pruned.A, AllenBrain)\n",
    "fig = fc_pruned_A.plot(cell_height=4, colorscale=COLORSCALE, color_max=1)\n",
    "fig.update_layout(yaxis=dict(scaleanchor=\"x\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fc_pruned in FCs_pruned:\n",
    "    title = f\"{fc_pruned.name} [n = {cc.n}, {'|r|' if PC_USE_NEGATIVE_LINKS else 'r'} >= {fc_pruned.r_cutoff}, p <= {fc_pruned.p_cutoff}, d >= {10**SC_LOG10_CUTOFF}]\"\n",
    "    random.seed(0) # used by layout_fun to arrange the nodes of the connectome\n",
    "    fig = BraiAn.draw_network_plot(fc_pruned, layout_fun, AllenBrain, title=title, use_centrality=True, centrality_metric=\"Harmonic (out)\", width=1000, isolated_regions=False)\n",
    "    # fig = BraiAn.draw_network_plot(fc_pruned, layout_fun, AllenBrain, title=title, use_centrality=False, use_clustering=False, width=1000, isolated_regions=False)\n",
    "    # fig = BraiAn.draw_chord_plot(fc_pruned,\n",
    "    #                             AllenBrain=AllenBrain,\n",
    "    #                             ideograms_arc_index=50,\n",
    "    #                             title=title,\n",
    "    #                             size=CHORD_PLOT_SIZE,\n",
    "    #                             no_background=CHORD_NO_BACKGROUND,\n",
    "    #                             isolated_regions=False,\n",
    "    #                             regions_size=CHORD_REGIONS_SIZE,\n",
    "    #                             regions_font_size=CHORD_REGIONS_FONT_SIZE,\n",
    "    #                             max_edge_width=CHORD_MAX_EDGE_WIDTH,\n",
    "    #                             use_weighted_edge_widths=CHORD_USE_WEIGHTED_EDGE_WIDTHS,\n",
    "    #                             colorscale_edges=CHORD_USE_COLORSCALE_EDGES,\n",
    "    #                             colorscale=CHORD_COLORSCALE,\n",
    "    #                             colorscale_min=NETWORK_R_CUTOFF, #CHORD_COLORSCALE_MIN,\n",
    "    # )\n",
    "    fig.show()\n",
    "    # fig.write_html(f\"chord_{fc_pruned.name.lower()}.html\")\n",
    "    # fig.write_html(f\"{fc_pruned.name.lower()}.html\") #_r{NETWORK_R_CUTOFF}_p{NETWORK_P_CUTOFF}_d{log10_cutoff}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = fc_pruned.G.vs.select(name=\"VPL\")[0]\n",
    "for e in re.all_edges():\n",
    "    d = e[\"weight\"] # fc_pruned. .data.loc[e.source_vertex['name'], e.target_vertex['name']]\n",
    "    p = cc.p.data.loc[e.source_vertex['name'], e.target_vertex['name']]\n",
    "    print(d >= 10**SC_LOG10_CUTOFF, 10**SC_LOG10_CUTOFF, SC_LOG10_CUTOFF)\n",
    "    print(f\"{e.source_vertex['name']}->{e.target_vertex['name']}: r={e['weight']:.3f} p={p:.4f} d={d:.5f} ({np.log10(d):.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "def importance_score(scores, ranks):\n",
    "    return 1/np.sqrt(ranks+1)\n",
    "    #return 1/(ranks+1)\n",
    "\n",
    "def normalize(x: np.array, nmin=0):\n",
    "    x = x-nmin #np.nanmin(x)\n",
    "    return x/np.nanmax(x)\n",
    "\n",
    "def normalize_centrality(vs: ig.VertexSeq, centrality: str):\n",
    "    if centrality not in vs.attributes():\n",
    "        raise ValueError(f\"Invalid attribute name for centrality '{centrality}'\")\n",
    "    return normalize(np.asarray(vs[centrality]))\n",
    "\n",
    "def get_ranks(vs: ig.VertexSeq, centrality: str):\n",
    "    if centrality not in vs.attributes():\n",
    "        raise ValueError(f\"Invalid attribute name for centrality '{centrality}'\")\n",
    "    centrality_scores = np.nan_to_num(vs[centrality], copy=False, nan=0.0)\n",
    "    i_sorted_centrality = np.flip(np.argsort(centrality_scores))\n",
    "    centrality_scores = centrality_scores[i_sorted_centrality]\n",
    "    _, unique_ranks = np.unique(centrality_scores, return_index=True) # returns indices of the unique centrality scores (in ascending order)\n",
    "    ranks_repetitions = unique_ranks[:-1]-unique_ranks[1:]\n",
    "    ranks_repetitions = np.insert(ranks_repetitions, 0, len(vs)-unique_ranks[0])\n",
    "    ranks = np.repeat(unique_ranks, ranks_repetitions)\n",
    "    return ranks[np.flip(i_sorted_centrality).argsort()]\n",
    "\n",
    "def centrality_barplot(G: ig.Graph, centrality, group_by, offsetgroup, first_n, **kwargs):\n",
    "    # group_by is, most probably, either 'upper_region', 'cluster', or 'name'\n",
    "    if centrality not in G.vs.attributes():\n",
    "        raise ValueError(f\"Invalid attribute name for centrality '{centrality}'\")\n",
    "    if first_n is not None:\n",
    "        vs_indices = sorted(G.vs.indices, key=lambda i: np.nan_to_num(G.vs[i][centrality], nan=0.0), reverse=True)[:first_n]\n",
    "    else:\n",
    "        vs_indices = G.vs.indices\n",
    "    sorted_vs = sorted(vs_indices, key=lambda i: (G.vs[i][group_by], np.nan_to_num(G.vs[i][centrality], nan=0.0)), reverse=True)\n",
    "    sorted_vs = ig.VertexSeq(G, sorted_vs)\n",
    "    # normalization on max can only be done if\n",
    "    scores = normalize_centrality(sorted_vs, centrality)\n",
    "    ranks = get_ranks(sorted_vs, centrality)\n",
    "    return go.Bar(\n",
    "        x=sorted_vs[group_by],\n",
    "        y=normalize(scores),\n",
    "        hovertext=[\n",
    "            f\"Region: {v['name']}<br>\"+\n",
    "            f\"{centrality}: {v[centrality]:.5f}<br>\"+\n",
    "            f\"rank: {rank}\"\n",
    "            for v,rank in zip(sorted_vs, ranks)],\n",
    "        name=centrality,\n",
    "        offsetgroup=offsetgroup,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "def plot_centralities(connectome: BraiAn.Connectome, *attrs: str, group_by=\"upper_region\", first_n=None, **kwargs):\n",
    "    barplots = []\n",
    "    for i, centrality in enumerate(attrs):\n",
    "        barplot = centrality_barplot(connectome.G, centrality, group_by=group_by, offsetgroup=i, first_n=first_n, **kwargs)\n",
    "        barplots.append(barplot)\n",
    "    return go.Figure(\n",
    "        data=barplots,\n",
    "        layout=dict(\n",
    "            title=f\"Regions ranks with different metrics (grouped by '{group_by}')\",\n",
    "            yaxis=dict(\n",
    "                title=\"Normalized centrality score\",\n",
    "                side=\"left\",\n",
    "            ),\n",
    "        ))\n",
    "\n",
    "for fc_pruned in FCs_pruned:\n",
    "    # \"Degree\", \"In-degree\", \"Out-degree\", \"Strength\" # these metrics appear to roughly say the same thing in all connectomes\n",
    "    # fig = plot_centralities(fc_pruned, \"Degree\", \"Betweeness\", \"Eigenvector\", \"PageRank\", \"Closeness (out)\", group_by=\"upper_region\") #, \"Harmonic (out)\")\n",
    "    fig = plot_centralities(fc_pruned, \"Degree\", \"Betweeness\", \"Eigenvector\", \"PageRank\", \"Harmonic (out)\", group_by=\"name\", first_n=20) #\"upper_region\") #, \"Harmonic (out)\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.asarray(\n",
    "[[0,   1,   0.1, 0],\n",
    " [1,   0,   0,   1],\n",
    " [0.1, 0,   0,   0.1], \n",
    " [0,   1,   0.1, 0]])\n",
    "G = ig.Graph.Weighted_Adjacency(A, loops=False)\n",
    "G.get_all_shortest_paths(0, to=3), G.get_shortest_paths(0, to=3, weights=1/np.asarray(G.es[\"weight\"], dtype=float), output=\"vpath\"), G.get_shortest_paths(0, to=3, weights=\"weight\", output=\"vpath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp = connectome.G.get_shortest_paths(0, to=5, output=\"epath\")\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "def random_walk_probability(G: ig.Graph, path, use_weights=True):\n",
    "    if len(path) == 0:\n",
    "        # the two nodes are unreachable\n",
    "        return 0\n",
    "    if type(path) != ig.EdgeSeq:\n",
    "        path = G.es[path]\n",
    "    if G.is_weighted() and use_weights:\n",
    "        weights = functools.reduce(operator.mul, path[\"weight\"], 1)\n",
    "        source_strengths = functools.reduce(lambda res, e: res * e.source_vertex.strength(mode=\"out\", loops=False, weights=\"weight\"), path, 1)\n",
    "    else:\n",
    "        weights = 1\n",
    "        source_strengths = functools.reduce(lambda res, e: res * e.source_vertex.outdegree(loops=False), path, 1)\n",
    "    return weights / source_strengths\n",
    "\n",
    "# test random_walk_probability\n",
    "outdegree = 2\n",
    "v_start = np.where(np.asarray(fc_pruned.G.outdegree(), dtype=int) == outdegree)[0][0]\n",
    "v_end = fc_pruned.G.vs[v_start].neighbors()[0].index\n",
    "remapped_weights = 1/np.asarray(fc_pruned.G.es[\"weight\"], dtype=float)\n",
    "# igraph intends weights as \"cost\" not as \"strength\"\n",
    "sp = fc_pruned.G.get_shortest_paths(v_start, to=v_end, weights=remapped_weights, output=\"epath\")[0]\n",
    "random_walk_probability(fc_pruned.G, sp, use_weights=False), sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for connectome in itertools.chain.from_iterable(zip(FCs, FCs_pruned)):\n",
    "    go.Figure(\n",
    "        [go.Histogram(\n",
    "            x=connectome.G.degree(),\n",
    "            xbins=dict(start=0, size=2,)\n",
    "        )],\n",
    "        layout=dict(\n",
    "            # bargap=0.1,\n",
    "            title=f\"{connectome.name}: degree distribution\"\n",
    "        )\n",
    "    #    layout=dict(bargap=0.1)\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "\n",
    "def path_length(G: ig.Graph, unreachable_nodes=True):\n",
    "    if G.is_weighted():\n",
    "        ds = np.asarray(G.distances(weights=np.abs(G.es[\"weight\"])), dtype=float)\n",
    "    else:\n",
    "        ds = np.asarray(G.distances(), dtype=float)\n",
    "    if unreachable_nodes:\n",
    "        ds[ds == np.inf] = 0\n",
    "        N = G.vcount()\n",
    "        return ds.sum(axis=0) / (N-1)\n",
    "    else:\n",
    "        ds[ds == np.inf] = np.nan\n",
    "        Ns = (~np.isnan(ds)).sum(axis=0, dtype=float)\n",
    "        den = Ns - 1\n",
    "        den[den == 0] = np.nan\n",
    "        return np.nansum(ds, axis=0) / den\n",
    "\n",
    "def average_path_length(G: ig.Graph, unreachable_nodes=True):\n",
    "    # if unreachable_nodes=False, it's equal to igraph.Graph.average_path_length(unconn=True)\n",
    "    if G.is_weighted():\n",
    "        ds = np.asarray(G.distances(weights=np.abs(G.es[\"weight\"]), mode=\"out\"), dtype=float)\n",
    "    else:\n",
    "        ds = np.asarray(G.distances(), dtype=float)\n",
    "    if unreachable_nodes:\n",
    "        ds[ds == np.inf] = 0\n",
    "        N = G.vcount()\n",
    "        return ds.sum() / (N * (N - 1))\n",
    "    else:\n",
    "        ds = ds[ds != np.inf]\n",
    "        return ds.sum() / (len(ds) - G.vcount())\n",
    "\n",
    "# import networkx as nx\n",
    "\n",
    "# Gnx = nx.Graph([])\n",
    "# Gnx.add_node(1)\n",
    "# nx.global_efficiency(Gnx) # <- returns 0\n",
    "def nodal_efficiency(G: ig.Graph): # same as harmonic centrality (normalized and mode=\"out\")\n",
    "    # https://en.wikipedia.org/wiki/Efficiency_(network_science)\n",
    "    N = G.vcount()\n",
    "    if N == 0:\n",
    "        raise ValueError(\"Empty graph\")\n",
    "    elif N == 1:\n",
    "#        return np.full(N, 1, dtype=float)\n",
    "        return np.full(N, 0, dtype=float)\n",
    "    if G.is_weighted():\n",
    "        # ws = np.abs(1.0 / np.asarray(G.es[\"weight\"], dtype=float))\n",
    "        ws = np.abs(np.asarray(G.es[\"weight\"], dtype=float))\n",
    "        ds = np.asarray(G.distances(mode=\"out\", weights=ws), dtype=float)\n",
    "    else:\n",
    "        ds = np.asarray(G.distances(mode=\"out\"), dtype=float)\n",
    "    np.fill_diagonal(ds, np.NaN)\n",
    "    efficiency = 1 / ds\n",
    "    np.fill_diagonal(efficiency, 0) # we don't want to consider pathlength to itself\n",
    "    ne = np.apply_along_axis(sum, 1, efficiency) / (N-1)\n",
    "    return ne\n",
    "\n",
    "def global_efficiency(G):\n",
    "    if G.vcount() == 0:\n",
    "        return np.nan\n",
    "    # return np.asarray(G.harmonic_centrality(mode=\"out\", normalized=True, weights=\"weight\" if G.is_weighted() else None))\n",
    "    return nodal_efficiency(G).mean()\n",
    "\n",
    "def local_efficiency(G, zero_degree=True):\n",
    "    local_efficiency_i = []\n",
    "    for i in range(G.vcount()):\n",
    "        G_i = G.induced_subgraph(G.neighbors(i), \"create_from_scratch\")\n",
    "        global_efficiency_i = global_efficiency(G_i)\n",
    "        local_efficiency_i.append(global_efficiency_i)\n",
    "    if zero_degree:\n",
    "        return np.nansum(np.asarray(local_efficiency_i)) / len(local_efficiency_i)\n",
    "    else:\n",
    "        return np.nanmean(np.asarray(local_efficiency_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for connectome in itertools.chain.from_iterable(zip(FCs, FCs_pruned)):\n",
    "    print(f\"{connectome.name} global efficiency:\", global_efficiency(connectome.G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(G: ig.Graph):\n",
    "    print(f\"\"\"\n",
    "    INFO:\n",
    "        graph type: {'Weighted' if G.is_weighted() else 'Not weighted'}\n",
    "        #regions: {G.vcount()}\n",
    "        #connected regions: {len([d for d in G.degree() if d > 0])}\n",
    "        Max degree: {G.maxdegree()}\n",
    "    SEGREGATION:\n",
    "        Cluster coefficient: {G.transitivity_undirected()}\n",
    "        Mean local cluster coefficient (d>=2): {np.nanmean(G.transitivity_local_undirected())}\n",
    "        Mean local cluster coefficient (all): {np.nansum(G.transitivity_local_undirected()) / G.vcount()}\n",
    "        Local efficiency (d>=1): {local_efficiency(G, zero_degree=False)}\n",
    "        Local efficiency (all): {local_efficiency(G, zero_degree=True)}\n",
    "    INTEGRATION_\n",
    "        Global efficiency: {global_efficiency(G)}\n",
    "        Avg path length (∞ -> 0): {path_length(G, unreachable_nodes=True).mean()}\n",
    "        Avg path length (no ∞): {G.average_path_length(unconn=True)}\n",
    "        Median [characteristic] path lengh (∞ -> 0): {np.nanmedian(path_length(G, unreachable_nodes=True))}\n",
    "        Median [characteristic] path lengh (no ∞): {np.nanmedian(path_length(G, unreachable_nodes=False))}\n",
    "    \"\"\")\n",
    "\n",
    "print_stats(connectome.G)\n",
    "print_stats(fc_pruned.G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: certain measures of statistical dependence used to quantify functional connectivity can bias\n",
    "# network organization in a way that cannot be removed by topological rewiring.\n",
    "# \n",
    "G_rewired = FCs[1].G.copy()\n",
    "G_rewired.rewire(mode=\"loops\")      # functional connectomes are inherently more clustered and exaggerate features such as small-worldness.\n",
    "                                    # We should use Maslov-Sneppen rewiring method (Bullmore, et al. 2016 - Fundamentals of Brain Network Analysis, chapter 10.3)\n",
    "#G_rewired.rewire(mode=\"simple\")    # does not create/destroy loop edges. If you allow it, you may change the degrees\n",
    "G_rewired.es[\"weight\"] = FCs[1].G.es[\"weight\"]\n",
    "print_stats(G_rewired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_collapsed = fc_pruned\n",
    "for subregion in AllenBrain.direct_subregions[\"Isocortex\"]:\n",
    "    fc_collapsed = fc_collapsed.collapse_region(AllenBrain, subregion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_collapsed.G.vs[\"Degree\"] = fc_collapsed.G.degree(mode=\"all\")\n",
    "fc_collapsed.G.vs[\"In-degree\"] = fc_collapsed.G.degree(mode=\"in\")\n",
    "fc_collapsed.G.vs[\"Out-degree\"] = fc_collapsed.G.degree(mode=\"out\")\n",
    "fc_collapsed.G.vs[\"Strength\"] = fc_collapsed.G.strength(mode=\"all\")\n",
    "fc_collapsed.G.vs[\"Betweeness\"] = fc_collapsed.G.betweenness(directed=True)#, weights=\"weight\")\n",
    "fc_collapsed.G.vs[\"Closeness (out)\"] = fc_collapsed.G.closeness(mode=\"out\", normalized=True)#, weights=\"weight\")\n",
    "fc_collapsed.G.vs[\"Harmonic (out)\"] = fc_collapsed.G.harmonic_centrality(mode=\"out\", normalized=True)#, weights=\"weight\")\n",
    "fc_collapsed.G.vs[\"PageRank\"] = fc_collapsed.G.pagerank(directed=True)#, weights=\"weight\")\n",
    "fc_collapsed.G.vs[\"Eigenvector\"] = fc_collapsed.G.eigenvector_centrality(scale=True, directed=True, weights=None)\n",
    "fc_collapsed.cluster_regions(ig.Graph.community_infomap)\n",
    "from BraiAn.connectome.utils_bu import participation_coefficient\n",
    "fc_collapsed.G.vs[\"Participation coefficient\"] = participation_coefficient(fc_collapsed.G, fc_collapsed.vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f\"{fc_collapsed.name}\"\n",
    "random.seed(0) # used by layout_fun to arrange the nodes of the connectome\n",
    "fig = BraiAn.draw_network_plot(fc_collapsed, layout_fun, AllenBrain, title=title, use_centrality=True, centrality_metric=\"Harmonic (out)\", width=1000, isolated_regions=False)\n",
    "# fig = BraiAn.draw_network_plot(fc_collapsed, layout_fun, AllenBrain, title=title, use_centrality=True, centrality_metric=\"Participation coefficient\", width=1000, isolated_regions=False, use_clustering=True)\n",
    "# fig = BraiAn.draw_network_plot(fc_pruned, layout_fun, AllenBrain, title=title, use_centrality=False, use_clustering=False, width=1000, isolated_regions=False)\n",
    "fig.show()\n",
    "# fig.write_html(f\"chord_{fc_pruned.name.lower()}.html\")\n",
    "fig.write_html(f\"{fc_collapsed.name.lower()}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "__imported_modules = sys.modules.copy()\n",
    "for module_name, module in __imported_modules.items():\n",
    "    if not module_name.startswith(\"BraiAn\"):\n",
    "        continue\n",
    "    try:\n",
    "        importlib.reload(module)\n",
    "    except ModuleNotFoundError:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
