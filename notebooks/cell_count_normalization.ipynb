{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABBA cell count analysis\n",
    "\n",
    "This notebook is the last step in the ABBA whole-brain cell counting analysis.  \n",
    "It assumes you have done the following steps:\n",
    "- Alignment of brain slices in ABBA, exported to a QuPath project.\n",
    "- Detected cells of interest in QuPath. The detections should be exported to ```.csv``` files (one per slice) in a folder called ```results```. \n",
    "- If there are regions to exclude, you should have drawn them and exported to ```.txt``` files (one per slice) in a folder called ```regions_to_exclude```.\n",
    "\n",
    "Run this notebook to load the cell counts and do analysis on them. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start ...\n",
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIRECTORY = \"p4\"\n",
    "USE_LOCAL_DATA = False                                      # if False, it tries to read the data on the laboratory's server\n",
    "IS_COLLABORATION_PROJ = False\n",
    "import os\n",
    "COLLABORATION_DIRECTORY = os.path.join(\"Mathias Schmidt\", \"soumnya\")\n",
    "\n",
    "# ###################################### LOCAL DIRECTORIES ######################################\n",
    "# DATA_ROOT  = f\"../data/experiments/soumnya/{EXPERIMENT_DIRECTORY}\"\n",
    "# PLOTS_ROOT = f\"../plots/soumnya/{EXPERIMENT_DIRECTORY}/\"\n",
    "DATA_ROOT  = f\"../data/experiments/{EXPERIMENT_DIRECTORY}\"\n",
    "PLOTS_ROOT = f\"../plots/{EXPERIMENT_DIRECTORY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### GENERAL OPTIONS #######################################\n",
    "BRANCHES_TO_EXCLUDE = [\"retina\", \"VS\", \"grv\", \"fiber tracts\", \"CB\"]\n",
    "USE_LITERATURE_REUNIENS = True                             # add a 'REtot' region, merging the following regions: 'PR', 'RE', 'Xi', 'RH'\n",
    "PLOT_ALLENBRAIN_HIERARCHY = False\n",
    "PLOT_ANIMALS_ROOTS = True\n",
    "PLOT_COEFFICIENT_OF_VARIATION = True\n",
    "PLOT_COEFFICIENT_OF_VARIATION_THRESHOLD = 1\n",
    "\n",
    "# ###################################### DATA LOAD OPTIONS ######################################\n",
    "AREA_KEY = \"Area um^2\"\n",
    "TRACER_KEY = \"Num AF647\"\n",
    "MARKER = \"CFos\"\n",
    "\n",
    "# ###################################### DATA SAVE OPTIONS ######################################\n",
    "ANIMAL_BRAIN_MODE = \"sum\"                                   # available options are: 'sum', 'mean'/'avg', 'std', 'variation'/'cvar'\n",
    "SAVE_ANIMALS = True\n",
    "SAVE_GROUPS = True\n",
    "\n",
    "# ###############################################################################################\n",
    "from collections import namedtuple\n",
    "GroupDirectory = namedtuple(\"GroupDirectory\", \"name dirs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA FEMALES+MALES - 2 Groups {Stress|Control}\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        name=\"Control\",\n",
    "        dirs=[\"41CM\", \"42CF\", \"43CM\", \"44CF\", \"49CM\", \"50CF\", \"51CM\", \"52CF\", \"58CF\", \"60CF\", \"74CF\", \"76CF\", \"81CM\", \"83CM\", \"89CM\", \"91CM\"]\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Stress\",\n",
    "        dirs=[\"45SM\", \"46SF\", \"47SM\", \"48SF\", \"53SM\", \"54SF\", \"55SM\", \"56SF\", \"62SF\", \"64SF\", \"78SF\", \"80SF\", \"85SM\", \"87SM\", \"93SM\", \"95SM\"]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUMNYA ALL - 2 Groups {Stress|Control} + 2 Groups {Males|Females}\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        name=\"Control (Females)\",\n",
    "        dirs=[\"42CF\", \"44CF\", \"50CF\", \"52CF\", \"58CF\", \"60CF\", \"74CF\", \"76CF\"]\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Stress (Females)\",\n",
    "        dirs=[\"46SF\", \"48SF\", \"54SF\", \"56SF\", \"62SF\", \"64SF\", \"78SF\", \"80SF\"]\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Control (Males)\",\n",
    "        dirs=[\"41CM\", \"43CM\", \"49CM\", \"51CM\", \"81CM\", \"83CM\", \"89CM\", \"91CM\"]\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Stress (Males)\",\n",
    "        dirs=[\"45SM\", \"47SM\", \"53SM\", \"55SM\", \"85SM\", \"87SM\", \"93SM\", \"95SM\"]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHILA - 3 Groups {Control|Stress|Resilient}\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        name=\"Control\",\n",
    "        dirs=[\"16C\", \"17C\", \"19C\"] # 18C\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Stress\",\n",
    "        dirs=[\"5S\", \"8S\", \"10S\", \"13S\", \"14S\"]\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Resilient\",\n",
    "        dirs=[\"1R\", \"2R\", \"3R\", \"4R\", \"11R\"]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHILA - 2 Groups {Control|Stress+Resilient}\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        name=\"Control\",\n",
    "        dirs=[\"16C\", \"17C\", \"19C\"]\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Stress\",\n",
    "        dirs=[\"5S\", \"10S\", \"13S\", \"14S\", \"1R\", \"2R\", \"3R\", \"4R\", \"11R\"]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATA - Sample data\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        name=\"Control\",\n",
    "        dirs=[\"Control_16C\", \"Control_17C\", \"Control_18C\", \"Control_19C\", \"Control_42C\"]\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Stress\",\n",
    "        dirs=[\"Stress_5S\", \"Stress_8S\", \"Stress_10S\", \"Stress_13S\"]\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Resilient\",\n",
    "        dirs=[\"Resilient_1R\", \"Resilient_2R\", \"Resilient_3R\", \"Resilient_4R\", \"Resilient_11R\"]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P4 DATA - Sample data\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        name=\"SNi\",\n",
    "        dirs=[\"206\", \"208\", \"210\", \"211\"]\n",
    "    ),\n",
    "    GroupDirectory(\n",
    "        name=\"Sham\",\n",
    "        dirs=[\"212\", \"213\", \"214\", \"220\"]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "project_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(project_path)\n",
    "import BraiAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_LOCAL_DATA:\n",
    "    match sys.platform:\n",
    "        case \"darwin\":\n",
    "            mnt_point = \"/Volumes/Ricerca/\"\n",
    "            \n",
    "        case \"linux\":\n",
    "            mnt_point = \"/run/user/1000/gvfs/smb-share:server=ich.techosp.it,share=ricerca/\"\n",
    "        case \"win32\":\n",
    "            mnt_point = \"\\\\\\\\ich.techosp.it\\\\Ricerca\\\\\"\n",
    "        case _:\n",
    "            raise Exception(f\"Can't find the 'Ricerca' folder in the server for '{sys.platform}' operative system. Please report the developer (Carlo)!\")\n",
    "    if not os.path.isdir(mnt_point):\n",
    "        raise Exception(f\"Could not read '{mnt_point}'. Please be sure you are connected to the server.\")\n",
    "    if IS_COLLABORATION_PROJ:\n",
    "        DATA_ROOT  =  os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", COLLABORATION_DIRECTORY, \"data\", EXPERIMENT_DIRECTORY)\n",
    "        PLOTS_ROOT = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"collaborations\", \"Mathias Schmidt\", \"soumnya\", \"results\", EXPERIMENT_DIRECTORY, \"plots\")\n",
    "    else:\n",
    "        DATA_ROOT  =  os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"projects\", \"data\", EXPERIMENT_DIRECTORY)\n",
    "        PLOTS_ROOT = os.path.join(mnt_point, \"Lab Matteoli\", \"Silva\", \"projects\", \"results\", EXPERIMENT_DIRECTORY, \"plots\")\n",
    "\n",
    "data_input_path = os.path.join(DATA_ROOT, \"QuPath_output\")\n",
    "data_output_path= os.path.join(DATA_ROOT, \"BraiAn_output\")\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Allen Brain Atlas\n",
    "\n",
    "We start by importing the mouse Allen Brain Atlas, in which we find information about all brain regions (their parent region and children regions in the brain hierarchy, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "# StructureGraph id=1\n",
    "path_to_allen_json = os.path.join(project_path, \"data\", \"AllenMouseBrainOntology.json\")\n",
    "AllenBrain = BraiAn.AllenBrainHierarchy(path_to_allen_json, BRANCHES_TO_EXCLUDE, use_literature_reuniens=USE_LITERATURE_REUNIENS)\n",
    "path_to_summary_structures = os.path.join(project_path, \"data\", \"AllenSummaryStructures.csv\")\n",
    "AllenBrain.select_from_csv(path_to_summary_structures, include_nre_tot=USE_LITERATURE_REUNIENS)\n",
    "selected_regions = AllenBrain.get_selected_regions()\n",
    "print(f\"You selected {len(selected_regions)} Summary Structure regions.\")\n",
    "\n",
    "#parent_region = AllenBrain.parent_region\n",
    "#direct_subregions = AllenBrain.direct_subregions\n",
    "#full_name = AllenBrain.full_name\n",
    "#regions = AllenBrain.list_all_subregions(\"root\", mode=\"depth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the hierarchy of brain regions as a network (a tree). **Note that running the above cell may take a few minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Plot brain region hierarchy\n",
    "## If you want to plot it, install PyDot (pydot)\n",
    "if PLOT_ALLENBRAIN_HIERARCHY:\n",
    "    fig = AllenBrain.plot_plotly_graph()\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph above, you might want to specify the regions on which you want to do further PLS analysis:  \n",
    "*Note: to see more information about the regions, hover over them with your mouse.*\n",
    "\n",
    "- Specify a level. Analysis can only be done on one level (slice) in the brain region.\n",
    "\n",
    "- To exclude brain regions that belong to a certain branch, add the *abbreviated* nodes at the beginning of the branches to the list above.  \n",
    "Example:  \n",
    "```branches_to_exclude = [\"retina\", \"VS\"]```  \n",
    "means that **all the subregions that belong to the retina and the ventricular systems** are excluded from the PLS analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Now, we're ready to read the ```.csv``` files with the cell counts, and also the exclusion files (if there were regions to exclude).  \n",
    "Below, you have to specify:\n",
    "- ```animals_root```: Absolute path to the folder that contains the animal folders.\n",
    "- ```group_1_dirs```: A list of names of the folders corresponding to animals in **Group 1** (e.g., Control group). Indeed, it is necessary to store the results in individual folders for each animal.\n",
    "- ```group_2_dirs```: A list of names of the folders corresponding to animals in **Group 2** (e.g., Stress group).\n",
    "- ```group_1_name```: A meaningful string for Group 1.\n",
    "- ```group_2_name```: A meaningful string for Group 2.\n",
    "- ```area_key```: A string of the column in the ```.csv``` files that refers to the size of a brain areatra\n",
    "- ```tracer_key```: A string of the column in the ```.csv``` files that refers to the tracer number used to highlight the marker\n",
    "- ```marker```: A string of the marker we would like to highlight (e.g. CFos)\n",
    "\n",
    "Provare a modificar per ottenere densita in mm^2 (da micron)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the Control and Stress results seperately in two pandas dataframes, and save the results.\n",
    "\n",
    "**Note**: regions to exclude are automatically excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_slices: List[List[BraiAn.SlicedBrain]] = []\n",
    "for i in range(len(groups)):\n",
    "    group_slices = []\n",
    "    for animal_dir in groups[i].dirs:\n",
    "        if not os.path.isdir(os.path.join(data_input_path, animal_dir)):\n",
    "            print(f\"WARNING: could not find the directory '{animal_dir}' in '{EXPERIMENT_DIRECTORY}'. Skipping this animal.\")\n",
    "            continue\n",
    "        sliced_brain = BraiAn.SlicedBrain(animal_dir,\n",
    "                                            os.path.join(data_input_path, animal_dir),\n",
    "                                            AllenBrain,\n",
    "                                            AREA_KEY,\n",
    "                                            TRACER_KEY,\n",
    "                                            MARKER,\n",
    "                                            area_units=\"µm2\")\n",
    "        group_slices.append(sliced_brain)\n",
    "    groups_slices.append(group_slices)\n",
    "    print(f\"Imported all brain slices from {str(len(groups[i].dirs))} animals of {groups[i].name} group.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_ANIMALS_ROOTS:\n",
    "    root_plot = BraiAn.plot_region_density(\"root\", *groups_slices, width=1000, height=500)\n",
    "    root_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = \"root\"\n",
    "import numpy as np\n",
    "\n",
    "summed_brains = []\n",
    "group_lengths = [len(group) for group in groups_slices]\n",
    "n_brains_before_group = np.cumsum(group_lengths)\n",
    "groups_roots = []\n",
    "for i, group_slices in enumerate(groups_slices):\n",
    "    n_brains_before = n_brains_before_group[i-1] if i > 0 else np.int64(0)\n",
    "    group_summed_brains = [BraiAn.AnimalBrain(sliced_brain, hemisphere_distinction=False, use_literature_reuniens=USE_LITERATURE_REUNIENS) for sliced_brain in group_slices]\n",
    "    summed_brains.extend(group_summed_brains)\n",
    "    group_roots = []\n",
    "    for j, sliced_brain in enumerate(group_slices):\n",
    "        n_brain = n_brains_before+j\n",
    "        sliced_brain = BraiAn.merge_sliced_hemispheres(sliced_brain)\n",
    "        for slice in sliced_brain.slices:\n",
    "            try:\n",
    "                density = slice.data.loc[region_name, slice.marker] / slice.data.loc[region_name, \"area\"]\n",
    "                # density = slice.data.loc[region_name, slice.marker]\n",
    "            except KeyError as e:\n",
    "                print(f\"WARNING: Could not find the '{region_name}' region for image '{slice.name}' of {slice.animal}\")\n",
    "                continue\n",
    "            group_roots.append(density)\n",
    "    group_roots_avg = np.array(group_roots).mean()\n",
    "    groups_roots.append(group_roots_avg)\n",
    "for name, avg in zip([group.name for group in groups], groups_roots):\n",
    "    print(f\"{name}: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"N regions above threshold:\", sum([(brain.data > cv_threshold).sum() for brain in cvar_brains]))\n",
    "# print(\"N regions below threshold:\", sum([(brain.data <= cv_threshold).sum() for brain in cvar_brains]))\n",
    "if PLOT_COEFFICIENT_OF_VARIATION:\n",
    "    cvar_plot = BraiAn.plot_cv_above_threshold(AllenBrain, *groups_slices, cv_threshold=PLOT_COEFFICIENT_OF_VARIATION_THRESHOLD, width=1000, height=500)\n",
    "    cvar_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"IG\"\n",
    "n_group = 2\n",
    "n_animal = 3\n",
    "sliced_brain = groups_slices[n_group-1][n_animal-1]\n",
    "sliced_brain = BraiAn.merge_sliced_hemispheres(sliced_brain)\n",
    "all_slices_df = sliced_brain.concat_slices()\n",
    "slices_per_area = all_slices_df.groupby(all_slices_df.index).count().iloc[:,0]\n",
    "print(f\"\"\"Summary for brain region '{r}' of {sliced_brain.name}:\n",
    "    - N slices: {slices_per_area[r]}\n",
    "    - Mean: {BraiAn.AnimalBrain(sliced_brain, mode=\"avg\", hemisphere_distinction=False, use_literature_reuniens=USE_LITERATURE_REUNIENS).data[r]:.2f} {sliced_brain.marker}/mm²),\n",
    "    - S.D.: {BraiAn.AnimalBrain(sliced_brain, mode=\"std\", hemisphere_distinction=False, use_literature_reuniens=USE_LITERATURE_REUNIENS).data[r]:.2f} {sliced_brain.marker}/mm²,\n",
    "    - Coefficient of Variation: {BraiAn.AnimalBrain(sliced_brain, mode=\"cvar\", hemisphere_distinction=False, use_literature_reuniens=USE_LITERATURE_REUNIENS).data[r]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: brains are being written WITH Left/Right discrimination\n",
    "# If you desire to save them without, call AnimalBrain with hemisphere_distinction=False\n",
    "\n",
    "groups_sum_brains: List[List[BraiAn.AnimalBrain]] = [[BraiAn.AnimalBrain(sliced_brain, mode=ANIMAL_BRAIN_MODE, use_literature_reuniens=USE_LITERATURE_REUNIENS) for sliced_brain in sliced_brain_list] for sliced_brain_list in groups_slices]\n",
    "if SAVE_ANIMALS:\n",
    "    for i in range(len(groups)):\n",
    "        for animal in groups_sum_brains[i]:\n",
    "            animal.write_all_brains(data_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_groups: List[BraiAn.AnimalGroup] = [BraiAn.AnimalGroup(groups[i].name, groups_sum_brains[i], AllenBrain) for i in range(len(groups))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_GROUPS:\n",
    "    for i in range(len(groups)):\n",
    "        animal_groups[i].to_csv(data_output_path, f\"cell_counts_{groups[i].name}.csv\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
