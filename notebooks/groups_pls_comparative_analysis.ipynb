{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CONFIG_FILE_NAME = \"braian_config.toml\"                     # assumes the file is in DATA_ROOT directory\n",
    "# USE_REMOTE_DATA -> if True, it tries to read the data on the laboratory's server\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"p6\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"experiment\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"proof\", False\n",
    "EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"rebased_on_mjd\", False\n",
    "# EXPERIMENT_DIRECTORY, USE_REMOTE_DATA = \"Cariplo_NRe/IEGs Experiment\", True\n",
    "\n",
    "# ###################################### REMOTE DIRECTORIES #####################################\n",
    "IS_COLLABORATION_PROJ = False\n",
    "COLLABORATION_DIRECTORY = os.path.join(\"Mathias Schmidt\", \"soumnya\")\n",
    "\n",
    "# ###################################### LOCAL DIRECTORIES ######################################\n",
    "EXPERIMENT_DIRECTORY = EXPERIMENT_DIRECTORY.replace(\"/\", os.sep)\n",
    "# DATA_ROOT  = f\"../data/experiments/sowmya/{EXPERIMENT_DIRECTORY}\"\n",
    "# PLOTS_ROOT = f\"../plots/sowmya/{EXPERIMENT_DIRECTORY}\"\n",
    "DATA_ROOT  = f\"../data/experiments/{EXPERIMENT_DIRECTORY}\"\n",
    "PLOTS_ROOT = f\"../plots/{EXPERIMENT_DIRECTORY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on which comparison of CONFIG_FILE_NAME to run the PLS analysis\n",
    "COMPARISON_ID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### GENERAL OPTIONS #######################################\n",
    "SAVED_PLOT_EXTENSION = \".html\"                      # '.html' for interactive plot\n",
    "                                                    # '.svg' for vectorized image\n",
    "                                                    # '.png'/'.jpg'/... for rasterized image\n",
    "\n",
    "# ######################################### PLS OPTIONS #########################################\n",
    "PLOT_DISTRIBUTION_OF_SINGULAR_VALUES = True\n",
    "\n",
    "# ##################################### SALIENCE SCORE PLOT #####################################\n",
    "SHOW_SALIENCE_SCORES_PLOT = True\n",
    "SAVE_SALIENCE_SCORES_PLOT = True\n",
    "SALIENCE_TITLE_TEXT_SIZE = 40\n",
    "SALIENCE_AXIS_TEXT_SIZE = 22\n",
    "SALIENCE_USE_ACRONYMS = True\n",
    "SALIENCE_USE_ACRONYMS_IN_MJD = False\n",
    "SALIENCE_MJD_BG_OPACITY = 0.3\n",
    "SALIENCE_WIDTH = 1000\n",
    "SALIENCE_BARHEIGHT = 30\n",
    "\n",
    "# ########################################## PIE CHART ##########################################\n",
    "PIE_SAVE_PLOT = True\n",
    "PIE_SHOW_PLOT = False\n",
    "PIE_USE_ACRONYMS = False\n",
    "PIE_HOLE = 0.4                                          # a value between 0 (no hole) and 1 (just a hole, no plot)\n",
    "PIE_TEXT_SIZE = 25\n",
    "\n",
    "# ########################################## BAR PLOT ###########################################\n",
    "BAR_SAVE_PLOT = True\n",
    "BAR_SHOW_PLOT = True\n",
    "BAR_ANIMAL_SIZE = 8\n",
    "BAR_TITLE_TEXT_SIZE = 40\n",
    "BAR_AXIS_TEXT_SIZE = 22\n",
    "BAR_HEIGHT = 30\n",
    "BAR_WIDTH = 1_500\n",
    "BAR_TITLE = \"\"\n",
    "BAR_USE_ACRONYMS = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "\n",
    "project_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(project_path)\n",
    "import BraiAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REMOTE_DATA:\n",
    "    DATA_ROOT, PLOTS_ROOT = BraiAn.remote_dirs(EXPERIMENT_DIRECTORY, IS_COLLABORATION_PROJ, COLLABORATION_DIRECTORY)\n",
    "\n",
    "config_file = os.path.join(DATA_ROOT, CONFIG_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "with open(config_file, \"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "config\n",
    "# ######################################### LOAD CONFIG #########################################\n",
    "EXPERIMENT_NAME = config[\"experiment\"][\"name\"]\n",
    "\n",
    "ATLAS_VERSION = config[\"atlas\"][\"version\"]\n",
    "BRANCHES_TO_EXCLUDE = config[\"atlas\"][\"excluded-branches\"]\n",
    "\n",
    "NORMALIZATION = config[\"brains\"][\"normalization\"]\n",
    "MIN_AREA = config[\"pls\"][\"min-area\"]                                    # area in mmÂ². If a region of one animal is smaller, that same region won't be considered in the PLS\n",
    "                                                                        # That is because the PLS only considers the brain regions that appears in every animal of the groups\n",
    "REGIONS_TO_PLOT_SELECTION_METHOD = config[\"pls\"][\"regions-to-plot\"]     # Available options are: \"summary structures\", \"major divisions\" \"depth <n>\", \"structural level <n>\"\n",
    "                                                                        # where <n> is an integer of the depth/level desired\n",
    "PLS_SALIENCE_THRESHOLD = config[\"pls\"][\"salience-threshold\"]            # Only brain regions with a salience higher than plot_threshold are shown. 2 is the significance threshold.\n",
    "PLS_RANK = config[\"pls\"][\"rank\"]\n",
    "PLS_NUM_BOOTSTRAP = config[\"pls\"][\"num-bootstrap\"]\n",
    "PLS_NUM_PERMUTATIONS = config[\"pls\"][\"num-permutations\"]\n",
    "\n",
    "from collections import namedtuple\n",
    "GroupDirectory = namedtuple(\"GroupDirectory\", \"id name dirs\")\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        id=int(group[len(\"group\"):])-1,\n",
    "        name=config[\"experiment\"][group][\"name\"],\n",
    "        dirs=config[\"experiment\"][group][\"dirs\"]\n",
    "    ) for group in config[\"experiment\"] if group.startswith(\"group\") and group[len(\"group\"):].isdigit()\n",
    "]\n",
    "\n",
    "comparison_groups = config[\"comparison\"][str(COMPARISON_ID)][\"groups\"]\n",
    "assert len(comparison_groups) == 2, f\"The selected comparison is between {len(comparison_groups)} groups. PLS can only be computed between two groups!\"\n",
    "Comparison = namedtuple(\"Comparison\", \"group1 group2 dir\")\n",
    "comparison = Comparison(\n",
    "    group1=groups[comparison_groups[0]-1],\n",
    "    group2=groups[comparison_groups[1]-1],\n",
    "    dir=config[\"comparison\"][str(COMPARISON_ID)][\"dir\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_path = os.path.join(DATA_ROOT, \"BraiAn_output\")\n",
    "data_output_path = os.path.join(data_input_path, comparison.dir)\n",
    "plots_output_path = os.path.join(PLOTS_ROOT, comparison.dir)\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)\n",
    "\n",
    "if not(os.path.exists(plots_output_path)):\n",
    "    os.makedirs(plots_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "# StructureGraph id=1\n",
    "path_to_allen_json = os.path.join(project_path, \"data\", \"AllenMouseBrainOntology.json\")\n",
    "BraiAn.cache(path_to_allen_json, \"http://api.brain-map.org/api/v2/structure_graph_download/1.json\")\n",
    "brain_onthology = BraiAn.AllenBrainHierarchy(path_to_allen_json, BRANCHES_TO_EXCLUDE, version=ATLAS_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match REGIONS_TO_PLOT_SELECTION_METHOD:\n",
    "    case \"summary structures\":\n",
    "        # selects the Summary Strucutures\n",
    "        path_to_summary_structures = os.path.join(project_path, \"data\", \"AllenSummaryStructures.csv\")\n",
    "        brain_onthology.select_from_csv(path_to_summary_structures)\n",
    "    case \"major divisions\":\n",
    "        brain_onthology.select_regions(BraiAn.MAJOR_DIVISIONS)\n",
    "    case \"smallest\":\n",
    "        brain_onthology.select_leaves()\n",
    "    case s if s.startswith(\"depth\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            depth = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'depth' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        brain_onthology.select_at_depth(depth)\n",
    "    case s if s.startswith(\"structural level\"):\n",
    "        n = REGIONS_TO_PLOT_SELECTION_METHOD.split(\" \")[-1]\n",
    "        try:\n",
    "            level = int(n)\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not retrieve the <n> parameter of the 'structural level' method for 'REGIONS_TO_PLOT_SELECTION_METHOD'\")\n",
    "        brain_onthology.select_at_structural_level(level)\n",
    "    case _:\n",
    "        raise Exception(f\"Invalid value '{REGIONS_TO_PLOT_SELECTION_METHOD}' for REGIONS_TO_PLOT_SELECTION_METHOD\")\n",
    "selected_regions = brain_onthology.get_selected_regions()\n",
    "print(f\"You selected {len(selected_regions)} regions to do PLS analysis over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = BraiAn.AnimalGroup.from_csv(comparison.group1.name, data_input_path, f\"cell_counts_{comparison.group1.name}_{NORMALIZATION.lower()}.csv\")\n",
    "group_1.remove_smaller_subregions(MIN_AREA, brain_onthology)\n",
    "group_2 = BraiAn.AnimalGroup.from_csv(comparison.group2.name, data_input_path, f\"cell_counts_{comparison.group2.name}_{NORMALIZATION.lower()}.csv\")\n",
    "group_2.remove_smaller_subregions(MIN_AREA, brain_onthology)\n",
    "if not group_1.is_comparable(group_2):\n",
    "    raise ImportError(\"Group 1 and Group 2 are not comparable!\\n\\\n",
    "Please check that you're reading two groups that normalized on the same brain regions and on the same marker\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are stored in ```group_1.data``` and ```group_2.data```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Least Squares  \n",
    "\n",
    "The analysis done below is taken from the tutorial written by [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074).  \n",
    "Run the 2 cells below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PLS object\n",
    "pls = BraiAn.PLS(selected_regions, group_1, group_2, marker=group_1.markers[0])\n",
    "\n",
    "# Show the matrix X\n",
    "pls.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the matrix Y\n",
    "pls.Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two matrices printed above (X and Y) illustrate the data on which the PLS is done.  \n",
    "- ```X:``` The rows in this matrix are the mice. The columns in the matrix are the regions selected for analysis. The values in the matrix are the **normalized value of marked cells: in that region relative to the whole brain.** \n",
    "The normalization methods are either:\n",
    "  + Density\n",
    "  + Percentage (on the total number of detected marked cells outside of excluded regions)\n",
    "  + RelativeDensity\n",
    "- ```Y:``` The rows in this matrix are the mice. The columns in the matrix are the 2 groups. **A value in this matrix is 1 if the mice belongs to the specified group**.\n",
    "\n",
    "In brief, PLS analyzes the relationship (correlation) between the columns of ```X``` and ```Y```. In our specific case, there will be 2 important outputs:\n",
    "- **Salience scores**: Each brain region has a salience score. A high salience scores means that the brain region explains much of the correlation between ```X``` and ```Y```.  \n",
    "- **Singular values**: These are the eigenvalues of the correlation matrix $R = Y^TX$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random permutations to see whether we can differentiate signal from noise. \n",
    "Here, we randomly shuffle the group to which a mouse belongs, and calculate the singular values of the permuted dataset.  \n",
    "From [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074):  \n",
    "> The set of all the (permuted) singular values provides a sampling distribution of the singular values under the null hypothesis and, therefore can be used as a null hypothesis test.\n",
    "\n",
    "*Note: running the cell below will take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Randomly permuting singular values {PLS_NUM_PERMUTATIONS} times...\")\n",
    "s,singular_values = pls.randomly_permute_singular_values(PLS_NUM_PERMUTATIONS)\n",
    "# Plot distribution of singular values\n",
    "if PLOT_DISTRIBUTION_OF_SINGULAR_VALUES:\n",
    "    fig = BraiAn.plot_permutation(pls.s[0], singular_values, PLS_NUM_PERMUTATIONS)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate p-value = Probability(experiment | H0)\n",
    "p = (singular_values[:,0] > s[0]).sum() / PLS_NUM_PERMUTATIONS\n",
    "print(\"p-value = \"+str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BraiAn.plot_groups_salience(pls, component=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BraiAn.plot_latent_variables(pls, of=\"X\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap to identify stable salience scores\n",
    "\n",
    "Here, we use [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) (= sampling of the mice in the dataset, with replacement) to get an estimate of which salience scores are stable.\n",
    "\n",
    "From [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074):  \n",
    "> When a vector of saliences is considered generalizable and is kept for further analysis, we need to identify its elements that are stable through resampling. In practice, the stability of an element is evaluated by dividing it by its standard error. [...] To estimate the standard errors, we create bootstrap samples which are obtained by sampling with replacement the observations in and (Efron and Tibshirani, 1986). A salience standard error is then estimated as the standard error of the saliences from a large number of these bootstrap samples (say 1000 or 10000). **The ratios are akin to a Z-score, therefore when they are larger than 2 the corresponding saliences are considered significantly stable.**\n",
    "\n",
    "*Note: Running the cell below will take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Bootstrapping salience scores {PLS_NUM_BOOTSTRAP} times...\")\n",
    "u_salience_scores,v_salience_scores = pls.bootstrap_salience_scores(PLS_RANK, PLS_NUM_BOOTSTRAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_salience_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_to_plot_selection_method_str = REGIONS_TO_PLOT_SELECTION_METHOD.replace(\" \", \"_\")\n",
    "salient_regions = pls.above_threshold(PLS_SALIENCE_THRESHOLD).reset_index().rename(columns={\"index\":\"acronym\", 0: \"salience_score\"})\n",
    "\n",
    "# save the salient regions in a CSV\n",
    "pls_salience_threshold_str = str(PLS_SALIENCE_THRESHOLD).replace(\".\", \"_\")\n",
    "salient_regions_file = f\"PLS_{group_1.markers[0]}_{str(group_1.metric)}_{regions_to_plot_selection_method_str}_above_{pls_salience_threshold_str}.csv\"\n",
    "BraiAn.save_csv(salient_regions, data_output_path, salient_regions_file.lower(), overwrite=True)\n",
    "\n",
    "# save ALL the regions with salient score\n",
    "pls_filename = f\"PLS_{group_1.markers[0]}_{str(group_1.metric)}_{regions_to_plot_selection_method_str}_salience_scores.csv\"\n",
    "BraiAn.save_csv(v_salience_scores.rename(columns={0:\"salience_score\"}), data_output_path, pls_filename.lower(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pls_(x, y):\n",
    "    diag = np.diagflat((np.ones((1, y.shape[0])) @ y) ** (-1))\n",
    "    m = diag @ y.transpose() @ x\n",
    "    r = m - np.ones((m.shape[0], 1)) @ ((np.ones((1, m.shape[0])) @ m) / m.shape[0])\n",
    "    u, s, v = np.linalg.svd(r, full_matrices=False)\n",
    "    return u, s, v\n",
    "\n",
    "def procrustes(u, s, v, u0):\n",
    "    import numpy as np\n",
    "    n, o, p = np.linalg.svd(np.matmul(u0.transpose(), u), full_matrices=False)\n",
    "    q = n @ p.transpose()\n",
    "    vr = v.transpose() @ q\n",
    "    ur = u @ np.diagflat(s) @ q\n",
    "    return ur, vr.transpose()\n",
    "\n",
    "def bootstrap_test(x, y, v0, u0, n):\n",
    "    import numpy as np\n",
    "    vdist = np.zeros((n,) + v0.shape)\n",
    "    m = x.shape[0]\n",
    "    for i in np.arange(n):\n",
    "        # generate random index sequence for bootstrapping (i.e. sampling with replacement)\n",
    "        while True:\n",
    "            idx = np.random.randint(0, m, m)\n",
    "            # extract resampled arrays\n",
    "            xsh = x[idx]\n",
    "            ysh = y[idx]\n",
    "            if not np.any(np.all(ysh[..., :] == 0, axis=0)):\n",
    "                break\n",
    "        u, s, v = pls_(xsh, ysh)\n",
    "        ur, vr = procrustes(u, s, v, u0)\n",
    "        # vr = v\n",
    "        vdist[i, ...] = vr\n",
    "    vs = np.std(vdist, axis=0)\n",
    "    return vs\n",
    "\n",
    "x = np.asarray(pls.X.values)\n",
    "y = np.asarray(pls.Y.values)\n",
    "u, s, v = pls_(x, y)\n",
    "np.isclose(v.T, pls.v)\n",
    "vs = bootstrap_test(x, y, v, u, PLS_NUM_BOOTSTRAP)\n",
    "vpd = pd.DataFrame((v/vs), columns=pls.X.columns)\n",
    "\n",
    "df = pd.DataFrame({\"salience_score\": vpd.T[vpd.T.iloc[:,0].abs() > 0.9][0]})\n",
    "df.reset_index(inplace=True)\n",
    "df = df.rename({\"index\": \"acronym\"}, axis=1)\n",
    "\n",
    "# Plot PLS salience scores\n",
    "fig = BraiAn.plot_salient_regions(df, brain_onthology,\n",
    "                                    title=f\"Salient regions (|score| >= {PLS_SALIENCE_THRESHOLD})\",\n",
    "                                    title_size=SALIENCE_TITLE_TEXT_SIZE, axis_size=SALIENCE_AXIS_TEXT_SIZE,\n",
    "                                    use_acronyms=SALIENCE_USE_ACRONYMS, use_acronyms_in_mjd=SALIENCE_USE_ACRONYMS_IN_MJD,\n",
    "                                    mjd_opacity=SALIENCE_MJD_BG_OPACITY,\n",
    "                                    width=SALIENCE_WIDTH, barheight=SALIENCE_BARHEIGHT)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PLS salience scores\n",
    "fig = BraiAn.plot_salient_regions(salient_regions, brain_onthology,\n",
    "                                    title=f\"Salient regions (|score| >= {PLS_SALIENCE_THRESHOLD})\",\n",
    "                                    title_size=SALIENCE_TITLE_TEXT_SIZE, axis_size=SALIENCE_AXIS_TEXT_SIZE,\n",
    "                                    use_acronyms=SALIENCE_USE_ACRONYMS, use_acronyms_in_mjd=SALIENCE_USE_ACRONYMS_IN_MJD,\n",
    "                                    mjd_opacity=SALIENCE_MJD_BG_OPACITY,\n",
    "                                    width=SALIENCE_WIDTH, barheight=SALIENCE_BARHEIGHT)\n",
    "\n",
    "if SAVE_SALIENCE_SCORES_PLOT:\n",
    "    if not(os.path.exists(plots_output_path)):\n",
    "        os.mkdir(plots_output_path)\n",
    "    plot_filename = f\"PLS_{pls_salience_threshold_str}_{group_1.markers[0]}_{str(group_1.metric)}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "    plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "    match SAVED_PLOT_EXTENSION.lower():\n",
    "        case \".html\":\n",
    "            fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "        case _:\n",
    "            fig.write_image(plot_filepath)\n",
    "\n",
    "if SHOW_SALIENCE_SCORES_PLOT:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_data = BraiAn.as_prism_data(brain_onthology, group_1, group_2)\n",
    "prism_data = prism_data.loc[salient_regions.acronym.array]\n",
    "prism_file = f\"prism_{comparison.dir}_{group_1.markers[0]}_{str(group_1.metric)}_{regions_to_plot_selection_method_str}_pls_above_{pls_salience_threshold_str}.csv\"\n",
    "BraiAn.save_csv(prism_data.swaplevel(), data_output_path, prism_file.lower(), sep=\",\", overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = BraiAn.plot_pie(v_salience_scores.index.values, brain_onthology, use_acronyms=PIE_USE_ACRONYMS, hole=PIE_HOLE, line_width=1, text_size=PIE_TEXT_SIZE)\n",
    "\n",
    "if PIE_SAVE_PLOT:\n",
    "    plot_filename = f\"pls_all_regions_piechart_{comparison.dir}_{group_1.markers[0]}_{str(group_1.metric)}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "    plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "    match SAVED_PLOT_EXTENSION.lower():\n",
    "        case \".html\":\n",
    "            fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "        case _:\n",
    "            fig.write_image(plot_filepath)\n",
    "if PIE_SHOW_PLOT:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = BraiAn.plot_pie(salient_regions.acronym.array, brain_onthology, use_acronyms=PIE_USE_ACRONYMS, hole=PIE_HOLE, line_width=1, text_size=PIE_TEXT_SIZE)\n",
    "\n",
    "if PIE_SAVE_PLOT:\n",
    "    plot_filename = f\"pls_{pls_salience_threshold_str}_piechart_{comparison.dir}_{group_1.markers[0]}_{str(group_1.metric)}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "    plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "    match SAVED_PLOT_EXTENSION.lower():\n",
    "        case \".html\":\n",
    "            fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "        case _:\n",
    "            fig.write_image(plot_filepath)\n",
    "if PIE_SHOW_PLOT:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = BraiAn.plot_groups(brain_onthology, group_1, group_2, selected_regions=salient_regions.acronym.array,\n",
    "                            plot_title=BAR_TITLE, title_size=BAR_TITLE_TEXT_SIZE, axis_size=BAR_AXIS_TEXT_SIZE, animal_size=BAR_ANIMAL_SIZE,\n",
    "                            use_acronyms=BAR_USE_ACRONYMS, colors=(DEFAULT_PLOTLY_COLORS[group.id] for group in (comparison.group1, comparison.group2)),\n",
    "                            width=BAR_WIDTH, barheight=BAR_HEIGHT, bargap=0.3, bargroupgap=0.0)\n",
    "\n",
    "if BAR_SAVE_PLOT:\n",
    "    plot_filename = f\"pls_{pls_salience_threshold_str}_barplot_{comparison.dir}_{group_1.markers[0]}_{str(group_1.metric)}_{regions_to_plot_selection_method_str}{SAVED_PLOT_EXTENSION}\".lower()\n",
    "    plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "    match SAVED_PLOT_EXTENSION.lower():\n",
    "        case \".html\":\n",
    "            fig.write_html(plot_filepath, config=dict(toImageButtonOptions=dict(format=\"svg\")))\n",
    "        case _:\n",
    "            fig.write_image(plot_filepath)\n",
    "if BAR_SHOW_PLOT:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "__imported_modules = sys.modules.copy()\n",
    "for module_name, module in __imported_modules.items():\n",
    "    if not module_name.startswith(\"BraiAn\"):\n",
    "        continue\n",
    "    try:\n",
    "        importlib.reload(module)\n",
    "    except ModuleNotFoundError:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
