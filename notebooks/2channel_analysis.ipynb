{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABBA cell count analysis\n",
    "\n",
    "This notebook is the last step in the ABBA whole-brain cell counting analysis.  \n",
    "It assumes you have done the following steps:\n",
    "- Alignment of brain slices in ABBA, exported to a QuPath project.\n",
    "- Detected cells of interest in QuPath. The detections should be exported to ```.csv``` files (one per slice) in a folder called ```results```. \n",
    "- If there are regions to exclude, you should have drawn them and exported to ```.txt``` files (one per slice) in a folder called ```regions_to_exclude```.\n",
    "\n",
    "Run this notebook to load the cell counts and do analysis on them. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start ...\n",
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CONFIG_FILE_NAME = \"braian_config.toml\"                     # assumes the file is in DATA_ROOT directory\n",
    "EXPERIMENT_DIRECTORY = \"ieg\"\n",
    "EXPERIMENT_DIRECTORY = \"cohort4\"\n",
    "\n",
    "USE_REMOTE_DATA = False                                     # if True, it tries to read the data on the laboratory's server\n",
    "# ###################################### REMOTE DIRECTORIES #####################################\n",
    "IS_COLLABORATION_PROJ = False\n",
    "COLLABORATION_DIRECTORY = os.path.join(\"Mathias Schmidt\", \"soumnya\")\n",
    "\n",
    "# ###################################### LOCAL DIRECTORIES ######################################\n",
    "DATA_ROOT  = f\"../data/experiments/{EXPERIMENT_DIRECTORY}\"\n",
    "PLOTS_ROOT = f\"../plots/{EXPERIMENT_DIRECTORY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################### PLOT OPTIONS ######################################\n",
    "PLOT_ALLENBRAIN_HIERARCHY = False\n",
    "PLOT_ANIMALS_ROOTS = True\n",
    "PLOT_COEFFICIENT_OF_VARIATION = True\n",
    "PLOT_COEFFICIENT_OF_VARIATION_THRESHOLD = 1\n",
    "\n",
    "REMOVE_SMALL_REGIONS_FROM_SLICES = False\n",
    "REMOVE_HIGH_CV_REGIONS = False\n",
    "SAVE_ANIMALS = True\n",
    "SAVE_GROUPS = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "project_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(project_path)\n",
    "import BraiAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REMOTE_DATA:\n",
    "    DATA_ROOT, _ = BraiAn.remote_dirs(EXPERIMENT_DIRECTORY, IS_COLLABORATION_PROJ, COLLABORATION_DIRECTORY)\n",
    "\n",
    "data_input_path = os.path.join(DATA_ROOT, \"QuPath_output\")\n",
    "data_output_path= os.path.join(DATA_ROOT, \"BraiAn_output\")\n",
    "plots_output_path = PLOTS_ROOT\n",
    "config_file = os.path.join(DATA_ROOT, CONFIG_FILE_NAME)\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)\n",
    "if not(os.path.exists(plots_output_path)):\n",
    "    os.makedirs(plots_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "with open(config_file, \"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "config\n",
    "# ######################################### LOAD CONFIG #########################################\n",
    "EXPERIMENT_NAME = config[\"experiment\"][\"name\"]\n",
    "\n",
    "ATLAS_VERSION = config[\"atlas\"][\"version\"]\n",
    "BRANCHES_TO_EXCLUDE = config[\"atlas\"][\"excluded-branches\"]\n",
    "USE_LITERATURE_REUNIENS =  config[\"atlas\"][\"use-literature-reuniens\"]   # add a 'REtot' region, merging the following regions: 'RE', 'Xi', 'RH'\n",
    "\n",
    "BRAINS_AREA_KEY = config[\"brains\"][\"area-column\"]\n",
    "BRAINS_TRACER_KEYS = config[\"brains\"][\"tracer-columns\"]\n",
    "BRAINS_MARKERS = config[\"brains\"][\"markers\"]\n",
    "BRAINS_AGGREGATION_MODE = config[\"brains\"][\"slices-aggregation-mode\"]   # available options are: 'sum', 'mean'/'avg', 'std', 'variation'/'cvar'\n",
    "\n",
    "from collections import namedtuple\n",
    "GroupDirectory = namedtuple(\"GroupDirectory\", \"id name dirs\")\n",
    "groups = [\n",
    "    GroupDirectory(\n",
    "        id=int(group[len(\"group\"):])-1,\n",
    "        name=config[\"experiment\"][group][\"name\"],\n",
    "        dirs=config[\"experiment\"][group][\"dirs\"]\n",
    "    ) for group in config[\"experiment\"] if group.startswith(\"group\") and group[len(\"group\"):].isdigit()\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Allen Brain Atlas\n",
    "\n",
    "We start by importing the mouse Allen Brain Atlas, in which we find information about all brain regions (their parent region and children regions in the brain hierarchy, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "# StructureGraph id=1\n",
    "path_to_allen_json = os.path.join(project_path, \"data\", \"AllenMouseBrainOntology.json\")\n",
    "AllenBrain = BraiAn.AllenBrainHierarchy(path_to_allen_json, BRANCHES_TO_EXCLUDE, use_literature_reuniens=USE_LITERATURE_REUNIENS, version=ATLAS_VERSION)\n",
    "# path_to_summary_structures = os.path.join(project_path, \"data\", \"AllenSummaryStructures.csv\")\n",
    "# AllenBrain.select_from_csv(path_to_summary_structures, include_nre_tot=USE_LITERATURE_REUNIENS)\n",
    "# AllenBrain.select_at_depth(8)\n",
    "AllenBrain.select_leaves()\n",
    "selected_regions = AllenBrain.get_selected_regions()\n",
    "print(f\"You selected {len(selected_regions)} Summary Structure regions.\")\n",
    "\n",
    "#parent_region = AllenBrain.parent_region\n",
    "#direct_subregions = AllenBrain.direct_subregions\n",
    "#full_name = AllenBrain.full_name\n",
    "#regions = AllenBrain.list_all_subregions(\"root\", mode=\"depth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the hierarchy of brain regions as a network (a tree). **Note that running the above cell may take a few minutes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Plot brain region hierarchy\n",
    "## If you want to plot it, install PyDot (pydot)\n",
    "if PLOT_ALLENBRAIN_HIERARCHY:\n",
    "    fig = AllenBrain.plot_plotly_graph()\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph above, you might want to specify the regions on which you want to do further PLS analysis:  \n",
    "*Note: to see more information about the regions, hover over them with your mouse.*\n",
    "\n",
    "- Specify a level. Analysis can only be done on one level (slice) in the brain region.\n",
    "\n",
    "- To exclude brain regions that belong to a certain branch, add the *abbreviated* nodes at the beginning of the branches to the list above.  \n",
    "Example:  \n",
    "```branches_to_exclude = [\"retina\", \"VS\"]```  \n",
    "means that **all the subregions that belong to the retina and the ventricular systems** are excluded from the PLS analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Now, we're ready to read the ```.csv``` files with the cell counts, and also the exclusion files (if there were regions to exclude).  \n",
    "Below, you have to specify:\n",
    "- ```animals_root```: Absolute path to the folder that contains the animal folders.\n",
    "- ```group_1_dirs```: A list of names of the folders corresponding to animals in **Group 1** (e.g., Control group). Indeed, it is necessary to store the results in individual folders for each animal.\n",
    "- ```group_2_dirs```: A list of names of the folders corresponding to animals in **Group 2** (e.g., Stress group).\n",
    "- ```group_1_name```: A meaningful string for Group 1.\n",
    "- ```group_2_name```: A meaningful string for Group 2.\n",
    "- ```area_key```: A string of the column in the ```.csv``` files that refers to the size of a brain areatra\n",
    "- ```tracer_key```: A string of the column in the ```.csv``` files that refers to the tracer number used to highlight the marker\n",
    "- ```marker```: A string of the marker we would like to highlight (e.g. CFos)\n",
    "\n",
    "Provare a modificar per ottenere densita in mm^2 (da micron)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the Control and Stress results seperately in two pandas dataframes, and save the results.\n",
    "\n",
    "**Note**: regions to exclude are automatically excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# retrieve the name of the marker of the channel used as control for the overlapping\n",
    "marker1 = next(s for s in BRAINS_MARKERS if re.match(\"[a-zA-Z0-9]+-\\(.*\\)\", s)).split(\"-(\")[0]\n",
    "marker2 = min(BRAINS_MARKERS, key=len)\n",
    "marker1_diff = f\"{marker1}-({marker1}+{marker2})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_slices: List[List[BraiAn.SlicedBrain]] = []\n",
    "for group in groups:\n",
    "    sliced_brains = []\n",
    "    for animal_dir in group.dirs:\n",
    "        if not os.path.isdir(os.path.join(data_input_path, animal_dir)):\n",
    "            print(f\"WARNING: could not find the directory '{animal_dir}' in '{EXPERIMENT_DIRECTORY}'. Skipping this animal.\")\n",
    "            continue\n",
    "        multich_sliced_brain = BraiAn.SlicedBrain(animal_dir,\n",
    "                                                os.path.join(data_input_path, animal_dir),\n",
    "                                                AllenBrain,\n",
    "                                                BRAINS_AREA_KEY,\n",
    "                                                BRAINS_TRACER_KEYS,\n",
    "                                                BRAINS_MARKERS,\n",
    "                                                area_units=\"µm2\")\n",
    "        for i in range(len(multich_sliced_brain.slices)):\n",
    "            multich_sliced_brain.slices[i].data[marker1_diff] += multich_sliced_brain.slices[i].data[f\"{marker1}+{marker2}\"]\n",
    "            multich_sliced_brain.slices[i].data.rename(columns={marker1_diff: marker1}, inplace=True)\n",
    "            multich_sliced_brain.markers = [marker1 if m == marker1_diff else m for m in multich_sliced_brain.markers]\n",
    "        sliced_brains.append(multich_sliced_brain)\n",
    "    groups_slices.append(sliced_brains)\n",
    "    print(f\"Imported all brain slices from {str(len(group.dirs))} animals of {group.name} group.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REMOVE_SMALL_REGIONS_FROM_SLICES:\n",
    "    for group_ in groups_slices:\n",
    "        for animal_ in group_:\n",
    "            for s in animal_.slices:\n",
    "                s._data = s.data\n",
    "                s.data = s.data[(s.data[marker1] != 1) & (s.data[marker2] != 1) & (s.data.area > 0.001)].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023_08_28__0792.czi - Scene #08 of 371 excludes both right and left of 'root'!\n",
    "if PLOT_ANIMALS_ROOTS:\n",
    "    region_name = \"root\"\n",
    "    root_plot = BraiAn.plot_region_density(region_name, *groups_slices, width=1000, height=500)\n",
    "    root_plot.layout.title = f\"IEG densities in '{region_name}'\"\n",
    "    root_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"N regions above threshold:\", sum([(brain.data > cv_threshold).sum() for brain in cvar_brains]))\n",
    "# print(\"N regions below threshold:\", sum([(brain.data <= cv_threshold).sum() for brain in cvar_brains]))\n",
    "if PLOT_COEFFICIENT_OF_VARIATION:\n",
    "    cvar_plot = BraiAn.plot_cv_above_threshold(AllenBrain, *groups_slices, cv_threshold=PLOT_COEFFICIENT_OF_VARIATION_THRESHOLD, width=1000, height=500)\n",
    "    cvar_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"MD\"\n",
    "a = \"371\"\n",
    "# m = \"cFos\"\n",
    "def check_animal_region(animal_name: str, region_acronym: str, marker=None):\n",
    "    try:\n",
    "        sliced_brain = next(animal for group in groups_slices for animal in group if animal_name == animal.name)\n",
    "    except StopIteration:\n",
    "        print(f\"Can't find region '{region_acronym}' for animal '{animal_name}'\")\n",
    "        return\n",
    "    sliced_brain = BraiAn.merge_sliced_hemispheres(sliced_brain)\n",
    "    all_slices_df = sliced_brain.concat_slices()\n",
    "    slices_per_area = all_slices_df.groupby(all_slices_df.index).count().iloc[:,0]\n",
    "    markers = sliced_brain.markers if marker is None else [marker]\n",
    "    brain_avg = BraiAn.AnimalBrain(sliced_brain, mode=\"avg\", hemisphere_distinction=False, use_literature_reuniens=USE_LITERATURE_REUNIENS).data\n",
    "    brain_std = BraiAn.AnimalBrain(sliced_brain, mode=\"std\", hemisphere_distinction=False, use_literature_reuniens=USE_LITERATURE_REUNIENS).data\n",
    "    for m in markers:\n",
    "        marker_avg = brain_avg[f\"{m}_density\"]\n",
    "        marker_std = brain_std[f\"{m}_density\"]\n",
    "        print(f\"\"\"Summary for brain region '{region_acronym}' of marker '{m}':\n",
    "            - N slices: {slices_per_area[region_acronym]}\n",
    "            - Mean: {marker_avg[region_acronym]:.2f} {m}/mm²),\n",
    "            - S.D.: {marker_std[region_acronym]:.2f} {m}/mm²,\n",
    "            - Coefficient of Variation: {marker_avg[region_acronym]}\n",
    "        \"\"\")\n",
    "# for a in groups[-1].dirs:\n",
    "check_animal_region(a, r) #, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see the slices in specific, run this\n",
    "import pandas as pd\n",
    "slices = []\n",
    "try:\n",
    "    sliced_brain = next(animal for group in groups_slices for animal in group if a == animal.name)\n",
    "    sliced_brain = BraiAn.merge_sliced_hemispheres(sliced_brain)\n",
    "    for slice in sliced_brain.slices:\n",
    "        if r not in slice.data.index:\n",
    "            continue\n",
    "        region = slice.data.loc[r].copy()\n",
    "        for marker in sliced_brain.markers:\n",
    "            region[f\"{marker} density\"] = region[marker] / region[\"area\"]\n",
    "        region[\"name\"] = slice.name\n",
    "        slices.append(region)\n",
    "except StopIteration:\n",
    "    print(f\"Can't find region '{r}' for animal '{a}'\")\n",
    "pd.concat(slices, axis=1) if len(slices) != 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell:\n",
    "#  * creates a summed AnimalBrain for each SlicedBrain\n",
    "#  * from each animal, removes all regions that have a coefficent of variation above cvar_threshold\n",
    "#  * for each animal, computes the percentage of both marker1 and marker2 overlapping with each other\n",
    "#  * for each group, computes the normalizations (Density, RelativeDensity & Percentage)\n",
    "#  * for each group, computes the average percentage of overlapping\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cvar_threshold = 1\n",
    "\n",
    "avg_overlap_groups = []\n",
    "normalized_groups = []\n",
    "for i, group in enumerate(groups_slices):\n",
    "    animal_brains_df = []\n",
    "    animal_brains = []\n",
    "    for slices in group:\n",
    "        if REMOVE_HIGH_CV_REGIONS:\n",
    "            # remove all regions that have a Coefficent of Variation above cvar_threshold\n",
    "            cvars = BraiAn.AnimalBrain(slices, mode=\"cvar\", hemisphere_distinction=False, min_slices=0).data\n",
    "            disperse_regions = cvars.index[(cvars > cvar_threshold)[[f\"{marker1}_density\", f\"{marker2}_density\"]].any(axis=1)]\n",
    "            print(f\"removing {len(disperse_regions)}/{len(cvars)} dispersive regions from '{slices.name}'\")\n",
    "        animal_brain = BraiAn.AnimalBrain(slices, hemisphere_distinction=False, mode=\"sum\", min_slices=0)\n",
    "        animal_brains.append(animal_brain)\n",
    "\n",
    "        animal_brain_df = animal_brain.data\n",
    "        if REMOVE_HIGH_CV_REGIONS:\n",
    "            animal_brain_df[~animal_brain_df.index.isin(disperse_regions)]\n",
    "        animal_brain_df[f\"%{marker1}_overlapping\"] = animal_brain_df[f\"{marker1}+{marker2}\"] / animal_brain_df[marker1]\n",
    "        animal_brain_df[f\"%{marker2}_overlapping\"] = animal_brain_df[f\"{marker1}+{marker2}\"] / animal_brain_df[marker2]\n",
    "        animal_brains_df.append(animal_brain_df)\n",
    "\n",
    "    normalized_group = BraiAn.AnimalGroup(groups[i].name, animal_brains, AllenBrain)\n",
    "    normalized_groups.append(normalized_group)\n",
    "    avg_overlap = dict()\n",
    "    for i, brain in enumerate(animal_brains_df):\n",
    "        avg_overlap[i] = brain[[f\"%{marker1}_overlapping\", f\"%{marker2}_overlapping\"]]\n",
    "    avg_overlap = pd.concat(avg_overlap, join=\"outer\").groupby(level=1).mean()\n",
    "    avg_overlap_groups.append(avg_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# animal_brain.to_csv(\"FC_369.csv\", sep=\",\")\n",
    "# pd.read_csv(\"FC_369.csv\", sep=\",\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bgheatmaps as bgh\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import vedo as vd\n",
    "\n",
    "# vd.embedWindow(None)\n",
    "vd.embedWindow(\"k3d\") # doesn't spawn a 3rd party window frame for the scene\n",
    "# vd.embedWindow(\"itkwidgets\")\n",
    "\n",
    "def make_filename(*ss: str):\n",
    "    return \"_\".join((s.replace(' ', '_') for s in ss if s != \"\"))\n",
    "\n",
    "def plot_brain(plot_filename: str, brain_data: pd.DataFrame, n: int, title: str, selected_regions: list[str],\n",
    "                cmin=None, cmax=None, cmap=\"OrRd\", show_text=True):\n",
    "    heatmaps = []\n",
    "    hems = (\"right\", \"left\")\n",
    "    # brain_data = brain_data.loc[selected_regions]\n",
    "    brain_data = brain_data[brain_data.index.isin(selected_regions)]\n",
    "    brain_data = brain_data[~brain_data.isna().all(axis=1)]\n",
    "    if cmin is None:\n",
    "        cmin = math.floor(brain_data[brain_data != np.inf].min(axis=None))\n",
    "    if cmax is None:\n",
    "        cmax = math.ceil(brain_data[brain_data != np.inf].max(axis=None))\n",
    "    for metric, hem in zip(brain_data.columns, hems):\n",
    "        metric_data = brain_data[metric]\n",
    "        dataDict = metric_data.to_dict()\n",
    "\n",
    "        print(f\"Rendering '{metric}' heatmap ({hem} hemisphere)...\")\n",
    "        heatmap = bgh.heatmap(\n",
    "            dataDict,\n",
    "            position=5000,\n",
    "            orientation=\"frontal\",\n",
    "            thickness=15000,\n",
    "            title=metric,\n",
    "            cmap=cmap, # \"PuBu\",\n",
    "            vmin=cmin,\n",
    "            vmax=cmax,\n",
    "            format=\"2D\",\n",
    "            hemisphere=hem  # this option was added by me in my local installation of bgheatmaps.heatmap() in order to split the heatmap in two\n",
    "                            # if you don't know how to do it, just remove this row\n",
    "        )\n",
    "        #heatmap.scene.close()\n",
    "        heatmaps.append(heatmap)\n",
    "    heatmap1, heatmap2 = heatmaps\n",
    "\n",
    "    print(\"depths: \", end=\"\")\n",
    "    for depth in np.linspace(1500,11000,n):\n",
    "        # center = heatmap.scene.root.centerOfMass()\n",
    "        print(f\"{depth:.2f}\", end=\"  \")\n",
    "        s = bgh.slicer.Slicer(depth, \"frontal\", 100, heatmap1.scene.root) # BraiAn.Plane(center, np.array([0,0,1]), np.array([0,1,0])) # frontal\n",
    "        heatmap.slicer = s\n",
    "        projected1, _ = heatmap.slicer.get_structures_slice_coords(heatmap1.regions_meshes, heatmap1.scene.root)\n",
    "        projected2, _ = heatmap.slicer.get_structures_slice_coords(heatmap2.regions_meshes, heatmap2.scene.root)\n",
    "\n",
    "        f, ax = plt.subplots(figsize=(9, 9))\n",
    "        for r, coords in projected1.items():\n",
    "            name, segment = r.split(\"_segment_\")\n",
    "            filled_polys = ax.fill(\n",
    "                coords[:, 0],\n",
    "                coords[:, 1],\n",
    "                color=heatmap1.colors[name],\n",
    "                label=name if segment == \"0\" and name != \"root\" else None,\n",
    "                lw=1,\n",
    "                ec=\"k\",\n",
    "                zorder=-1 if name == \"root\" or heatmap1.colors[name] == [0,0,0] else None,\n",
    "                alpha=0.3 if name == \"root\" or heatmap1.colors[name] == [0,0,0] else None,\n",
    "            )\n",
    "            if name == \"root\":\n",
    "                continue\n",
    "            (x0, y0), (x1, y1) = filled_polys[0].get_path().get_extents().get_points()\n",
    "            if show_text:\n",
    "                ax.text((x0 + x1) / 2, (y0 + y1) / 2, name, ha=\"center\", va=\"center\", fontsize=10, color=\"black\")\n",
    "        for r, coords in projected2.items():\n",
    "            name, segment = r.split(\"_segment_\")\n",
    "            filled_polys = ax.fill(\n",
    "                coords[:, 0],\n",
    "                coords[:, 1],\n",
    "                color=heatmap2.colors[name],\n",
    "                label=name if segment == \"0\" and name != \"root\" else None,\n",
    "                lw=1,\n",
    "                ec=\"k\",\n",
    "                zorder=-1 if name == \"root\" or heatmap2.colors[name] == [0,0,0] else None,\n",
    "                alpha=0.3 if name == \"root\" or heatmap2.colors[name] == [0,0,0] else None,\n",
    "            )\n",
    "            if name == \"root\":\n",
    "                continue\n",
    "            (x0, y0), (x1, y1) = filled_polys[0].get_path().get_extents().get_points()\n",
    "            if show_text:\n",
    "                ax.text((x0 + x1) / 2, (y0 + y1) / 2, name, ha=\"center\", va=\"center\", fontsize=10, color=\"white\")\n",
    "\n",
    "        # set title\n",
    "        ax.set_title(title, fontsize=20, pad=-15)\n",
    "        for data_column, hem in zip(brain_data.columns, reversed(hems)): # the hemispheres are flipped because the brain is cut front->back, not back->front\n",
    "            ax.set_title(data_column, loc=hem, y=0, pad=-15)\n",
    "\n",
    "        # style axes\n",
    "        ax.invert_yaxis()\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set(xlabel='', ylabel='')\n",
    "        ax.set_aspect('equal',adjustable='box')\n",
    "\n",
    "        # add colorbar\n",
    "        ax.figure.colorbar(\n",
    "            mpl.cm.ScalarMappable(norm=mpl.colors.Normalize(vmin=heatmap.vmin, vmax=heatmap.vmax), cmap=heatmap.cmap),\n",
    "            ax=ax, label=title, fraction=0.046, pad=0.04\n",
    "        )\n",
    "\n",
    "        plot_filepath = os.path.join(plots_output_path, plot_filename+f\"_{depth:05.0f}.svg\")\n",
    "        f.savefig(plot_filepath)\n",
    "        plt.close(f)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_regions.remove(\"RSPd4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overlapping\n",
    "for avg_overlap, group in zip(avg_overlap_groups, groups):\n",
    "    filename = make_filename(\"overlapping\", group.name, f\"{marker1}+{marker2}\")\n",
    "    plot_brain(filename, avg_overlap, 12, \"overlapping\", selected_regions, cmap=\"magma_r\", show_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(normalized_groups)%2 == 0:\n",
    "    for right_g, left_g in zip(normalized_groups[::2], normalized_groups[1::2]):\n",
    "        for marker in (marker1, marker2):\n",
    "            marker_density_change = pd.concat({\n",
    "                    right_g.name: right_g.group_by_region(marker=marker, method=\"Density\").mean(), # .apply(lambda x: np.nan if x.isna().all() else np.nanmean(x)), # .data[marker][\"Density\"].groupby(level=0).mean(),\n",
    "                    left_g.name:   left_g.group_by_region(marker=marker, method=\"Density\").mean()  # .apply(lambda x: np.nan if x.isna().all() else np.nanmean(x))  # .data[marker][\"Density\"].groupby(level=0).mean()\n",
    "                }, axis=1)\n",
    "            # filename = make_filename(\"density\", \"hsv\", marker, f\"{left_g.name}+{right_g.name}\")\n",
    "            # plot_brain(filename, marker_density_change, 12, \"density\", selected_regions, cmap=\"hsv\")\n",
    "            filename = make_filename(\"density\", marker, f\"{right_g.name}+{left_g.name}\")\n",
    "            plot_brain(filename, marker_density_change, 12, \"density\", selected_regions, cmap=\"magma_r\", show_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(normalized_groups) == 2:\n",
    "    # for each marker, get the density fold change of group1 (e.g. FC) over group2 (e.g. HC)\n",
    "    fold_change = dict()\n",
    "    for marker in (marker1, marker2):\n",
    "        marker_density_change = pd.concat({\n",
    "                normalized_group.name: normalized_group.data[marker][\"Density\"].groupby(level=0).mean()\n",
    "                for normalized_group in normalized_groups\n",
    "            }, axis=1)\n",
    "        # compute the fold change of group1 over group2\n",
    "        fold_change[f\"{marker}_density_fold_change\"] = marker_density_change[normalized_groups[0].name] / marker_density_change[normalized_groups[1].name]\n",
    "    fold_change = pd.concat(fold_change, axis=1)\n",
    "    # filename = make_filename(\"fold change\", \"hsv\", f\"{marker1}+{marker2}\")\n",
    "    # plot_brain(filename, fold_change, 12, \"fold change\", selected_regions, cmap=\"hsv\")\n",
    "    filename = make_filename(\"fold change\", \"max5\", f\"{marker1}+{marker2}\")\n",
    "    plot_brain(filename, fold_change, 12, \"fold change\", selected_regions, cmin=-3, cmax=5, cmap=\"coolwarm\")\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "__imported_modules = sys.modules.copy()\n",
    "for module_name, module in __imported_modules.items():\n",
    "    if not module_name.startswith(\"BraiAn\"):\n",
    "        continue\n",
    "    try:\n",
    "        importlib.reload(module)\n",
    "    except ModuleNotFoundError:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
