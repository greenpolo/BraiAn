{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### GENERAL OPTIONS #######################################\n",
    "data_root = \"/run/user/1000/gvfs/smb-share:server=ich.techosp.it,share=ricerca/Lab Matteoli/Silva/collaborations/Mathias/soumnya/data/experiment/\"\n",
    "plots_root = \"/run/user/1000/gvfs/smb-share:server=ich.techosp.it,share=ricerca/Lab Matteoli/Silva/collaborations/Mathias/soumnya/results/experiment/plots/\"\n",
    "branches_to_exclude = [\"retina\", \"VS\", \"grv\", \"fiber tracts\", \"CB\"]\n",
    "region_to_plot_selection_method = \"depth 5\"         # Available options are: \"summary structures\", \"major divisions\" \"depth <n>\", \"structural level <n>\"\n",
    "                                                    # where <n> is an integer of the depth/level desired\n",
    "normalization = \"Density\"                           # call get_normalization_methods() on a AnimalGroup object to know its available normalization methods\n",
    "saved_plot_extension = \".html\"                      # '.html' for interactive plot\n",
    "                                                    # '.svg' for vectorized image\n",
    "                                                    # '.png'/'.jpg'/... for rasterized image\n",
    "\n",
    "# ######################################### PLS OPTIONS #########################################\n",
    "pls_salience_threshold = 1.2 # Only brain regions with a salience higher than plot_threshold are shown. 2 is the significance threshold.\n",
    "pls_rank = 1\n",
    "pls_num_bootstrap = 5000\n",
    "pls_num_permutations = 5000\n",
    "plot_distribution_of_singular_values = True\n",
    "plot_salience_scores = True\n",
    "\n",
    "# ########################################## BAR PLOT ###########################################\n",
    "bar_height = 10_000\n",
    "bar_use_acronyms = False\n",
    "bar_save_plot = True\n",
    "bar_show_plot = False\n",
    "\n",
    "# ###################################### CORRELATION MATRIX #####################################\n",
    "matrix_cell_height = 5\n",
    "matrix_cell_ratio = 3/2\n",
    "matrix_min_plot_height = 500\n",
    "matrix_save_plot = True\n",
    "matrix_show_plot = True\n",
    "\n",
    "# ######################################## CHORD DIAGRAM ########################################\n",
    "chord_p_cutoff = 1 # 0.05                      # 1 if you don't want to filter by p-value\n",
    "chord_r_cutoff = 0.8\n",
    "chord_plot_size = 1200\n",
    "chord_no_background = False\n",
    "chord_regions_size = 15\n",
    "chord_regions_font_size = 10\n",
    "chord_max_edge_width = 5\n",
    "chord_use_weighted_edge_widths = True\n",
    "chord_use_colorscale_edges = True\n",
    "chord_save_plot = True\n",
    "chord_show_plot = True\n",
    "chord_bottom_annotations = dict(\n",
    "    annotation1 = \"Dark grey nodes are regions with insufficient data to compute cross correlation\",\n",
    "    annotation2 = \"Light grey nodes are regions with no correlation with others above the threshold\",\n",
    "    annotation3 = \"This is the third annotation\",\n",
    "    # howmany annotations desired with the following format:\n",
    "    # annotations<k> = \"<annotation>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"soumnya\"\n",
    "group_1_name = \"Control\"\n",
    "group_2_name = \"Stress\"\n",
    "output_folder = \"C-S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"soumnya\"\n",
    "group_1_name = \"Control (Females)\"\n",
    "group_2_name = \"Stress (Females)\"\n",
    "output_folder = \"CF-SF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"soumnya\"\n",
    "group_1_name = \"Control (Males)\"\n",
    "group_2_name = \"Stress (Males)\"\n",
    "output_folder = \"CM-SM\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BraiAn\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_path = os.path.join(data_root, \"BraiAn_output\")\n",
    "data_output_path = os.path.join(data_input_path, output_folder)\n",
    "plots_output_path = os.path.join(plots_root, output_folder)\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)\n",
    "\n",
    "if not(os.path.exists(plots_output_path)):\n",
    "    os.makedirs(plots_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = BraiAn.AnimalGroup.from_csv(group_1_name, data_input_path, f\"cell_counts_{group_1_name}.csv\")\n",
    "group_2 = BraiAn.AnimalGroup.from_csv(group_2_name, data_input_path, f\"cell_counts_{group_2_name}.csv\")\n",
    "if not group_1.is_comparable(group_2):\n",
    "    raise ImportError(\"Group 1 and Group 2 are not comparable!\\n\\\n",
    "Please check that you're reading two groups that normalized on the same brain regions and on the same marker\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are stored in ```group_1.data``` and ```group_2.data```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "# StructureGraph id=1\n",
    "path_to_allen_json = \"./data/AllenMouseBrainOntology.json\"\n",
    "AllenBrain = BraiAn.AllenBrainHierarchy(path_to_allen_json, branches_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if region_to_plot_selection_method == \"summary structures\":\n",
    "    AllenBrain.select_from_csv(\"./data/AllenSummaryStructures.csv\")\n",
    "     # selects the Summary Strucutures\n",
    "elif region_to_plot_selection_method == \"major divisions\":\n",
    "    AllenBrain.select_regions(BraiAn.MAJOR_DIVISIONS)\n",
    "elif region_to_plot_selection_method.startswith(\"depth\"):\n",
    "    n = region_to_plot_selection_method.split(\" \")[-1]\n",
    "    try:\n",
    "        depth = int(n)\n",
    "    except Exception:\n",
    "        raise Exception(\"Could not retrieve the <n> parameter of the 'depth' method for 'region_to_plot_selection_method'\")\n",
    "    regions_to_plot = AllenBrain.select_at_depth(depth)\n",
    "elif region_to_plot_selection_method.startswith(\"structural level\"):\n",
    "    n = region_to_plot_selection_method.split(\" \")[-1]\n",
    "    try:\n",
    "        level = int(n)\n",
    "    except Exception:\n",
    "        raise Exception(\"Could not retrieve the <n> parameter of the 'structural level' method for 'region_to_plot_selection_method'\")\n",
    "    regions_to_plot = AllenBrain.select_at_structural_level(level)\n",
    "regions_to_plot = AllenBrain.get_selected_regions()\n",
    "print(f\"You selected {len(regions_to_plot)} regions to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Least Squares  \n",
    "\n",
    "The analysis done below is taken from the tutorial written by [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074).  \n",
    "Run the 2 cells below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PLS object\n",
    "pls = BraiAn.PLS(group_1, group_2, regions_to_plot, normalization)\n",
    "\n",
    "# Show the matrix X\n",
    "pls.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the matrix Y\n",
    "pd.get_dummies(pls.y).rename(columns={0: group_2_name, 1: group_1_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two matrices printed above (X and Y) illustrate the data on which the PLS is done.  \n",
    "- ```X:``` The rows in this matrix are the mice. The columns in the matrix are the regions selected for analysis. The values in the matrix are the **normalized value of marked cells: in that region relative to the whole brain.** \n",
    "The normalization methods are either:\n",
    "  + Density\n",
    "  + Percentage (on the total number of detected marked cells outside of excluded regions)\n",
    "  + RelativeDensity\n",
    "- ```Y:``` The rows in this matrix are the mice. The columns in the matrix are the 2 groups. **A value in this matrix is 1 if the mice belongs to the specified group**.\n",
    "\n",
    "In brief, PLS analyzes the relationship (correlation) between the columns of ```X``` and ```Y```. In our specific case, there will be 2 important outputs:\n",
    "- **Salience scores**: Each brain region has a salience score. A high salience scores means that the brain region explains much of the correlation between ```X``` and ```Y```.  \n",
    "- **Singular values**: These are the eigenvalues of the correlation matrix $R = Y^TX$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random permutations to see whether we can differentiate signal from noise. \n",
    "Here, we randomly shuffle the group to which a mouse belongs, and calculate the singular values of the permuted dataset.  \n",
    "From [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074):  \n",
    "> The set of all the (permuted) singular values provides a sampling distribution of the singular values under the null hypothesis and, therefore can be used as a null hypothesis test.\n",
    "\n",
    "*Note: running the cell below will take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Randomly permuting singular values {pls_num_permutations} times...\")\n",
    "s,singular_values = pls.randomly_permute_singular_values(pls_num_permutations)\n",
    "# Plot distribution of singular values\n",
    "if plot_distribution_of_singular_values:\n",
    "    fig = BraiAn.plot_permutation(pls.s[0], singular_values, pls_num_permutations)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate p-value = Probability(experiment | H0)\n",
    "p = (singular_values[:,0] > s[0]).sum() / pls_num_permutations\n",
    "print(\"p-value = \"+str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap to identify stable salience scores\n",
    "\n",
    "Here, we use [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) (= sampling of the mice in the dataset, with replacement) to get an estimate of which salience scores are stable.\n",
    "\n",
    "From [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074):  \n",
    "> When a vector of saliences is considered generalizable and is kept for further analysis, we need to identify its elements that are stable through resampling. In practice, the stability of an element is evaluated by dividing it by its standard error. [...] To estimate the standard errors, we create bootstrap samples which are obtained by sampling with replacement the observations in and (Efron and Tibshirani, 1986). A salience standard error is then estimated as the standard error of the saliences from a large number of these bootstrap samples (say 1000 or 10000). **The ratios are akin to a Z-score, therefore when they are larger than 2 the corresponding saliences are considered significantly stable.**\n",
    "\n",
    "*Note: Running the cell below will take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Bootstrapping salience scores {pls_num_bootstrap} times...\")\n",
    "u_salience_scores,v_salience_scores = pls.bootstrap_salience_scores(pls_rank, pls_num_bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PLS salience scores\n",
    "if plot_salience_scores:\n",
    "    file_title = f\"PLS_{group_1.marker}_{normalization}.svg\".lower()\n",
    "    tp, salient_regions = pls.plot_salience_scores(pls_salience_threshold, plots_output_path, file_title,\n",
    "                                  fig_width=1000, fig_height=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salient_regions = salient_regions.reset_index()\n",
    "# salient_regions.columns = [\"region\", \"salience\"]\n",
    "# salient_regions[\"salience\"] = salient_regions[\"salience\"].abs()\n",
    "# salient_regions = salient_regions.sort_values(by=\"salience\")\n",
    "# salient_regions.to_csv(os.path.join(data_output_path, \"salient_regions.csv\"), sep=\";\", index=False)\n",
    "# salient_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_filename = f\"PLS_{group_1.marker}_{normalization}_salience_scores.csv\".lower()\n",
    "v_salience_scores = v_salience_scores.rename(columns={0:\"salience score\"})\n",
    "BraiAn.save_csv(v_salience_scores, data_output_path, pls_filename, overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = BraiAn.plot_groups(normalization, AllenBrain, group_1, group_2,\n",
    "                            selected_regions=regions_to_plot, use_acronyms=bar_use_acronyms, height=bar_height)\n",
    "\n",
    "if bar_save_plot:\n",
    "    plot_filename =    f\"pls_barplot_{output_folder}_{normalization}_{group_1.marker}{saved_plot_extension}\".lower()\n",
    "    plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "    match saved_plot_extension.lower():\n",
    "        case \".html\":\n",
    "            fig.write_html(plot_filepath)\n",
    "        case _:\n",
    "            fig.write_image(plot_filepath)\n",
    "if bar_show_plot:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_cross_correlations = []\n",
    "for group in (group_1, group_2):\n",
    "    # min_animals=None because it doesn't matter. PLS already removes every region with NaNs.\n",
    "    r, p = group.cross_correlation(normalization, regions_to_plot, min_animals=None)\n",
    "    groups_cross_correlations.append((r, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if matrix_save_plot or matrix_show_plot:\n",
    "    for group, (r,p) in zip((group_1, group_2), groups_cross_correlations):\n",
    "        title = f\"{group.name} Pearson cross correlation matrix (n = {group.n})\"\n",
    "        fig = BraiAn.plot_cross_correlation(r=r, p=p,\n",
    "                title=title,\n",
    "                cell_height=matrix_cell_height, min_plot_height=matrix_min_plot_height,\n",
    "                aspect_ratio=matrix_cell_ratio)\n",
    "        if matrix_save_plot:\n",
    "            plot_filename = f\"pls_correlation_matrix_filtered_{group.name}_{normalization}_{group.marker}{saved_plot_extension}\".lower()\n",
    "            plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "            match saved_plot_extension.lower():\n",
    "                case \".html\":\n",
    "                    fig.write_html(plot_filepath)\n",
    "                case _:\n",
    "                    fig.write_image(plot_filepath)\n",
    "        if matrix_show_plot:\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, (r,p) in zip((group_1, group_2), groups_cross_correlations):\n",
    "    group_annotations = dict(\n",
    "                            subtitle=\"\",\n",
    "                            **chord_bottom_annotations\n",
    "                        )\n",
    "    fig = BraiAn.draw_chord_plot(r=r, p=p, r_cutoff=chord_r_cutoff, p_cutoff=chord_p_cutoff,\n",
    "                                AllenBrain=AllenBrain,\n",
    "                                ideograms_a=50,\n",
    "                                title=f\"{group.name} connectomics graph from Pearson correlation (n = {group.n}, |r| >= {chord_r_cutoff}, p <= {chord_p_cutoff})\",\n",
    "                                size=chord_plot_size,\n",
    "                                no_background=chord_no_background,\n",
    "                                regions_size=chord_regions_size,\n",
    "                                regions_font_size=chord_regions_font_size,\n",
    "                                max_edge_width=chord_max_edge_width,\n",
    "                                use_weighted_edge_widths=chord_use_weighted_edge_widths,\n",
    "                                colorscale_edges=chord_use_colorscale_edges,\n",
    "                                **group_annotations\n",
    "    )\n",
    "    if chord_save_plot:\n",
    "        plot_filename = f\"pls_chord_plot_filtered_{group.name}_{normalization}_{group.marker}{saved_plot_extension}\".lower()\n",
    "        plot_filepath = os.path.join(plots_output_path, plot_filename)\n",
    "        match saved_plot_extension.lower():\n",
    "            case \".html\":\n",
    "                fig.write_html(plot_filepath)\n",
    "            case _:\n",
    "                fig.write_image(plot_filepath)\n",
    "    if chord_show_plot:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(BraiAn.plot_chord)\n",
    "importlib.reload(BraiAn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
