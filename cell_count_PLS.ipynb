{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BraiAn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll need other python functions to easily read and manipulate data and make nice plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Below, you have to specify:\n",
    "- ```animals_root```: Absolute path to the folder that contains the animal folders.\n",
    "- ```group_1_name```: A meaningful string for Group 1.\n",
    "- ```group_2_name```: A meaningful string for Group 2.\n",
    "- ```group_1_names```: A list of names of the folders corresponding to animals in **Group 1** (e.g., Control group). Indeed, it is necessary to store the results in individual folders for each animal.\n",
    "- ```group_2_names```: A list of names of the folders corresponding to animals in **Group 2** (e.g., Stress group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################### SET PARAMETERS ####################################\n",
    "\n",
    "\n",
    "animals_root = './data/QuPath_output/'\n",
    "group_1_name = 'Control'\n",
    "group_2_name = 'Stress'\n",
    "\n",
    "data_input_path = './data/python_norm_output/'\n",
    "data_output_path = './data/python_PLS_output/'\n",
    "plots_output_path = './plots/python_output/'\n",
    "\n",
    "\n",
    "# ###########################################################################################\n",
    "\n",
    "\n",
    "if not(os.path.exists(data_output_path)):\n",
    "    os.makedirs(data_output_path, exist_ok=True)\n",
    "\n",
    "if not(os.path.exists(plots_output_path)):\n",
    "    os.makedirs(plots_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1_results = pd.read_csv(os.path.join(data_input_path, f'results_cell_counts_{group_1_name}.csv'), sep='\\t', header=[0, 1], index_col=[0,1])\n",
    "group_2_results = pd.read_csv(os.path.join(data_input_path, f'results_cell_counts_{group_2_name}.csv'), sep='\\t', header=[0, 1], index_col=[0,1])\n",
    "\n",
    "group_1_names = {index[1] for index in group_1_results.index}\n",
    "group_2_names = {index[1] for index in group_2_results.index}\n",
    "\n",
    "group_1_tracers = list({cols[0] for cols in group_1_results.columns})\n",
    "group_2_tracers = list({cols[0] for cols in group_2_results.columns})\n",
    "assert len(group_1_tracers) == len(group_2_tracers) == 1, \"The CSVs in input should have data for one tracer only.\"\n",
    "assert group_1_tracers[0] == group_2_tracers[0], f\"The data in the CSV of group 1 and 2 should refer to the same tracer. \\\n",
    "Instead group 1 CSV presents data for the tracer '{group_1_tracers[0]}', while group 2 CSV for '{group_2_tracers[0]}'.\"\n",
    "tracer = group_1_tracers[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are stored in ```group_1_results``` and ```group_2_results```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://help.brain-map.org/display/api/Downloading+an+Ontology%27s+Structure+Graph\n",
    "# StructureGraph id=1\n",
    "path_to_allen_json = \"./data/AllenMouseBrainOntology.json\"\n",
    "\n",
    "branches_to_exclude = ['retina','VS','grv','fiber tracts']\n",
    "AllenBrain = BraiAn.AllenBrainHierarchy(path_to_allen_json, branches_to_exclude)\n",
    "\n",
    "# Now, get the selected regions as a variable:\n",
    "level = 6\n",
    "\n",
    "AllenBrain.select_at_structural_level(level)\n",
    "selected_regions = AllenBrain.get_selected_regions()\n",
    "print(f'You selected {len(selected_regions)} regions at level {level}.')\n",
    "\n",
    "AllenBrain.unselect_all()\n",
    "AllenBrain.select_at_depth(level)\n",
    "selected_regions = AllenBrain.get_selected_regions()\n",
    "print(f'You selected {len(selected_regions)} regions at depth {level}.')\n",
    "\n",
    "AllenBrain.unselect_all()\n",
    "AllenBrain.select_from_csv(\"./data/AllenSummaryStructures.csv\")\n",
    "selected_regions = AllenBrain.get_selected_regions()\n",
    "print(f'You selected {len(selected_regions)} Summary Structure regions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Least Squares  \n",
    "\n",
    "The analysis done below is taken from the tutorial written by [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074).  \n",
    "Run the 2 cells below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLS\n",
    "normalization = 'Density' # 'Density', 'Percentage' or 'RelativeDensity'\n",
    "rank = 1\n",
    "\n",
    "# Create a PLS object\n",
    "# TODO: see what happens if analyze() does not include the NaN rows\n",
    "cfosPLS = BraiAn.PLS(group_1_results, group_2_results, group_1_names, group_2_names, selected_regions, tracer, normalization)\n",
    "\n",
    "# Show the matrix X\n",
    "cfosPLS.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the matrix Y\n",
    "pd.get_dummies(cfosPLS.y).rename(columns={0: group_2_name, 1: group_1_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two matrices printed above (X and Y) illustrate the data on which the PLS is done.  \n",
    "- ```X:``` The rows in this matrix are the mice. The columns in the matrix are the regions selected for analysis. The values in the matrix are the **normalized value of marked cells: in that region relative to the whole brain.** \n",
    "The normalization methods are either:\n",
    "  + Density\n",
    "  + Percentage (on the total number of detected marked cells outside of excluded regions)\n",
    "  + RelativeDensity\n",
    "- ```Y:``` The rows in this matrix are the mice. The columns in the matrix are the 2 groups. **A value in this matrix is 1 if the mice belongs to the specified group**.\n",
    "\n",
    "In brief, PLS analyzes the relationship (correlation) between the columns of ```X``` and ```Y```. In our specific case, there will be 2 important outputs:\n",
    "- **Salience scores**: Each brain region has a salience score. A high salience scores means that the brain region explains much of the correlation between ```X``` and ```Y```.  \n",
    "- **Singular values**: These are the eigenvalues of the correlation matrix $R = Y^TX$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random permutations to see whether we can differentiate signal from noise. \n",
    "Here, we randomly shuffle the group to which a mouse belongs, and calculate the singular values of the permuted dataset.  \n",
    "From [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074):  \n",
    "> The set of all the (permuted) singular values provides a sampling distribution of the singular values under the null hypothesis and, therefore can be used as a null hypothesis test.\n",
    "\n",
    "*Note: running the cell below will take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_permutations = 5000\n",
    "print(f'Randomly permuting singular values %d times ...'%num_permutations)\n",
    "s,singular_values = cfosPLS.randomly_permute_singular_values(num_permutations)\n",
    "print('Done!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to Plotly\n",
    "\n",
    "# Plot distribution of singular values\n",
    "# plt.figure(figsize=(10,4))\n",
    "# plt.hist(singular_values[:,0],bins=10)\n",
    "# plt.axvline(cfosPLS.s[0], color='r')\n",
    "# plt.xlabel('First singular value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.legend([f'Experiment','Sampling distribution\\nunder H0 (%d permutations)'%num_permutations])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate p-value = Probability(experiment | H0)\n",
    "p = (singular_values[:,0] > s[0]).sum() / num_permutations\n",
    "print('p-value = '+str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap to identify stable salience scores\n",
    "\n",
    "Here, we use [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) (= sampling of the mice in the dataset, with replacement) to get an estimate of which salience scores are stable.\n",
    "\n",
    "From [Krishnan et al.](https://www.sciencedirect.com/science/article/pii/S1053811910010074):  \n",
    "> When a vector of saliences is considered generalizable and is kept for further analysis, we need to identify its elements that are stable through resampling. In practice, the stability of an element is evaluated by dividing it by its standard error. [...] To estimate the standard errors, we create bootstrap samples which are obtained by sampling with replacement the observations in and (Efron and Tibshirani, 1986). A salience standard error is then estimated as the standard error of the saliences from a large number of these bootstrap samples (say 1000 or 10000). **The ratios are akin to a Z-score, therefore when they are larger than 2 the corresponding saliences are considered significantly stable.**\n",
    "\n",
    "*Note: Running the cell below will take a few minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bootstrap = 5000\n",
    "print(f'Bootstrapping salience scores {num_bootstrap} times...')\n",
    "u_salience_scores,v_salience_scores = cfosPLS.bootstrap_salience_scores(rank, num_bootstrap)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PLS salience scores\n",
    "plot_threshold = 1.2 # Only brain regions with a salience higher than plot_threshold are shown. 2 is the significance threshold.\n",
    "file_title = f'PLS_{tracer}_{normalization}.png'\n",
    "tp, salient_regions = cfosPLS.plot_salience_scores(plot_threshold, plots_output_path, file_title, AllenBrain.brain_region_dict,\n",
    "                              fig_width=1000, fig_height=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salient_regions = salient_regions.reset_index()\n",
    "salient_regions.columns = ['region', 'salience']\n",
    "salient_regions['salience'] = salient_regions['salience'].abs()\n",
    "salient_regions = salient_regions.sort_values(by='salience')\n",
    "salient_regions.to_csv(os.path.join(data_output_path, 'salient_regions.csv'), sep=';', index=False)\n",
    "salient_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results_df, output_path, filename):\n",
    "    if not(os.path.exists(output_path)):\n",
    "        os.mkdir(output_path)\n",
    "        print('\\nCreated a new results_python folder '+output_path+' \\n')\n",
    "    else:\n",
    "        print('\\n! A results_python folder already existed in root. I am overwriting previous results!\\n')\n",
    "\n",
    "    # results_df.to_csv( os.path.join(output_path, filename) )\n",
    "    results_df.to_csv(os.path.join(output_path, filename), sep='\\t', mode='w')\n",
    "\n",
    "    print('Results are saved in '+output_path)\n",
    "    print('\\nDone!')\n",
    "    return True\n",
    "\n",
    "pls_filename = f'PLS_{tracer}_{normalization}_salience_scores.csv'\n",
    "save_results(v_salience_scores.rename(columns={0:'salience score'}), data_output_path, pls_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we wanted to normalize it based on the density, rather then the Percentage \n",
    "# I didn't modify the various labels in the plot as I was just focused on adapting the code to our dataset, rather then polishing it\n",
    "\n",
    "threshold = 1e-2 # Only plot bars with value larger than threshold (1e-6, 1e-2, 3)\n",
    "y_axis_label = 'region_names' # change this to 'acronym' to have acronyms on the y-axis\n",
    "\n",
    "# Calculate mean values\n",
    "group_1_df = pd.DataFrame(group_1_results[(tracer,normalization)].rename('cell counts'))\n",
    "group_1_avg = group_1_df.reset_index().groupby('level_0').mean(numeric_only=True)\n",
    "group_1_sem = group_1_df.reset_index().groupby('level_0').sem(numeric_only=True)\n",
    "\n",
    "group_2_df = pd.DataFrame(group_2_results[(tracer,normalization)].rename('cell counts'))\n",
    "group_2_avg = group_2_df.reset_index().groupby('level_0').mean(numeric_only=True)\n",
    "group_2_sem = group_2_df.reset_index().groupby('level_0').sem(numeric_only=True)\n",
    "\n",
    "# Determine which regions to plot  \n",
    "mean_sum = group_1_avg + group_2_avg\n",
    "#regs_to_plot = mean_sum[(mean_sum['cell counts']>threshold) & (mean_sum['cell counts'].notnull())].sort_values(by='cell counts').index.to_list()\n",
    "regs_to_plot = cfosPLS.X.columns.to_list()\n",
    "\n",
    "# y-axis, with seperate values for each region\n",
    "y_axis_il, ticklabels = pd.factorize(group_1_df.loc[regs_to_plot].reset_index()['level_0'])\n",
    "y_axis_bla, ticklabels = pd.factorize(group_2_df.loc[regs_to_plot].reset_index()['level_0'])\n",
    "if(y_axis_label=='region_names'):\n",
    "    ticklabels = [AllenBrain.brain_region_dict[reg] for reg in ticklabels]\n",
    "     \n",
    "fig = go.Figure()\n",
    "\n",
    "# Barplot\n",
    "fig.add_trace(go.Bar(\n",
    "                     x = group_1_avg.loc[regs_to_plot]['cell counts'],\n",
    "                     name = f'{group_1_name} mean',\n",
    "                     error_x = dict(\n",
    "                         type='data',\n",
    "                         array=group_1_sem.loc[regs_to_plot]['cell counts']\n",
    "                     )\n",
    "              )\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "                     x = group_2_avg.loc[regs_to_plot]['cell counts'],\n",
    "                     name = f'{group_2_name} mean',\n",
    "                     error_x = dict(\n",
    "                         type='data',\n",
    "                         array=group_2_sem.loc[regs_to_plot]['cell counts']\n",
    "                     )\n",
    "              )\n",
    ")\n",
    "\n",
    "fig.update_layout(barmode='group', colorway=['rgb(0,255,0)', 'rgb(255,0,0)'])\n",
    "\n",
    "# Scatterplot (animals)\n",
    "fig.add_trace(go.Scatter(\n",
    "                    mode = 'markers',\n",
    "                    y = y_axis_il - 0.2,\n",
    "                    x = group_1_df.loc[regs_to_plot]['cell counts'],\n",
    "                    name = f'{group_1_name} animals',\n",
    "                    opacity=0.5,\n",
    "                    marker=dict(\n",
    "                        color='rgb(0,255,0)',\n",
    "                        size=5,\n",
    "                        line=dict(\n",
    "                            color='rgb(0,0,0)',\n",
    "                            width=1\n",
    "                        )\n",
    "                    )\n",
    "              )\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "                    mode = 'markers',\n",
    "                    y = y_axis_bla + 0.2,\n",
    "                    x = group_2_df.loc[regs_to_plot]['cell counts'],\n",
    "                    name = f'{group_2_name} animals',\n",
    "                    opacity=0.5,\n",
    "                    marker=dict(\n",
    "                        color='rgb(255,0,0)',\n",
    "                        size=5,\n",
    "                        line=dict(\n",
    "                            color='rgb(0,0,0)',\n",
    "                            width=1\n",
    "                        )\n",
    "                    )\n",
    "              )\n",
    ")\n",
    "\n",
    "# Figure title\n",
    "title = ''\n",
    "if normalization == 'RelativeDensity':\n",
    "    title = f'[#{tracer} / area] / [{tracer} (brain) / area (brain)].'\n",
    "elif normalization == 'Density':\n",
    "    title = f'[#{tracer} / area]'\n",
    "elif normalization == 'Percentage':\n",
    "    title = f'[#{tracer} / brain]'\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title = title,\n",
    "    yaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = np.arange(0,len(regs_to_plot)),\n",
    "        ticktext = ticklabels\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title = f'{tracer} density (relative to brain)'\n",
    "    ),\n",
    "    width=900, height=5000,\n",
    "    hovermode=\"x unified\",\n",
    "    yaxis_range = [-1,len(regs_to_plot)+1]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save figure as PNG\n",
    "file_title = 'barplot_' + tracer + '_' + normalization + 'CvS.png'\n",
    "fig.write_image(os.path.join(plots_output_path, file_title))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "176c264d6092c25dbd928a202ffef3b4345a7b482eecd2272f203a3592feb37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
